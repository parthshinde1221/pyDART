{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Clean Codebase for DP-Based Partitioning & Offline Scheduling\n",
        "\n",
        "This notebook defines:\n",
        "  - Node class to manage task execution on a given device.\n",
        "  - Utility functions: resolve_arg, move_tensor_to_device, measure_max_transfer_penalty.\n",
        "  - Profiler class (unchanged).\n",
        "  - HPCUtilizationMetric class (which returns raw per-layer execution times).\n",
        "  - Task class with a method run_offline_partition_makespan() that partitions the FX graph layers\n",
        "    using a DP algorithm that minimizes the overall makespan.\n",
        "  - Stage class representing a block of layers (a stage) scheduled on one node.\n",
        "  - Taskset class that creates a DP-based partitioning for each Task and then executes them.\n",
        "  - Evaluator class to compare naive (sequential) and parallel executions.\n",
        "  - Test models and dataloader utilities.\n",
        "  - run_experiment() and run_multiple_experiments() functions for experiments.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import io\n",
        "import copy\n",
        "import time\n",
        "import queue\n",
        "import threading\n",
        "import torch\n",
        "import torch.fx as fx\n",
        "import torch.nn as nn\n",
        "import torch.profiler\n",
        "import torch.cuda\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from torch.fx import Node as FxNode\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models\n",
        "from typing import Callable, Any, List, Dict, Optional, Set, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ],
      "metadata": {
        "id": "pdn9QuE5-4nK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node\n",
        "\n",
        "**Description:**  \n",
        "The **Node** class represents a compute node (a CPU core or a GPU with an associated CPU core) responsible for executing tasks. Each node maintains its own task queue and runs a dedicated worker thread. Before executing a task, it sets the proper CPU affinity and GPU device context. Additionally, the class provides a static method to discover available nodes based on the systemâ€™s resources.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4vQV_Nwu_ezK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# Node Class\n",
        "##############################################################################\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, node_id: str, cpus=None, gpu=None):\n",
        "        self._node_id = node_id\n",
        "        self._cpus = tuple(cpus or [])\n",
        "        self._gpu = gpu\n",
        "        self._original_affinity = os.sched_getaffinity(0)\n",
        "        self._task_queue = queue.Queue()\n",
        "        self._stop_signal = False\n",
        "        self._worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n",
        "        self._worker_thread.start()\n",
        "        self.current_load = 0.0\n",
        "        self.assigned_stages = []\n",
        "    @property\n",
        "    def node_id(self):\n",
        "        return self._node_id\n",
        "    @property\n",
        "    def cpus(self):\n",
        "        return self._cpus\n",
        "    @property\n",
        "    def gpu(self):\n",
        "        return self._gpu\n",
        "    def assign_task(self, func: Callable, *args, **kwargs) -> queue.Queue:\n",
        "        result_queue = queue.Queue(maxsize=1)\n",
        "        self._task_queue.put((func, args, kwargs, result_queue))\n",
        "        return result_queue\n",
        "    def stop(self):\n",
        "        self._stop_signal = True\n",
        "        self._task_queue.put(None)\n",
        "        self._worker_thread.join()\n",
        "    def _worker_loop(self):\n",
        "        while not self._stop_signal:\n",
        "            item = self._task_queue.get()\n",
        "            if item is None:\n",
        "                break\n",
        "            func, args, kwargs, result_queue = item\n",
        "            try:\n",
        "                self._set_context()\n",
        "                result = func(*args, **kwargs)\n",
        "            except Exception as e:\n",
        "                result = e\n",
        "            finally:\n",
        "                self._reset_context()\n",
        "            result_queue.put(result)\n",
        "    def _set_context(self):\n",
        "        if self._cpus:\n",
        "            os.sched_setaffinity(0, self._cpus)\n",
        "        if self._gpu is not None and torch.cuda.is_available():\n",
        "            torch.cuda.set_device(self._gpu)\n",
        "            torch.cuda.synchronize(self._gpu)\n",
        "    def _reset_context(self):\n",
        "        os.sched_setaffinity(0, self._original_affinity)\n",
        "        if self._gpu is not None and torch.cuda.is_available():\n",
        "            torch.cuda.synchronize(self._gpu)\n",
        "    @staticmethod\n",
        "    def discover_nodes(disjoint: bool = True) -> List['Node']:\n",
        "        nodes = []\n",
        "        num_cpus = os.cpu_count() or 1\n",
        "        ngpus = torch.cuda.device_count()\n",
        "        if not disjoint:\n",
        "            for core_id in range(num_cpus):\n",
        "                nodes.append(Node(node_id=f\"CPU-{core_id}\", cpus=[core_id]))\n",
        "            for g in range(ngpus):\n",
        "                for core_id in range(num_cpus):\n",
        "                    nodes.append(Node(node_id=f\"GPU-{g}-CPU-{core_id}\", cpus=[core_id], gpu=g))\n",
        "        else:\n",
        "            cpu_nodes = [Node(node_id=f\"CPU-{i}\", cpus=[i]) for i in range(num_cpus)]\n",
        "            gpu_nodes = []\n",
        "            for g in range(ngpus):\n",
        "                if cpu_nodes:\n",
        "                    cpu_node = cpu_nodes.pop()\n",
        "                    gpu_nodes.append(Node(node_id=f\"GPU-{g}-CPU-{cpu_node.cpus[0]}\", cpus=[cpu_node.cpus[0]], gpu=g))\n",
        "                else:\n",
        "                    gpu_nodes.append(Node(node_id=f\"GPU-{g}\", cpus=[], gpu=g))\n",
        "            nodes = gpu_nodes + cpu_nodes\n",
        "        return nodes\n",
        "    def __repr__(self):\n",
        "        return f\"Node({self._node_id}, cpus={self._cpus}, gpu={self._gpu})\""
      ],
      "metadata": {
        "id": "i1sKvWYP_CMG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions\n",
        "\n",
        "**Description:**  \n",
        "Several helper functions support the overall framework:\n",
        "- **resolve_arg:** Recursively resolves arguments containing FX nodes using a dictionary of node outputs.\n",
        "- **move_tensor_to_device:** Transfers tensors (or nested containers of tensors) to a specified device.\n",
        "- **measure_max_transfer_penalty:** Measures the maximum time needed to transfer a tensor between different nodes.\n",
        "- **Other helpers:** Functions like `set_seed` and `create_dataloader` ensure reproducibility and facilitate synthetic data generation.\n",
        "\n",
        "---\n",
        "\n",
        "## Metric Interface and Default Metric Class\n",
        "\n",
        "## HPCUtilizationMetric\n",
        "\n",
        "**Description:**  \n",
        "The **HPCUtilizationMetric** class provides methods to compute performance metrics. It calculates:\n",
        "- The overall forward pass execution time for a task.\n",
        "- The execution time of individual layers (FX nodes) based on profiling records.\n",
        "\n",
        "These metrics are used to guide the dynamic programming (DP) partitioning process to minimize the overall makespan."
      ],
      "metadata": {
        "id": "4v1xvRWHDHfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##############################################################################\n",
        "# Utility Functions\n",
        "##############################################################################\n",
        "def resolve_arg(arg: Any, node_outputs: Dict[str, torch.Tensor]) -> Any:\n",
        "    if isinstance(arg, FxNode):\n",
        "        return node_outputs.get(arg.name, arg)\n",
        "    elif isinstance(arg, (list, tuple)):\n",
        "        return type(arg)(resolve_arg(a, node_outputs) for a in arg)\n",
        "    elif isinstance(arg, dict):\n",
        "        return {k: resolve_arg(v, node_outputs) for k, v in arg.items()}\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "def move_tensor_to_device(obj, device):\n",
        "    if isinstance(obj, torch.Tensor):\n",
        "        return obj.to(device, non_blocking=True) if obj.device != device else obj\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return type(obj)(move_tensor_to_device(x, device) for x in obj)\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: move_tensor_to_device(v, device) for k, v in obj.items()}\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "def measure_max_transfer_penalty(available_nodes: List[Node], sample_tensor: torch.Tensor) -> float:\n",
        "    max_time = 0.0\n",
        "    for src in available_nodes:\n",
        "        src_device = torch.device(f\"cuda:{src.gpu}\") if src.gpu is not None and torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "        tensor_on_src = sample_tensor.to(src_device)\n",
        "        for dst in available_nodes:\n",
        "            dst_device = torch.device(f\"cuda:{dst.gpu}\") if dst.gpu is not None and torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "            start = time.time()\n",
        "            _ = tensor_on_src.to(dst_device)\n",
        "            if dst_device.type == 'cuda':\n",
        "                torch.cuda.synchronize(dst_device)\n",
        "            elapsed = time.time() - start\n",
        "            max_time = max(max_time, elapsed)\n",
        "    return max_time\n",
        "\n",
        "class HPCUtilizationMetric:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def compute_task(self, task: \"Task\", taskset: \"Taskset\") -> float:\n",
        "        return float(task.get_forward_pass_time(sum_across_compute=True))\n",
        "    def compute_layer(self, task: \"Task\", node: Node, fx_node: FxNode) -> float:\n",
        "        key = (node.node_id, fx_node.name)\n",
        "        record = task.prof_records.get(key, None)\n",
        "        if record is None:\n",
        "            return 0.0\n",
        "        return float(record.get(\"Total Execution Time (us)\", 0.0))"
      ],
      "metadata": {
        "id": "88m6Ckw0_R5P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Profiler\n",
        "\n",
        "**Description:**  \n",
        "The **Profiler** class leverages PyTorchâ€™s profiling tools to instrument and analyze a modelâ€™s performance. It:\n",
        "- Traces the modelâ€™s FX graph and wraps key operations with profiling contexts.\n",
        "- Collects metrics such as CPU/GPU execution times and memory usage.\n",
        "- Caches and saves the profiling data (e.g., in CSV format).\n",
        "\n",
        "This detailed performance data is critical for the subsequent partitioning and scheduling decisions in tasks.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Vs7mcaq5DcS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# Profiler Class\n",
        "##############################################################################\n",
        "\n",
        "class Profiler:\n",
        "    def __init__(self, mode: str, profile_db_path='profiling_results.csv', log_dir='logs'):\n",
        "        assert mode in ['init', 'runtime'], \"Mode must be 'init' or 'runtime'\"\n",
        "        self.mode = mode\n",
        "        self.profile_db_path = profile_db_path\n",
        "        self.log_dir = log_dir\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "        self.columns = ['Task_ID', 'Model', 'Layer', 'Compute',\n",
        "                        'Self CPU (us)', 'CPU Total (us)', 'CUDA Total (us)',\n",
        "                        'Self CPU Mem (bytes)', 'Self CUDA Mem (bytes)',\n",
        "                        'Total Execution Time (us)', 'Total Memory Used (bytes)']\n",
        "        if os.path.exists(self.profile_db_path):\n",
        "            self.profile_db = pd.read_csv(self.profile_db_path)\n",
        "        else:\n",
        "            self.profile_db = pd.DataFrame(columns=self.columns)\n",
        "        self.runtime_csv = os.path.join(self.log_dir, 'runtime_results.csv')\n",
        "        if not os.path.exists(self.runtime_csv):\n",
        "            pd.DataFrame(columns=['Task_ID', 'Model', 'Layer', 'Compute', 'Execution Time (us)']).to_csv(self.runtime_csv, index=False)\n",
        "        self.observation_window = 0.0\n",
        "        self.profile_cache: Dict[Tuple[str, str], pd.DataFrame] = {}\n",
        "\n",
        "    def profile_model(self,\n",
        "                      model: nn.Module,\n",
        "                      input_data: Any,\n",
        "                      node: \"Node\",\n",
        "                      task_id: str,\n",
        "                      warmup_iters: int = 3,\n",
        "                      profile_iters: int = 5):\n",
        "        cache_key = (model.__class__.__name__, node.node_id)\n",
        "        if cache_key in self.profile_cache:\n",
        "            cached_data = self.profile_cache[cache_key].copy()\n",
        "            cached_data['Task_ID'] = task_id\n",
        "            self.profile_db = pd.concat([self.profile_db, cached_data], ignore_index=True)\n",
        "            print(f\"[Profiler] Reused cached profiling data for {model.__class__.__name__} on {node.node_id}.\")\n",
        "            return\n",
        "\n",
        "        old_affinity = os.sched_getaffinity(0)\n",
        "        try:\n",
        "            if node.cpus:\n",
        "                os.sched_setaffinity(0, node.cpus)\n",
        "            if node.gpu is not None and torch.cuda.is_available():\n",
        "                torch.cuda.set_device(node.gpu)\n",
        "                device = torch.device(f\"cuda:{node.gpu}\")\n",
        "            else:\n",
        "                device = torch.device(\"cpu\")\n",
        "            model_copy = self._clone_model_safely(model)\n",
        "            instrumented_model = self._trace_and_instrument_model(model_copy)\n",
        "            instrumented_model.to(device)\n",
        "            instrumented_model.eval()\n",
        "            with torch.no_grad():\n",
        "                for _ in range(warmup_iters):\n",
        "                    _ = instrumented_model(input_data.to(device))\n",
        "            print(f\"[Profiler] Starting profiling for Task '{task_id}' on {node.node_id} (device={device}).\")\n",
        "            with torch.profiler.profile(\n",
        "                activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
        "                schedule=torch.profiler.schedule(wait=1, warmup=1, active=profile_iters),\n",
        "                on_trace_ready=lambda prof: self._trace_handler(prof, task_id, model.__class__.__name__, node.node_id),\n",
        "                record_shapes=True,\n",
        "                profile_memory=True,\n",
        "                with_stack=True\n",
        "            ) as prof:\n",
        "                for _ in range(profile_iters):\n",
        "                    with torch.no_grad():\n",
        "                        _ = instrumented_model(input_data.to(device))\n",
        "                    if device.type == 'cuda':\n",
        "                        torch.cuda.synchronize(device)\n",
        "                    prof.step()\n",
        "            time.sleep(0.0001)\n",
        "            new_rows = self.profile_db[self.profile_db['Task_ID'] == task_id].copy()\n",
        "            self.profile_cache[cache_key] = new_rows\n",
        "            self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "            print(f\"[Profiler] Profiling complete. Data saved to {self.profile_db_path}.\")\n",
        "        finally:\n",
        "            os.sched_setaffinity(0, old_affinity)\n",
        "\n",
        "    def _clone_model_safely(self, model: nn.Module) -> nn.Module:\n",
        "        try:\n",
        "            return copy.deepcopy(model)\n",
        "        except Exception as e:\n",
        "            print(f\"[Profiler] deepcopy failed: {e}. Falling back to torch.save/load.\")\n",
        "            buffer = io.BytesIO()\n",
        "            torch.save(model, buffer)\n",
        "            buffer.seek(0)\n",
        "            return torch.load(buffer)\n",
        "\n",
        "    def _trace_and_instrument_model(self, model: nn.Module) -> fx.GraphModule:\n",
        "        tracer = fx.Tracer()\n",
        "        graph = tracer.trace(model)\n",
        "        graph_module = fx.GraphModule(model, graph)\n",
        "        profiler_attr_prefix = \"_profiler_wrapped_\"\n",
        "        for node in list(graph.nodes):\n",
        "            node_name = node.name\n",
        "            if node.op == 'call_function':\n",
        "                func = node.target\n",
        "                wrapped_func_name = f\"{profiler_attr_prefix}{node_name}_{id(func)}\"\n",
        "                def make_wrapped_func(original_func, profile_name):\n",
        "                    def wrapped(*args, **kwargs):\n",
        "                        with torch.profiler.record_function(profile_name):\n",
        "                            return original_func(*args, **kwargs)\n",
        "                    return wrapped\n",
        "                wrapped_func = make_wrapped_func(func, node_name)\n",
        "                setattr(model, wrapped_func_name, wrapped_func)\n",
        "                node.target = getattr(model, wrapped_func_name)\n",
        "            elif node.op == 'call_module':\n",
        "                submodule = dict(model.named_modules())[node.target]\n",
        "                func = submodule.forward\n",
        "                wrapped_func_name = f\"{profiler_attr_prefix}{node_name}_{id(func)}\"\n",
        "                def make_wrapped_forward(original_forward, profile_name):\n",
        "                    def wrapped_forward(*args, **kwargs):\n",
        "                        with torch.profiler.record_function(profile_name):\n",
        "                            return original_forward(*args, **kwargs)\n",
        "                    return wrapped_forward\n",
        "                wrapped_forward = make_wrapped_forward(func, node_name)\n",
        "                setattr(submodule, wrapped_func_name, wrapped_forward)\n",
        "                submodule.forward = getattr(submodule, wrapped_func_name)\n",
        "            elif node.op == 'call_method':\n",
        "                method_name = node.target\n",
        "                obj = node.args[0]\n",
        "                original_method = getattr(obj, method_name, None)\n",
        "                if original_method is None:\n",
        "                    continue\n",
        "                wrapped_method_name = f\"{profiler_attr_prefix}{node_name}_{id(original_method)}\"\n",
        "                def make_wrapped_method(orig_meth, profile_name):\n",
        "                    def wrapped_method(*args, **kwargs):\n",
        "                        with torch.profiler.record_function(profile_name):\n",
        "                            return orig_meth(*args, **kwargs)\n",
        "                    return wrapped_method\n",
        "                wrapped_method = make_wrapped_method(original_method, node_name)\n",
        "                setattr(obj, wrapped_method_name, wrapped_method)\n",
        "            # Placeholders need no instrumentation.\n",
        "        graph_module.recompile()\n",
        "        return graph_module\n",
        "\n",
        "    def _trace_handler(self, prof, task_id: str, model_name: str, node_id: str):\n",
        "        self._process_profiler_data(prof, task_id, model_name, node_id)\n",
        "\n",
        "    def _process_profiler_data(self, profiler, task_id: str, model_name: str, node_id: str):\n",
        "        aggregated = {}\n",
        "        forward_pass = {\n",
        "            'Task_ID': task_id,\n",
        "            'Model': model_name,\n",
        "            'Layer': 'forward_pass',\n",
        "            'Compute': node_id,\n",
        "            'Self CPU (us)': 0.0,\n",
        "            'CPU Total (us)': 0.0,\n",
        "            'CUDA Total (us)': 0.0,\n",
        "            'Self CPU Mem (bytes)': 0,\n",
        "            'Self CUDA Mem (bytes)': 0,\n",
        "            'Total Execution Time (us)': 0.0,\n",
        "            'Total Memory Used (bytes)': 0\n",
        "        }\n",
        "        events = profiler.key_averages()\n",
        "        for evt in events:\n",
        "            layer_name = evt.key\n",
        "            if layer_name.startswith(\"aten::\"):\n",
        "                continue\n",
        "            forward_pass['Self CPU (us)'] += evt.self_cpu_time_total\n",
        "            forward_pass['CPU Total (us)'] += evt.cpu_time_total\n",
        "            forward_pass['CUDA Total (us)'] += getattr(evt, 'cuda_time_total', 0.0)\n",
        "            forward_pass['Self CPU Mem (bytes)'] += getattr(evt, 'self_cpu_memory_usage', 0)\n",
        "            forward_pass['Self CUDA Mem (bytes)'] += getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "            forward_pass['Total Execution Time (us)'] += evt.cpu_time_total + getattr(evt, 'cuda_time_total', 0.0)\n",
        "            forward_pass['Total Memory Used (bytes)'] += getattr(evt, 'self_cpu_memory_usage', 0) + getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "            if layer_name not in aggregated:\n",
        "                aggregated[layer_name] = {\n",
        "                    'Task_ID': task_id,\n",
        "                    'Model': model_name,\n",
        "                    'Layer': layer_name,\n",
        "                    'Compute': node_id,\n",
        "                    'Self CPU (us)': 0.0,\n",
        "                    'CPU Total (us)': 0.0,\n",
        "                    'CUDA Total (us)': 0.0,\n",
        "                    'Self CPU Mem (bytes)': 0,\n",
        "                    'Self CUDA Mem (bytes)': 0,\n",
        "                    'Total Execution Time (us)': 0.0,\n",
        "                    'Total Memory Used (bytes)': 0\n",
        "                }\n",
        "            aggregated[layer_name]['Self CPU (us)'] += evt.self_cpu_time_total\n",
        "            aggregated[layer_name]['CPU Total (us)'] += evt.cpu_time_total\n",
        "            aggregated[layer_name]['CUDA Total (us)'] += getattr(evt, 'cuda_time_total', 0.0)\n",
        "            aggregated[layer_name]['Self CPU Mem (bytes)'] += getattr(evt, 'self_cpu_memory_usage', 0)\n",
        "            aggregated[layer_name]['Self CUDA Mem (bytes)'] += getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "            aggregated[layer_name]['Total Execution Time (us)'] += evt.cpu_time_total + getattr(evt, 'cuda_time_total', 0.0)\n",
        "            aggregated[layer_name]['Total Memory Used (bytes)'] += getattr(evt, 'self_cpu_memory_usage', 0) + getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "        self.profile_db = self._upsert(self.profile_db, forward_pass)\n",
        "        for data in aggregated.values():\n",
        "            self.profile_db = self._upsert(self.profile_db, data)\n",
        "        self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "\n",
        "    def _upsert(self, df: pd.DataFrame, row: Dict[str, Any]) -> pd.DataFrame:\n",
        "        mask = (df['Task_ID'] == row['Task_ID']) & (df['Model'] == row['Model']) & (df['Layer'] == row['Layer']) & (df['Compute'] == row['Compute'])\n",
        "        if mask.any():\n",
        "            existing_time = df.loc[mask, 'Total Execution Time (us)'].max()\n",
        "            if row['Total Execution Time (us)'] > existing_time:\n",
        "                for key in self.columns:\n",
        "                    df.loc[mask, key] = row[key]\n",
        "        else:\n",
        "            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "        return df\n",
        "\n",
        "    def get_profile_db(self) -> pd.DataFrame:\n",
        "        return self.profile_db\n",
        "\n",
        "    def print_profile_db(self):\n",
        "        if self.profile_db.empty:\n",
        "            print(\"ProfileDB is empty.\")\n",
        "        else:\n",
        "            print(\"ProfileDB:\")\n",
        "            print(self.profile_db.to_string(index=False))"
      ],
      "metadata": {
        "id": "lCvlcH8gDwId"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "**Description:**  \n",
        "The **Task** class encapsulates a single model inference execution. It holds:\n",
        "- The model and its input data.\n",
        "- Profiling records and execution metrics.\n",
        "- The results of a DP-based partitioning of the modelâ€™s FX graph into stages.\n",
        "\n",
        "Each task manages the execution of its stages, tracks metrics (e.g., busy time, transfer time), and ultimately records the final output.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9uwwxcZeHlwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# Task Class with DP-Based Partitioning (Minimizing Makespan)\n",
        "##############################################################################\n",
        "class Task:\n",
        "    def __init__(self, task_id: str, model: nn.Module, input_data: torch.Tensor, model_name: str,\n",
        "                 profiler: Profiler, load_metric: Optional[HPCUtilizationMetric] = None):\n",
        "        self.task_id = task_id\n",
        "        self.model = model\n",
        "        self.input_data = input_data\n",
        "        self.model_name = model_name\n",
        "        self.profiler = profiler\n",
        "        self.load_metric = load_metric if load_metric else HPCUtilizationMetric()\n",
        "        self.stages: Dict[str, Stage] = {}\n",
        "        self.graph = nx.DiGraph()\n",
        "        self.start_time: Optional[float] = None\n",
        "        self.finish_time: Optional[float] = None\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "        self.busy_time: float = 0.0\n",
        "        self.computation_time: float = 0.0\n",
        "        self.transfer_time: float = 0.0\n",
        "        self.prof_records: Dict[Tuple[str, str], Dict[str, Any]] = {}\n",
        "        self._available_nodes: List[Node] = []\n",
        "        self.init_traced_graph: List[str] = []\n",
        "        self.placeholder_names: Set[str] = set()\n",
        "        self._initialize_dag()\n",
        "\n",
        "    def _initialize_dag(self):\n",
        "        tracer = fx.symbolic_trace(self.model)\n",
        "        fx_nodes = list(tracer.graph.nodes)\n",
        "        self.init_traced_graph = [node.name for node in fx_nodes]\n",
        "        self.placeholder_names = set(n.name for n in fx_nodes if n.op == \"placeholder\")\n",
        "\n",
        "    def get_forward_pass_time(self, sum_across_compute: bool = False) -> float:\n",
        "        if not self.profiler:\n",
        "            return 0.0\n",
        "        df = self.profiler.get_profile_db()\n",
        "        mask = (df['Task_ID'] == self.task_id) & (df['Model'] == self.model_name) & (df['Layer'] == 'forward_pass')\n",
        "        matched = df.loc[mask]\n",
        "        if matched.empty:\n",
        "            return 0.0\n",
        "        times = matched['Total Execution Time (us)']\n",
        "        return float(times.sum()) if sum_across_compute else float(times.max())\n",
        "\n",
        "    def populate_profile_records(self):\n",
        "        if not self.profiler:\n",
        "            return\n",
        "        df = self.profiler.get_profile_db()\n",
        "        mask_all = (df['Task_ID'] == self.task_id) & (df['Model'] == self.model_name)\n",
        "        relevant = df.loc[mask_all]\n",
        "        all_computes = relevant['Compute'].unique()\n",
        "        for comp in all_computes:\n",
        "            mask_comp = (relevant['Compute'] == comp)\n",
        "            subdf = relevant.loc[mask_comp]\n",
        "            for layer in self.init_traced_graph:\n",
        "                row = subdf.loc[subdf['Layer'] == layer]\n",
        "                if not row.empty:\n",
        "                    self.prof_records[(comp, layer)] = row.iloc[0].to_dict()\n",
        "                else:\n",
        "                    self.prof_records[(comp, layer)] = None\n",
        "\n",
        "    def run_offline_partition_makespan(self):\n",
        "        \"\"\"\n",
        "        Uses DP to partition the model's layers into K blocks (K = number of available nodes)\n",
        "        to minimize the overall makespan.\n",
        "        \"\"\"\n",
        "        tracer = fx.symbolic_trace(self.model)\n",
        "        fx_nodes = list(tracer.graph.nodes)\n",
        "        L = len(fx_nodes)\n",
        "        K = len(self._available_nodes)\n",
        "        if L == 0 or K == 0:\n",
        "            return\n",
        "        # Precompute cost for block [i, j] on best node.\n",
        "        cost = [[0.0 for _ in range(L)] for _ in range(L)]\n",
        "        for i in range(L):\n",
        "            for j in range(i, L):\n",
        "                block_costs = []\n",
        "                for node in self._available_nodes:\n",
        "                    s = 0.0\n",
        "                    for l in range(i, j + 1):\n",
        "                        s += self.load_metric.compute_layer(self, node, fx_nodes[l])\n",
        "                    block_costs.append(s)\n",
        "                cost[i][j] = min(block_costs)\n",
        "        # DP table: dp[i][k] = minimal possible maximum cost when partitioning layers 0..i into k blocks.\n",
        "        dp = [[float(\"inf\")] * (K + 1) for _ in range(L)]\n",
        "        split = [[-1] * (K + 1) for _ in range(L)]\n",
        "        for i in range(L):\n",
        "            dp[i][1] = cost[0][i]\n",
        "        for k in range(2, K + 1):\n",
        "            for i in range(L):\n",
        "                for x in range(0, i):\n",
        "                    candidate = max(dp[x][k - 1], cost[x + 1][i])\n",
        "                    if candidate < dp[i][k]:\n",
        "                        dp[i][k] = candidate\n",
        "                        split[i][k] = x\n",
        "        optimal_makespan = dp[L - 1][K]\n",
        "        # Backtrack to obtain partition indices.\n",
        "        partitions = []\n",
        "        k_val = K\n",
        "        i_val = L - 1\n",
        "        while k_val > 1:\n",
        "            x = split[i_val][k_val]\n",
        "            partitions.append((x + 1, i_val))\n",
        "            i_val = x\n",
        "            k_val -= 1\n",
        "        partitions.append((0, i_val))\n",
        "        partitions.reverse()\n",
        "        # Create Stage objects from partitions.\n",
        "        self.stages.clear()\n",
        "        self.graph.clear()\n",
        "        for idx, (start, end) in enumerate(partitions):\n",
        "            stage_id = f\"{self.task_id}-stage-{idx + 1}\"\n",
        "            best_node = None\n",
        "            best_cost = float(\"inf\")\n",
        "            for node in self._available_nodes:\n",
        "                s = 0.0\n",
        "                for l in range(start, end + 1):\n",
        "                    s += self.load_metric.compute_layer(self, node, fx_nodes[l])\n",
        "                if s < best_cost:\n",
        "                    best_cost = s\n",
        "                    best_node = node\n",
        "            stg = Stage(stage_id, fx_nodes[start:end + 1], best_node, self)\n",
        "            stg.execution_time = best_cost\n",
        "            self.stages[stage_id] = stg\n",
        "            self.graph.add_node(stage_id, stage=stg)\n",
        "        # Link stages sequentially.\n",
        "        stage_ids = sorted(self.stages.keys(), key=lambda sid: int(sid.split(\"-\")[-1]))\n",
        "        for i in range(len(stage_ids) - 1):\n",
        "            self.stages[stage_ids[i + 1]].add_dependency(stage_ids[i])\n",
        "            self.stages[stage_ids[i]].add_dependent(stage_ids[i + 1])\n",
        "            self.graph.add_edge(stage_ids[i], stage_ids[i + 1])\n",
        "        self.finish_time = optimal_makespan\n",
        "\n",
        "    def get_execution_order(self) -> List[str]:\n",
        "        try:\n",
        "            return list(nx.topological_sort(self.graph))\n",
        "        except nx.NetworkXUnfeasible:\n",
        "            raise ValueError(\"Cycle in stage DAG\")\n",
        "\n",
        "    def update_busy_time(self, exec_time: float, transfer_time: float = 0.0):\n",
        "        self.busy_time += exec_time\n",
        "        self.transfer_time += transfer_time\n",
        "        self.computation_time += (exec_time - transfer_time)\n",
        "\n",
        "    def set_output_data(self, output: torch.Tensor):\n",
        "        self.output_data = output.cpu() if output is not None else None\n",
        "        self.finish_time = time.time()\n",
        "\n",
        "    def get_total_execution_time(self) -> float:\n",
        "        if self.start_time and self.finish_time:\n",
        "            return self.finish_time - self.start_time\n",
        "        return 0.0\n",
        "\n",
        "    def print_stage_allocations(self):\n",
        "        print(f\"=== Stage Allocations for Task {self.task_id} ===\")\n",
        "        for sid, stg in self.stages.items():\n",
        "            layer_names = [fxn.name for fxn in stg.nodes]\n",
        "            node_id = stg.assigned_node.node_id if stg.assigned_node else \"Unassigned\"\n",
        "            print(f\"{sid}: Node={node_id}, Layers={layer_names}, Deps={stg.dependencies}\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Task({self.task_id}, model={self.model_name})\""
      ],
      "metadata": {
        "id": "-F1ZkLXvHg0g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Stage\n",
        "\n",
        "**Description:**  \n",
        "A **Stage** represents a contiguous block of FX nodes (or model layers) that will execute on a designated node. It is responsible for:\n",
        "- Transferring data to the proper device.\n",
        "- Sequentially executing its operations.\n",
        "- Recording its execution and data transfer times.\n",
        "- Managing dependencies with other stages to ensure correct execution order.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "x4prFGuwD6as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# Stage Class\n",
        "##############################################################################\n",
        "class Stage:\n",
        "    def __init__(self, stage_id: str, nodes: List[FxNode], assigned_node: Node, task: Task):\n",
        "        self.stage_id = stage_id\n",
        "        self.nodes = nodes\n",
        "        self.assigned_node = assigned_node\n",
        "        self.dependencies: List[str] = []\n",
        "        self.dependents: List[str] = []\n",
        "        self.execution_time: Optional[float] = None\n",
        "        self.transfer_time: float = 0.0\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "        self.task = task\n",
        "        self.stage_device: str = \"cpu\"\n",
        "    def add_dependency(self, stage_id: str):\n",
        "        self.dependencies.append(stage_id)\n",
        "    def add_dependent(self, stage_id: str):\n",
        "        self.dependents.append(stage_id)\n",
        "    def run_stage(self, node_outputs: Dict[str, torch.Tensor]):\n",
        "        start_time = time.time()\n",
        "        transfer_time = 0.0\n",
        "        if self.assigned_node and self.assigned_node.gpu is not None and torch.cuda.is_available():\n",
        "            device = torch.device(f\"cuda:{self.assigned_node.gpu}\")\n",
        "            self.stage_device = str(device)\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            self.stage_device = \"cpu\"\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                for fx_node in self.nodes:\n",
        "                    resolved_args = resolve_arg(fx_node.args, node_outputs)\n",
        "                    resolved_kwargs = resolve_arg(fx_node.kwargs, node_outputs)\n",
        "                    t_start = time.time()\n",
        "                    resolved_args = move_tensor_to_device(resolved_args, device)\n",
        "                    resolved_kwargs = move_tensor_to_device(resolved_kwargs, device)\n",
        "                    t_end = time.time()\n",
        "                    transfer_time += (t_end - t_start)\n",
        "                    if fx_node.op == \"placeholder\":\n",
        "                        out = self.task.input_data.to(device)\n",
        "                    elif fx_node.op == \"get_attr\":\n",
        "                        out = getattr(self.task.model, fx_node.target)\n",
        "                    elif fx_node.op == \"call_module\":\n",
        "                        submodule = self.task.model.get_submodule(fx_node.target)\n",
        "                        submodule.to(device)\n",
        "                        out = submodule(*resolved_args, **resolved_kwargs)\n",
        "                    elif fx_node.op == \"call_function\":\n",
        "                        out = fx_node.target(*resolved_args, **resolved_kwargs)\n",
        "                    elif fx_node.op == \"call_method\":\n",
        "                        method = getattr(resolved_args[0], fx_node.target)\n",
        "                        out = method(*resolved_args[1:], **resolved_kwargs)\n",
        "                    elif fx_node.op == \"output\":\n",
        "                        out = resolved_args[0]\n",
        "                    else:\n",
        "                        raise NotImplementedError(f\"Operation '{fx_node.op}' is not supported.\")\n",
        "                    node_outputs[fx_node.name] = out\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage] {self.stage_id} error: {e}\")\n",
        "            self.execution_time = float('inf')\n",
        "            self.transfer_time = float('inf')\n",
        "            node_outputs[self.stage_id] = None\n",
        "            return\n",
        "        finally:\n",
        "            if device.type == 'cuda':\n",
        "                torch.cuda.synchronize(device)\n",
        "            end_time = time.time()\n",
        "            self.execution_time = end_time - start_time\n",
        "            self.transfer_time = transfer_time\n",
        "        self.task.update_busy_time(self.execution_time, self.transfer_time)\n",
        "        if not self.dependents:\n",
        "            final_output_node = next((n for n in self.nodes if n.op == 'output'), None)\n",
        "            if final_output_node:\n",
        "                arg = final_output_node.args[0]\n",
        "                if isinstance(arg, torch.Tensor):\n",
        "                    final_res = arg.cpu()\n",
        "                elif isinstance(arg, FxNode):\n",
        "                    final_res = node_outputs.get(arg.name, None)\n",
        "                else:\n",
        "                    final_res = None\n",
        "                self.task.set_output_data(final_res)\n",
        "            else:\n",
        "                self.task.set_output_data(None)\n",
        "        print(f\"[Stage] {self.stage_id}: Executed on {self.assigned_node.node_id} in {self.execution_time:.4f} s, Transfer: {self.transfer_time:.4f} s.\")\n",
        "    def __repr__(self):\n",
        "        return (f\"Stage({self.stage_id}, device={self.stage_device}, node={self.assigned_node.node_id if self.assigned_node else 'None'}, \"\n",
        "                f\"deps={self.dependencies}, exec_time={self.execution_time}, transfer_time={self.transfer_time})\")"
      ],
      "metadata": {
        "id": "-Q7BX4zbEKK6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taskset\n",
        "\n",
        "**Description:**  \n",
        "The **Taskset** class manages a collection of tasks. Its main responsibilities include:\n",
        "- Running DP-based partitioning for each task.\n",
        "- Scheduling the execution of task stages across available nodes in parallel.\n",
        "- Calculating overall performance metrics such as makespan, throughput, and node utilization.\n",
        "\n",
        "It abstracts the complexity of coordinating multiple tasks on heterogeneous computing resources.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "47omsjFNEbxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# Taskset Class (Using DP-Based Partitioning for Makespan)\n",
        "##############################################################################\n",
        "class Taskset:\n",
        "    def __init__(self, tasks: List[Task], available_nodes: List[Node],\n",
        "                 metric: Optional[HPCUtilizationMetric] = None):\n",
        "        self.tasks = tasks\n",
        "        self.available_nodes = sorted(available_nodes, key=lambda n: 0 if n.gpu is not None else 1)\n",
        "        self.metric = metric if metric else HPCUtilizationMetric()\n",
        "        if self.tasks and self.available_nodes:\n",
        "            sample_tensor = self.tasks[0].input_data\n",
        "            penalty = measure_max_transfer_penalty(self.available_nodes, sample_tensor)\n",
        "            print(f\"Measured max transfer penalty: {penalty:.6f} s\")\n",
        "            self.metric.transfer_penalty = penalty\n",
        "        self.total_utilization = 0.0\n",
        "        self.average_turnaround_time = 0.0\n",
        "        self.throughput = 0.0\n",
        "        self.makespan = 0.0\n",
        "        self.task_completion_rate = 0.0\n",
        "        self.loads: Dict[str, float] = {}\n",
        "        for t in self.tasks:\n",
        "            t.load_metric = self.metric\n",
        "            self.loads[t.task_id] = t.load_metric.compute_task(t, self)\n",
        "            t._available_nodes = self.available_nodes\n",
        "            t.run_offline_partition_makespan()\n",
        "    def execute_all(self):\n",
        "        threads = []\n",
        "        for t in self.tasks:\n",
        "            thr = threading.Thread(target=self._execute_task, args=(t,))\n",
        "            thr.start()\n",
        "            threads.append(thr)\n",
        "        for thr in threads:\n",
        "            thr.join()\n",
        "        self._calculate_metrics()\n",
        "    def _execute_task(self, task: Task):\n",
        "        print(f\"[Taskset] Starting Task {task.task_id}\")\n",
        "        task.start_time = time.time()\n",
        "        try:\n",
        "            order = task.get_execution_order()\n",
        "        except ValueError as e:\n",
        "            print(f\"[Taskset] {task.task_id} error: {e}\")\n",
        "            return\n",
        "        node_outputs = {}\n",
        "        for sid in order:\n",
        "            stg = task.stages[sid]\n",
        "            def run_stage(s=stg):\n",
        "                s.run_stage(node_outputs)\n",
        "            rq = stg.assigned_node.assign_task(run_stage)\n",
        "            rq.get()\n",
        "        task.finish_time = time.time()\n",
        "        print(f\"[Taskset] Completed Task {task.task_id} in {task.finish_time - task.start_time:.2f} s\")\n",
        "    def _calculate_metrics(self):\n",
        "        total_busy_time = sum(stg.execution_time for t in self.tasks for stg in t.stages.values() if stg.execution_time)\n",
        "        earliest_start = min((t.start_time for t in self.tasks if t.start_time), default=None)\n",
        "        latest_finish = max((t.finish_time for t in self.tasks if t.finish_time), default=None)\n",
        "        obs = (latest_finish - earliest_start) if earliest_start and latest_finish else 0.0\n",
        "        used_nodes = {stg.assigned_node.node_id for t in self.tasks for stg in t.stages.values() if stg.assigned_node}\n",
        "        total_available_time = obs * len(used_nodes)\n",
        "        self.total_utilization = total_busy_time / total_available_time if total_available_time > 0 else 0.0\n",
        "        ttimes = [t.get_total_execution_time() for t in self.tasks if t.start_time and t.finish_time]\n",
        "        self.average_turnaround_time = sum(ttimes) / len(ttimes) if ttimes else 0.0\n",
        "        self.makespan = obs\n",
        "        self.throughput = len(self.tasks) / obs if obs > 0 else 0.0\n",
        "        done = [t for t in self.tasks if t.output_data is not None]\n",
        "        self.task_completion_rate = len(done) / len(self.tasks) if self.tasks else 0.0\n",
        "    def __repr__(self):\n",
        "        return (f\"Taskset(num_tasks={len(self.tasks)}, makespan={self.makespan:.4f}s, \"\n",
        "                f\"utilization={self.total_utilization:.2%}, throughput={self.throughput:.3f} tasks/s, \"\n",
        "                f\"avg_turnaround={self.average_turnaround_time:.4f}s, completion_rate={self.task_completion_rate:.2%})\")"
      ],
      "metadata": {
        "id": "IWwBvNYSEjV6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Evaluator\n",
        "\n",
        "**Description:**  \n",
        "The **Evaluator** class compares two execution strategies:\n",
        "- **Naive Execution:** Running tasks sequentially (or asynchronously without partitioning).\n",
        "- **Parallel Execution:** Utilizing DP-based partitioning and scheduling.\n",
        "\n",
        "It gathers outputs, measures execution times, validates output correctness, and computes performance metrics (speedup, throughput, etc.) to analyze the benefits of the parallel scheduling approach.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "W93J1XMCEoB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##############################################################################\n",
        "# Evaluator Class\n",
        "##############################################################################\n",
        "class Evaluator:\n",
        "    def __init__(self, taskset: Taskset, profiler: Profiler):\n",
        "        self.taskset = taskset\n",
        "        self.profiler = profiler\n",
        "        self.naive_outputs: Dict[str, torch.Tensor] = {}\n",
        "        self.parallel_outputs: Dict[str, torch.Tensor] = {}\n",
        "        self.naive_execution_times: Dict[str, float] = {}\n",
        "        self.parallel_execution_times: Dict[str, float] = {}\n",
        "        self.naive_completion_times: Dict[str, float] = {}\n",
        "        self.parallel_completion_times: Dict[str, float] = {}\n",
        "        self.naive_makespan: float = 0.0\n",
        "        self.parallel_makespan: float = 0.0\n",
        "        self.speedup_makespan: float = 0.0\n",
        "        self.throughput_makespan: float = 0.0\n",
        "\n",
        "    def run_naive_execution(self):\n",
        "        print(\"[Evaluator] Starting Naive Execution.\")\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        if device.type == 'cuda':\n",
        "          print(\"Running on cuda\")\n",
        "        else:\n",
        "          print(\"Running on cpu\")\n",
        "        start = time.time()\n",
        "        for task in self.taskset.tasks:\n",
        "            task.model.to(device)\n",
        "            inp = task.input_data.to(device)\n",
        "            t0 = time.time()\n",
        "            with torch.no_grad():\n",
        "                out = task.model(inp)\n",
        "            if device.type == 'cuda':\n",
        "                torch.cuda.synchronize()\n",
        "            t1 = time.time()\n",
        "            et = t1 - t0\n",
        "            self.naive_execution_times[task.task_id] = et\n",
        "            self.naive_completion_times[task.task_id] = time.time() - start\n",
        "            self.naive_outputs[task.task_id] = out.cpu()\n",
        "            print(f\"[Evaluator] Task {task.task_id}: Naive exec time: {et:.4f}s\")\n",
        "        self.naive_makespan = time.time() - start\n",
        "        print(f\"[Evaluator] Naive makespan: {self.naive_makespan:.4f}s\\n\")\n",
        "\n",
        "\n",
        "    # def run_naive_execution(self):\n",
        "    #     print(\"[Evaluator] Starting Async Execution.\")\n",
        "    #     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    #     if device.type == 'cuda':\n",
        "    #         print(\"Running on cuda\")\n",
        "    #     else:\n",
        "    #         print(\"Running on cpu\")\n",
        "    #     start = time.time()\n",
        "\n",
        "    #     def execute_task(task):\n",
        "    #         # Move the model and input to the selected device\n",
        "    #         task.model.to(device)\n",
        "    #         inp = task.input_data.to(device)\n",
        "    #         t0 = time.time()\n",
        "    #         with torch.no_grad():\n",
        "    #             out = task.model(inp)\n",
        "    #         # If using CUDA, synchronize to get an accurate execution time\n",
        "    #         if device.type == 'cuda':\n",
        "    #             torch.cuda.synchronize()\n",
        "    #         t1 = time.time()\n",
        "    #         et = t1 - t0\n",
        "    #         # Record the time elapsed since the start of the entire execution\n",
        "    #         completion_time = time.time() - start\n",
        "    #         # Return all necessary results along with the task id\n",
        "    #         return task.task_id, et, completion_time, out.cpu()\n",
        "\n",
        "    #     # Use ThreadPoolExecutor to run tasks concurrently\n",
        "    #     with ThreadPoolExecutor(max_workers=len(self.taskset.tasks)) as executor:\n",
        "    #         # Launch all tasks asynchronously\n",
        "    #         futures = [executor.submit(execute_task, task) for task in self.taskset.tasks]\n",
        "    #         for future in as_completed(futures):\n",
        "    #             task_id, et, completion_time, output = future.result()\n",
        "    #             self.naive_execution_times[task_id] = et\n",
        "    #             self.naive_completion_times[task_id] = completion_time\n",
        "    #             self.naive_outputs[task_id] = output\n",
        "    #             print(f\"[Evaluator] Task {task_id}: Async exec time: {et:.4f}s\")\n",
        "\n",
        "    #     self.naive_makespan = time.time() - start\n",
        "    #     print(f\"[Evaluator] Async makespan: {self.naive_makespan:.4f}s\\n\")\n",
        "\n",
        "    def run_parallel_execution(self):\n",
        "        print(\"[Evaluator] Starting Parallel Execution.\")\n",
        "        self.parallel_outputs.clear()\n",
        "        self.parallel_execution_times.clear()\n",
        "        self.parallel_completion_times.clear()\n",
        "        par_start = time.time()\n",
        "        self.taskset.execute_all()\n",
        "        par_end = time.time()\n",
        "        self.parallel_makespan = par_end - par_start\n",
        "        for task in self.taskset.tasks:\n",
        "            self.parallel_outputs[task.task_id] = task.output_data.cpu() if task.output_data is not None else None\n",
        "            self.parallel_execution_times[task.task_id] = task.get_total_execution_time()\n",
        "            if task.finish_time:\n",
        "                self.parallel_completion_times[task.task_id] = task.finish_time - par_start\n",
        "            else:\n",
        "                self.parallel_completion_times[task.task_id] = float('nan')\n",
        "        print(f\"[Evaluator] Parallel makespan: {self.parallel_makespan:.4f}s\\n\")\n",
        "    def compare_outputs(self):\n",
        "        print(\"[Evaluator] Comparing Outputs.\")\n",
        "        all_match = True\n",
        "        for tid, naive_out in self.naive_outputs.items():\n",
        "            par_out = self.parallel_outputs.get(tid)\n",
        "            if naive_out is None or par_out is None:\n",
        "                print(f\"[Evaluator] Task {tid} missing output.\")\n",
        "                all_match = False\n",
        "                continue\n",
        "            if torch.equal(naive_out, par_out) or torch.allclose(naive_out, par_out, atol=1e-5):\n",
        "                print(f\"[Evaluator] Task {tid}: Outputs match.\")\n",
        "            else:\n",
        "                print(f\"[Evaluator] Task {tid}: Outputs do NOT match.\")\n",
        "                all_match = False\n",
        "        if all_match:\n",
        "            print(\"[Evaluator] All outputs match.\\n\")\n",
        "        else:\n",
        "            print(\"[Evaluator] Some outputs differ.\\n\")\n",
        "    def analyze_speedup_throughput(self):\n",
        "        print(\"[Evaluator] Analyzing Speedup and Throughput.\\n\")\n",
        "        total_naive = sum(self.naive_execution_times.values())\n",
        "        total_parallel = sum(self.parallel_execution_times.values())\n",
        "        print(\"--- Sum-of-times ---\")\n",
        "        print(f\"Naive total: {total_naive:.4f}s, Parallel total: {total_parallel:.4f}s\")\n",
        "        speedup_sum = total_naive / total_parallel if total_parallel > 0 else float('inf')\n",
        "        n = len(self.taskset.tasks)\n",
        "        print(f\"Speedup (sum-of-times): {speedup_sum:.2f}x\")\n",
        "        print(f\"Naive Throughput: {n / total_naive:.2f} tasks/s, Parallel Throughput: {n / total_parallel:.2f} tasks/s\\n\")\n",
        "        print(\"--- Makespan ---\")\n",
        "        print(f\"Naive makespan: {self.naive_makespan:.4f}s, Parallel makespan: {self.parallel_makespan:.4f}s\")\n",
        "        self.speedup_makespan = self.naive_makespan / self.parallel_makespan if self.parallel_makespan > 0 else float('inf')\n",
        "        self.throughput_makespan = n / self.parallel_makespan if self.parallel_makespan > 0 else 0.0\n",
        "        print(f\"Speedup (makespan): {self.speedup_makespan:.2f}x\")\n",
        "        print(f\"Naive Throughput (makespan): {n / self.naive_makespan:.2f} tasks/s, Parallel Throughput (makespan): {self.throughput_makespan:.2f} tasks/s\\n\")\n",
        "        print(\"--- Task Completion Times ---\")\n",
        "        for tid in self.naive_completion_times:\n",
        "            nf = self.naive_completion_times[tid]\n",
        "            pf = self.parallel_completion_times.get(tid, float('nan'))\n",
        "            print(f\"Task {tid}: Naive finish: {nf:.4f}s, Parallel finish: {pf:.4f}s\")\n",
        "        print()\n",
        "    def __repr__(self):\n",
        "        return f\"Evaluator(Taskset with {len(self.taskset.tasks)} tasks)\""
      ],
      "metadata": {
        "id": "7Qh2W45CEuvH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models\n",
        "\n",
        "**Description:**  \n",
        "- **SimpleCNN:** A lightweight convolutional neural network designed for quick tests and light-load experiments.\n",
        "- **PretrainedResNet18:** A heavier, more complex model based on the ResNet18 architecture, simulating computationally intensive workloads.\n",
        "- **Additional Models:** (e.g., Vision Transformer) may also be used to assess varying computational demands.\n",
        "\n",
        "These models serve as practical test cases for evaluating the scheduling and partitioning framework.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jgnm2vlNE1WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##############################################################################\n",
        "# Test Models and DataLoader Utilities\n",
        "##############################################################################\n",
        "def set_seed(seed: int = 42):\n",
        "    import random, numpy as np\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Seed set to {seed}\")\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(3, 16, 5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(32 * 28 * 28, 10)\n",
        "    def forward(self, x):\n",
        "        x1 = self.relu(self.conv1(x))\n",
        "        x2 = self.relu(self.conv2(x))\n",
        "        x = torch.cat((x1, x2), dim=1)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class PretrainedResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(PretrainedResNet18, self).__init__()\n",
        "        self.resnet18 = models.resnet18(pretrained=False)\n",
        "        n = self.resnet18.fc.in_features\n",
        "        self.resnet18.fc = nn.Linear(n, num_classes)\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)\n",
        "\n",
        "# def create_vit_model(num_classes=10):\n",
        "#     model = models.vit_b_16(pretrained=False)\n",
        "#     in_features = model.heads.head.in_features\n",
        "#     model.heads.head = nn.Linear(in_features, num_classes)\n",
        "#     return model\n",
        "\n",
        "def create_dataloader(batch_size: int, num_samples: int, input_size: Tuple[int, int, int]):\n",
        "    inputs = torch.randn(num_samples, *input_size)\n",
        "    targets = torch.randint(0, 10, (num_samples,))\n",
        "    dataset = TensorDataset(inputs, targets)\n",
        "    return DataLoader(dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "5jURfEflGO8F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment Runner Functions\n",
        "\n",
        "---\n",
        "\n",
        "## run_experiment\n",
        "\n",
        "**Purpose:**  \n",
        "Sets up and executes a single experiment with a specified number of nodes and a given heavy/light task ratio.\n",
        "\n",
        "**Key Steps:**\n",
        "- **Initialization:**  \n",
        "  - Sets a random seed for reproducibility.\n",
        "  - Discovers available nodes and selects `k` nodes.\n",
        "- **Task Creation & Profiling:**  \n",
        "  - Creates heavy (e.g., ResNet-based) and light (e.g., CNN-based) tasks based on the specified ratio.\n",
        "  - Profiles each model on every selected node to collect per-layer performance metrics.\n",
        "- **Partitioning & Scheduling:**  \n",
        "  - Each task uses DP-based partitioning to split its model into stages.\n",
        "  - Stage allocations are printed for verification.\n",
        "- **Execution & Evaluation:**  \n",
        "  - Runs a naive (sequential) execution followed by a parallel execution using the computed partitions.\n",
        "  - Compares outputs and computes speedup, throughput, and makespan metrics.\n",
        "- **Cleanup:**  \n",
        "  - Stops all nodes after the experiment.\n",
        "- **Return:**  \n",
        "  - Returns an `Evaluator` object containing the performance results.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "y4-r-RGkGP-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##############################################################################\n",
        "# Experiment Runner Functions\n",
        "##############################################################################\n",
        "def run_experiment(k: int, heavy_light_ratio: Tuple[int, int], num_tasks: int = 10):\n",
        "    set_seed(42)\n",
        "    all_nodes = Node.discover_nodes(disjoint=True)\n",
        "    nodes = all_nodes[:k]  # Use only k nodes.\n",
        "    print(f\"Using {len(nodes)} nodes: {nodes}\")\n",
        "    profiler = Profiler(mode=\"init\")\n",
        "    heavy_models = [PretrainedResNet18]\n",
        "    light_models = [SimpleCNN]\n",
        "    heavy_count = (num_tasks * heavy_light_ratio[0]) // (heavy_light_ratio[0] + heavy_light_ratio[1])\n",
        "    light_count = num_tasks - heavy_count\n",
        "    print(f\"Creating {heavy_count} heavy tasks and {light_count} light tasks.\")\n",
        "    tasks = []\n",
        "    for i in range(heavy_count):\n",
        "        mc = heavy_models[i % len(heavy_models)]\n",
        "        model = mc()\n",
        "        dl = create_dataloader(batch_size=10, num_samples=100, input_size=(3, 224, 224))\n",
        "        inp, _ = next(iter(dl))\n",
        "        task = Task(task_id=f\"heavy_{i+1}\", model=model, input_data=inp,\n",
        "                    model_name=model.__class__.__name__, profiler=profiler,\n",
        "                    load_metric=HPCUtilizationMetric())\n",
        "        tasks.append(task)\n",
        "    for i in range(light_count):\n",
        "        mc = light_models[i % len(light_models)]\n",
        "        model = mc()\n",
        "        dl = create_dataloader(batch_size=10, num_samples=100, input_size=(3, 28, 28))\n",
        "        inp, _ = next(iter(dl))\n",
        "        task = Task(task_id=f\"light_{i+1}\", model=model, input_data=inp,\n",
        "                    model_name=model.__class__.__name__, profiler=profiler,\n",
        "                    load_metric=HPCUtilizationMetric())\n",
        "        tasks.append(task)\n",
        "    # Profile each model on each available node.\n",
        "    for task in tasks:\n",
        "        for node in nodes:\n",
        "            inp_copy = copy.deepcopy(task.input_data)\n",
        "            profiler.profile_model(model=task.model, input_data=inp_copy, node=node, task_id=task.task_id)\n",
        "            time.sleep(0.05)\n",
        "    for task in tasks:\n",
        "        task.populate_profile_records()\n",
        "    # Create Taskset (each task uses its DP-based partitioning).\n",
        "    taskset = Taskset(tasks, nodes)\n",
        "    for task in taskset.tasks:\n",
        "        task.print_stage_allocations()\n",
        "    evaluator = Evaluator(taskset, profiler)\n",
        "    evaluator.run_naive_execution()\n",
        "    evaluator.run_parallel_execution()\n",
        "    evaluator.compare_outputs()\n",
        "    evaluator.analyze_speedup_throughput()\n",
        "    for node in nodes:\n",
        "        node.stop()\n",
        "    return evaluator\n",
        "\n",
        "# def run_multiple_experiments(k: int, num_tasks: int = 15):\n",
        "#     ratios = [round(i / 10, 1) for i in range(1, 10)]\n",
        "#     speedups = []\n",
        "#     parallel_throughputs = []\n",
        "#     naive_throughputs = []\n",
        "#     makespans = []\n",
        "#     config = defaultdict(dict)\n",
        "#     for ratio in ratios:\n",
        "#         heavy_count = int(num_tasks * ratio)\n",
        "#         light_count = num_tasks - heavy_count\n",
        "#         print(f\"Running experiment with {heavy_count} heavy and {light_count} light tasks.\")\n",
        "#         if os.\n",
        "#         evaluator = run_experiment(k=k, heavy_light_ratio=(heavy_count, light_count), num_tasks=num_tasks)\n",
        "#         sp = evaluator.speedup_makespan\n",
        "#         par_th = evaluator.throughput_makespan\n",
        "#         naive_thr = num_tasks / evaluator.naive_makespan if evaluator.naive_makespan > 0 else 0\n",
        "#         mk = evaluator.parallel_makespan\n",
        "#         speedups.append(sp)\n",
        "#         parallel_throughputs.append(par_th)\n",
        "#         naive_throughputs.append(naive_thr)\n",
        "#         makespans.append(mk)\n",
        "#         config[ratio] = {'speedup': sp,\n",
        "#                          'parallel_throughput': par_th,\n",
        "#                          'naive_throughput': naive_thr,\n",
        "#                          'makespan': mk}\n",
        "#         print(f\"Speedup for ratio {ratio}: {sp:.2f}\")\n",
        "#         print(f\"Parallel Throughput for ratio {ratio}: {par_th:.2f}\")\n",
        "#         print(f\"Naive Throughput for ratio {ratio}: {naive_thr:.2f}\")\n",
        "#         print(f\"Makespan for ratio {ratio}: {mk:.2f}\\n\")\n",
        "#     print(\"Final Results:\")\n",
        "#     print(\"Speedups:\", speedups)\n",
        "#     print(\"Parallel Throughputs:\", parallel_throughputs)\n",
        "#     print(\"Naive Throughputs:\", naive_throughputs)\n",
        "#     print(\"Makespans:\", makespans)\n",
        "\n",
        "#     # Find the best configuration based on maximum speedup\n",
        "#     max_ratio = max(config, key=lambda r: config[r]['speedup'])\n",
        "#     best_config = config[max_ratio]\n",
        "\n",
        "#     print(f\"Best configuration: {best_config}\")\n",
        "#     print(f\"Max Speedup Ratio: {max_ratio}\\n\")\n",
        "\n",
        "#     # Plot results.\n",
        "#     plt.figure(figsize=(12, 4))\n",
        "#     plt.subplot(1, 3, 1)\n",
        "#     plt.plot(ratios, speedups, marker='o', linestyle='-', label='Speedup')\n",
        "#     plt.xlabel(\"Heavy Task Ratio\")\n",
        "#     plt.ylabel(\"Speedup (makespan)\")\n",
        "#     plt.title(\"Speedup vs Heavy Task Ratio\")\n",
        "#     plt.legend()\n",
        "#     plt.subplot(1, 3, 2)\n",
        "#     plt.plot(ratios, parallel_throughputs, marker='s', linestyle='-', label='Parallel Throughput')\n",
        "#     plt.plot(ratios, naive_throughputs, marker='^', linestyle='--', label='Naive Throughput', color='orange')\n",
        "#     plt.xlabel(\"Heavy Task Ratio\")\n",
        "#     plt.ylabel(\"Throughput (tasks/s)\")\n",
        "#     plt.title(\"Throughput Comparison\")\n",
        "#     plt.legend()\n",
        "#     plt.subplot(1, 3, 3)\n",
        "#     plt.plot(ratios, makespans, marker='d', linestyle='-', label='Makespan')\n",
        "#     plt.xlabel(\"Heavy Task Ratio\")\n",
        "#     plt.ylabel(\"Makespan (s)\")\n",
        "#     plt.title(\"Makespan vs Heavy Task Ratio\")\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     run_multiple_experiments(k=2, num_tasks=25)\n"
      ],
      "metadata": {
        "id": "V0MO8QT7hVvO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Multiple Experiments\n",
        "\n",
        "## run_multiple_experiments\n",
        "\n",
        "**Purpose:**  \n",
        "Executes a series of experiments across a range of heavy/light task ratios, collects performance metrics, saves results, and generates performance plots.\n",
        "\n",
        "**Key Steps:**\n",
        "- **Iteration Over Ratios:**  \n",
        "  - Iterates over heavy task ratios (e.g., 0.1 to 0.9) to determine the number of heavy and light tasks.\n",
        "- **Running Experiments:**  \n",
        "  - Clears previous profiling data.\n",
        "  - Runs `run_experiment` for each configuration.\n",
        "  - Collects metrics such as speedup, throughput, and makespan.\n",
        "- **Logging & Visualization:**  \n",
        "  - Saves the results to a CSV file.\n",
        "  - Identifies and prints the best configuration.\n",
        "  - Generates and saves plots (PDF) for speedup, throughput, and makespan versus heavy task ratio.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-t2pfy2eFe4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "def run_multiple_experiments(k: int, num_tasks: int = 15):\n",
        "    ratios = [round(i / 10, 1) for i in range(1, 10)]\n",
        "    speedups = []\n",
        "    parallel_throughputs = []\n",
        "    naive_throughputs = []\n",
        "    makespans = []\n",
        "    config = defaultdict(dict)\n",
        "    csv_filename = \"experiment_results.csv\"\n",
        "    pdf_filename = \"experiment_plots.pdf\"\n",
        "    profiling_file = \"profiling_results.csv\"\n",
        "\n",
        "\n",
        "\n",
        "    for ratio in ratios:\n",
        "        heavy_count = int(num_tasks * ratio)\n",
        "        light_count = num_tasks - heavy_count\n",
        "        print(f\"Running experiment with {heavy_count} heavy and {light_count} light tasks.\")\n",
        "\n",
        "        # Remove profiling results if exists\n",
        "        if os.path.exists(profiling_file):\n",
        "            os.remove(profiling_file)\n",
        "            print(\"The profiling file was removed.\")\n",
        "\n",
        "        evaluator = run_experiment(k=k, heavy_light_ratio=(heavy_count, light_count), num_tasks=num_tasks)\n",
        "        sp = evaluator.speedup_makespan\n",
        "        par_th = evaluator.throughput_makespan\n",
        "        naive_thr = num_tasks / evaluator.naive_makespan if evaluator.naive_makespan > 0 else 0\n",
        "        mk = evaluator.parallel_makespan\n",
        "\n",
        "        speedups.append(sp)\n",
        "        parallel_throughputs.append(par_th)\n",
        "        naive_throughputs.append(naive_thr)\n",
        "        makespans.append(mk)\n",
        "\n",
        "        config[ratio] = {\n",
        "            'speedup': sp,\n",
        "            'parallel_throughput': par_th,\n",
        "            'naive_throughput': naive_thr,\n",
        "            'makespan': mk\n",
        "        }\n",
        "\n",
        "        print(f\"Speedup for ratio {ratio}: {sp:.2f}\")\n",
        "        print(f\"Parallel Throughput for ratio {ratio}: {par_th:.2f}\")\n",
        "        print(f\"Naive Throughput for ratio {ratio}: {naive_thr:.2f}\")\n",
        "        print(f\"Makespan for ratio {ratio}: {mk:.2f}\\n\")\n",
        "\n",
        "    print(\"Final Results:\")\n",
        "    print(\"Speedups:\", speedups)\n",
        "    print(\"Parallel Throughputs:\", parallel_throughputs)\n",
        "    print(\"Naive Throughputs:\", naive_throughputs)\n",
        "    print(\"Makespans:\", makespans)\n",
        "\n",
        "    # Save results to CSV\n",
        "    with open(csv_filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Heavy Task Ratio\", \"Speedup\", \"Parallel Throughput\", \"Naive Throughput\", \"Makespan\"])\n",
        "        for i, ratio in enumerate(ratios):\n",
        "            writer.writerow([ratio, speedups[i], parallel_throughputs[i], naive_throughputs[i], makespans[i]])\n",
        "    print(f\"Experiment results saved to {csv_filename}\")\n",
        "\n",
        "    # Find the best configuration based on maximum speedup\n",
        "    max_ratio = max(config, key=lambda r: config[r]['speedup'])\n",
        "    best_config = config[max_ratio]\n",
        "\n",
        "    print(f\"Best configuration: {best_config}\")\n",
        "    print(f\"Max Speedup Ratio: {max_ratio}\\n\")\n",
        "\n",
        "    # Plot results\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "    axes[0].plot(ratios, speedups, marker='o', linestyle='-', label='Speedup')\n",
        "    axes[0].set_xlabel(\"Heavy Task Ratio\")\n",
        "    axes[0].set_ylabel(\"Speedup (makespan)\")\n",
        "    axes[0].set_title(\"Speedup vs Heavy Task Ratio\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].plot(ratios, parallel_throughputs, marker='s', linestyle='-', label='Parallel Throughput')\n",
        "    axes[1].plot(ratios, naive_throughputs, marker='^', linestyle='--', label='Naive Throughput', color='orange')\n",
        "    axes[1].set_xlabel(\"Heavy Task Ratio\")\n",
        "    axes[1].set_ylabel(\"Throughput (tasks/s)\")\n",
        "    axes[1].set_title(\"Throughput Comparison\")\n",
        "    axes[1].legend()\n",
        "\n",
        "    axes[2].plot(ratios, makespans, marker='d', linestyle='-', label='Makespan')\n",
        "    axes[2].set_xlabel(\"Heavy Task Ratio\")\n",
        "    axes[2].set_ylabel(\"Makespan (s)\")\n",
        "    axes[2].set_title(\"Makespan vs Heavy Task Ratio\")\n",
        "    axes[2].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(pdf_filename)\n",
        "    print(f\"Plots saved to {pdf_filename}\")\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_multiple_experiments(k=2, num_tasks=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HgL1kOk9HvIw",
        "outputId": "1483211b-5d41-4708-9edb-edb63cd7fcb1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running experiment with 0 heavy and 4 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 0 heavy tasks and 4 light tasks.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "Measured max transfer penalty: 0.000127 s\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "=== Stage Allocations for Task light_2 ===\n",
            "light_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_2-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_2-stage-1']\n",
            "=== Stage Allocations for Task light_3 ===\n",
            "light_3-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_3-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_3-stage-1']\n",
            "=== Stage Allocations for Task light_4 ===\n",
            "light_4-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_4-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_4-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0012s\n",
            "[Evaluator] Task light_2: Naive exec time: 0.0011s\n",
            "[Evaluator] Task light_3: Naive exec time: 0.0007s\n",
            "[Evaluator] Task light_4: Naive exec time: 0.0011s\n",
            "[Evaluator] Naive makespan: 0.0299s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task light_1\n",
            "[Taskset] Starting Task light_2\n",
            "[Taskset] Starting Task light_3\n",
            "[Taskset] Starting Task light_4\n",
            "[Stage] light_2-stage-1: Executed on GPU-0-CPU-1 in 0.0053 s, Transfer: 0.0000 s.\n",
            "[Stage] light_3-stage-1: Executed on GPU-0-CPU-1 in 0.0008 s, Transfer: 0.0000 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0011 s, Transfer: 0.0000 s.\n",
            "[Stage] light_4-stage-1: Executed on GPU-0-CPU-1 in 0.0012 s, Transfer: 0.0000 s.\n",
            "[Stage] light_2-stage-2: Executed on GPU-0-CPU-1 in 0.0009 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_2 in 0.03 s\n",
            "[Stage] light_3-stage-2: Executed on GPU-0-CPU-1 in 0.0006 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_3 in 0.02 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0010 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.03 s\n",
            "[Stage] light_4-stage-2: Executed on GPU-0-CPU-1 in 0.0022 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_4 in 0.03 s\n",
            "[Evaluator] Parallel makespan: 0.0480s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] Task light_2: Outputs match.\n",
            "[Evaluator] Task light_3: Outputs match.\n",
            "[Evaluator] Task light_4: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0041s, Parallel total: 0.1009s\n",
            "Speedup (sum-of-times): 0.04x\n",
            "Naive Throughput: 977.98 tasks/s, Parallel Throughput: 39.64 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.0299s, Parallel makespan: 0.0480s\n",
            "Speedup (makespan): 0.62x\n",
            "Naive Throughput (makespan): 133.69 tasks/s, Parallel Throughput (makespan): 83.25 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task light_1: Naive finish: 0.0184s, Parallel finish: 0.0449s\n",
            "Task light_2: Naive finish: 0.0210s, Parallel finish: 0.0385s\n",
            "Task light_3: Naive finish: 0.0272s, Parallel finish: 0.0408s\n",
            "Task light_4: Naive finish: 0.0298s, Parallel finish: 0.0475s\n",
            "\n",
            "Speedup for ratio 0.1: 0.62\n",
            "Parallel Throughput for ratio 0.1: 83.25\n",
            "Naive Throughput for ratio 0.1: 133.69\n",
            "Makespan for ratio 0.1: 0.05\n",
            "\n",
            "Running experiment with 0 heavy and 4 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 0 heavy tasks and 4 light tasks.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "Measured max transfer penalty: 0.000124 s\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=CPU-0, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=CPU-0, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "=== Stage Allocations for Task light_2 ===\n",
            "light_2-stage-1: Node=CPU-0, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_2-stage-2: Node=CPU-0, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_2-stage-1']\n",
            "=== Stage Allocations for Task light_3 ===\n",
            "light_3-stage-1: Node=CPU-0, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_3-stage-2: Node=CPU-0, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_3-stage-1']\n",
            "=== Stage Allocations for Task light_4 ===\n",
            "light_4-stage-1: Node=CPU-0, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_4-stage-2: Node=CPU-0, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_4-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0011s\n",
            "[Evaluator] Task light_2: Naive exec time: 0.0014s\n",
            "[Evaluator] Task light_3: Naive exec time: 0.0010s\n",
            "[Evaluator] Task light_4: Naive exec time: 0.0014s\n",
            "[Evaluator] Naive makespan: 0.0159s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task light_1\n",
            "[Taskset] Starting Task light_2\n",
            "[Taskset] Starting Task light_3\n",
            "[Taskset] Starting Task light_4\n",
            "[Stage] light_1-stage-1: Executed on CPU-0 in 0.0456 s, Transfer: 0.0000 s.\n",
            "[Stage] light_2-stage-1: Executed on CPU-0 in 0.0124 s, Transfer: 0.0000 s.\n",
            "[Stage] light_3-stage-1: Executed on CPU-0 in 0.0165 s, Transfer: 0.0000 s.\n",
            "[Stage] light_4-stage-1: Executed on CPU-0 in 0.0044 s, Transfer: 0.0000 s.\n",
            "[Stage] light_1-stage-2: Executed on CPU-0 in 0.0110 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.10 s\n",
            "[Stage] light_2-stage-2: Executed on CPU-0 in 0.0073 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_2 in 0.09 s\n",
            "[Stage] light_3-stage-2: Executed on CPU-0 in 0.0028 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_3 in 0.08 s\n",
            "[Stage] light_4-stage-2: Executed on CPU-0 in 0.0028 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_4 in 0.08 s\n",
            "[Evaluator] Parallel makespan: 0.1109s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] Task light_2: Outputs match.\n",
            "[Evaluator] Task light_3: Outputs match.\n",
            "[Evaluator] Task light_4: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0050s, Parallel total: 0.3461s\n",
            "Speedup (sum-of-times): 0.01x\n",
            "Naive Throughput: 806.44 tasks/s, Parallel Throughput: 11.56 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.0159s, Parallel makespan: 0.1109s\n",
            "Speedup (makespan): 0.14x\n",
            "Naive Throughput (makespan): 251.72 tasks/s, Parallel Throughput (makespan): 36.08 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task light_1: Naive finish: 0.0079s, Parallel finish: 0.0980s\n",
            "Task light_2: Naive finish: 0.0103s, Parallel finish: 0.1051s\n",
            "Task light_3: Naive finish: 0.0128s, Parallel finish: 0.1076s\n",
            "Task light_4: Naive finish: 0.0153s, Parallel finish: 0.1106s\n",
            "\n",
            "Speedup for ratio 0.2: 0.14\n",
            "Parallel Throughput for ratio 0.2: 36.08\n",
            "Naive Throughput for ratio 0.2: 251.72\n",
            "Makespan for ratio 0.2: 0.11\n",
            "\n",
            "Running experiment with 1 heavy and 3 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 1 heavy tasks and 3 light tasks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Starting profiling for Task 'heavy_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'heavy_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "Measured max transfer penalty: 0.001527 s\n",
            "=== Stage Allocations for Task heavy_1 ===\n",
            "heavy_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1'], Deps=[]\n",
            "heavy_1-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_1-stage-1']\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "=== Stage Allocations for Task light_2 ===\n",
            "light_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_2-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_2-stage-1']\n",
            "=== Stage Allocations for Task light_3 ===\n",
            "light_3-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_3-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_3-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task heavy_1: Naive exec time: 0.0205s\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0007s\n",
            "[Evaluator] Task light_2: Naive exec time: 0.0006s\n",
            "[Evaluator] Task light_3: Naive exec time: 0.0005s\n",
            "[Evaluator] Naive makespan: 0.0537s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task heavy_1\n",
            "[Taskset] Starting Task light_1\n",
            "[Taskset] Starting Task light_2\n",
            "[Taskset] Starting Task light_3\n",
            "[Stage] heavy_1-stage-1: Executed on GPU-0-CPU-1 in 0.0136 s, Transfer: 0.0002 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0021 s, Transfer: 0.0000 s.\n",
            "[Stage] light_2-stage-1: Executed on GPU-0-CPU-1 in 0.0008 s, Transfer: 0.0000 s.\n",
            "[Stage] light_3-stage-1: Executed on GPU-0-CPU-1 in 0.0006 s, Transfer: 0.0000 s.\n",
            "[Stage] heavy_1-stage-2: Executed on GPU-0-CPU-1 in 0.0124 s, Transfer: 0.0002 s.\n",
            "[Taskset] Completed Task heavy_1 in 0.03 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0020 s, Transfer: 0.0002 s.\n",
            "[Taskset] Completed Task light_1 in 0.03 s\n",
            "[Stage] light_2-stage-2: Executed on GPU-0-CPU-1 in 0.0012 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_2 in 0.03 s\n",
            "[Stage] light_3-stage-2: Executed on GPU-0-CPU-1 in 0.0012 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_3 in 0.04 s\n",
            "[Evaluator] Parallel makespan: 0.0402s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task heavy_1: Outputs match.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] Task light_2: Outputs match.\n",
            "[Evaluator] Task light_3: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0222s, Parallel total: 0.1359s\n",
            "Speedup (sum-of-times): 0.16x\n",
            "Naive Throughput: 180.51 tasks/s, Parallel Throughput: 29.43 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.0537s, Parallel makespan: 0.0402s\n",
            "Speedup (makespan): 1.34x\n",
            "Naive Throughput (makespan): 74.52 tasks/s, Parallel Throughput (makespan): 99.53 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task heavy_1: Naive finish: 0.0476s, Parallel finish: 0.0338s\n",
            "Task light_1: Naive finish: 0.0499s, Parallel finish: 0.0362s\n",
            "Task light_2: Naive finish: 0.0517s, Parallel finish: 0.0381s\n",
            "Task light_3: Naive finish: 0.0536s, Parallel finish: 0.0399s\n",
            "\n",
            "Speedup for ratio 0.3: 1.34\n",
            "Parallel Throughput for ratio 0.3: 99.53\n",
            "Naive Throughput for ratio 0.3: 74.52\n",
            "Makespan for ratio 0.3: 0.04\n",
            "\n",
            "Running experiment with 1 heavy and 3 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 1 heavy tasks and 3 light tasks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Starting profiling for Task 'heavy_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'heavy_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "Measured max transfer penalty: 0.001540 s\n",
            "=== Stage Allocations for Task heavy_1 ===\n",
            "heavy_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1'], Deps=[]\n",
            "heavy_1-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_1-stage-1']\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "=== Stage Allocations for Task light_2 ===\n",
            "light_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_2-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_2-stage-1']\n",
            "=== Stage Allocations for Task light_3 ===\n",
            "light_3-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_3-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_3-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task heavy_1: Naive exec time: 0.0163s\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0007s\n",
            "[Evaluator] Task light_2: Naive exec time: 0.0006s\n",
            "[Evaluator] Task light_3: Naive exec time: 0.0005s\n",
            "[Evaluator] Naive makespan: 0.0416s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task heavy_1\n",
            "[Taskset] Starting Task light_1\n",
            "[Taskset] Starting Task light_2\n",
            "[Taskset] Starting Task light_3\n",
            "[Stage] heavy_1-stage-1: Executed on GPU-0-CPU-1 in 0.0173 s, Transfer: 0.0002 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0020 s, Transfer: 0.0000 s.\n",
            "[Stage] light_2-stage-1: Executed on GPU-0-CPU-1 in 0.0006 s, Transfer: 0.0000 s.\n",
            "[Stage] light_3-stage-1: Executed on GPU-0-CPU-1 in 0.0011 s, Transfer: 0.0000 s.\n",
            "[Stage] heavy_1-stage-2: Executed on GPU-0-CPU-1 in 0.0107 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_1 in 0.03 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0014 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.03 s\n",
            "[Stage] light_2-stage-2: Executed on GPU-0-CPU-1 in 0.0013 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_2 in 0.03 s\n",
            "[Stage] light_3-stage-2: Executed on GPU-0-CPU-1 in 0.0017 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_3 in 0.04 s\n",
            "[Evaluator] Parallel makespan: 0.0420s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task heavy_1: Outputs match.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] Task light_2: Outputs match.\n",
            "[Evaluator] Task light_3: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0182s, Parallel total: 0.1402s\n",
            "Speedup (sum-of-times): 0.13x\n",
            "Naive Throughput: 220.37 tasks/s, Parallel Throughput: 28.54 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.0416s, Parallel makespan: 0.0420s\n",
            "Speedup (makespan): 0.99x\n",
            "Naive Throughput (makespan): 96.23 tasks/s, Parallel Throughput (makespan): 95.20 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task heavy_1: Naive finish: 0.0356s, Parallel finish: 0.0355s\n",
            "Task light_1: Naive finish: 0.0378s, Parallel finish: 0.0375s\n",
            "Task light_2: Naive finish: 0.0397s, Parallel finish: 0.0391s\n",
            "Task light_3: Naive finish: 0.0415s, Parallel finish: 0.0413s\n",
            "\n",
            "Speedup for ratio 0.4: 0.99\n",
            "Parallel Throughput for ratio 0.4: 95.20\n",
            "Naive Throughput for ratio 0.4: 96.23\n",
            "Makespan for ratio 0.4: 0.04\n",
            "\n",
            "Running experiment with 2 heavy and 2 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 2 heavy tasks and 2 light tasks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Starting profiling for Task 'heavy_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'heavy_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on CPU-0.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "Measured max transfer penalty: 0.001511 s\n",
            "=== Stage Allocations for Task heavy_1 ===\n",
            "heavy_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1'], Deps=[]\n",
            "heavy_1-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_1-stage-1']\n",
            "=== Stage Allocations for Task heavy_2 ===\n",
            "heavy_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1'], Deps=[]\n",
            "heavy_2-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_2-stage-1']\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "=== Stage Allocations for Task light_2 ===\n",
            "light_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_2-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_2-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task heavy_1: Naive exec time: 0.0163s\n",
            "[Evaluator] Task heavy_2: Naive exec time: 0.0163s\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0007s\n",
            "[Evaluator] Task light_2: Naive exec time: 0.0006s\n",
            "[Evaluator] Naive makespan: 0.0753s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task heavy_1\n",
            "[Taskset] Starting Task heavy_2\n",
            "[Taskset] Starting Task light_1\n",
            "[Taskset] Starting Task light_2\n",
            "[Stage] heavy_1-stage-1: Executed on GPU-0-CPU-1 in 0.0138 s, Transfer: 0.0002 s.\n",
            "[Stage] heavy_2-stage-1: Executed on GPU-0-CPU-1 in 0.0113 s, Transfer: 0.0001 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0030 s, Transfer: 0.0000 s.\n",
            "[Stage] light_2-stage-1: Executed on GPU-0-CPU-1 in 0.0006 s, Transfer: 0.0000 s.\n",
            "[Stage] heavy_1-stage-2: Executed on GPU-0-CPU-1 in 0.0120 s, Transfer: 0.0002 s.\n",
            "[Taskset] Completed Task heavy_1 in 0.04 s\n",
            "[Stage] heavy_2-stage-2: Executed on GPU-0-CPU-1 in 0.0082 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_2 in 0.05 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0018 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.05 s\n",
            "[Stage] light_2-stage-2: Executed on GPU-0-CPU-1 in 0.0013 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_2 in 0.05 s\n",
            "[Evaluator] Parallel makespan: 0.0580s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task heavy_1: Outputs match.\n",
            "[Evaluator] Task heavy_2: Outputs match.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] Task light_2: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0339s, Parallel total: 0.2027s\n",
            "Speedup (sum-of-times): 0.17x\n",
            "Naive Throughput: 118.11 tasks/s, Parallel Throughput: 19.74 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.0753s, Parallel makespan: 0.0580s\n",
            "Speedup (makespan): 1.30x\n",
            "Naive Throughput (makespan): 53.12 tasks/s, Parallel Throughput (makespan): 68.92 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task heavy_1: Naive finish: 0.0368s, Parallel finish: 0.0448s\n",
            "Task heavy_2: Naive finish: 0.0713s, Parallel finish: 0.0532s\n",
            "Task light_1: Naive finish: 0.0734s, Parallel finish: 0.0556s\n",
            "Task light_2: Naive finish: 0.0752s, Parallel finish: 0.0573s\n",
            "\n",
            "Speedup for ratio 0.5: 1.30\n",
            "Parallel Throughput for ratio 0.5: 68.92\n",
            "Naive Throughput for ratio 0.5: 53.12\n",
            "Makespan for ratio 0.5: 0.06\n",
            "\n",
            "Running experiment with 2 heavy and 2 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 2 heavy tasks and 2 light tasks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Starting profiling for Task 'heavy_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'heavy_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on CPU-0.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "Measured max transfer penalty: 0.001518 s\n",
            "=== Stage Allocations for Task heavy_1 ===\n",
            "heavy_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1'], Deps=[]\n",
            "heavy_1-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_1-stage-1']\n",
            "=== Stage Allocations for Task heavy_2 ===\n",
            "heavy_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1'], Deps=[]\n",
            "heavy_2-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_2-stage-1']\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "=== Stage Allocations for Task light_2 ===\n",
            "light_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_2-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_2-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task heavy_1: Naive exec time: 0.0163s\n",
            "[Evaluator] Task heavy_2: Naive exec time: 0.0163s\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0006s\n",
            "[Evaluator] Task light_2: Naive exec time: 0.0005s\n",
            "[Evaluator] Naive makespan: 0.0764s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task heavy_1\n",
            "[Taskset] Starting Task heavy_2\n",
            "[Taskset] Starting Task light_1\n",
            "[Taskset] Starting Task light_2\n",
            "[Stage] heavy_1-stage-1: Executed on GPU-0-CPU-1 in 0.0169 s, Transfer: 0.0002 s.\n",
            "[Stage] heavy_2-stage-1: Executed on GPU-0-CPU-1 in 0.0116 s, Transfer: 0.0001 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0026 s, Transfer: 0.0000 s.\n",
            "[Stage] light_2-stage-1: Executed on GPU-0-CPU-1 in 0.0006 s, Transfer: 0.0000 s.\n",
            "[Stage] heavy_1-stage-2: Executed on GPU-0-CPU-1 in 0.0105 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_1 in 0.05 s\n",
            "[Stage] heavy_2-stage-2: Executed on GPU-0-CPU-1 in 0.0075 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_2 in 0.05 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0017 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.05 s\n",
            "[Stage] light_2-stage-2: Executed on GPU-0-CPU-1 in 0.0012 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_2 in 0.05 s\n",
            "[Evaluator] Parallel makespan: 0.0590s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task heavy_1: Outputs match.\n",
            "[Evaluator] Task heavy_2: Outputs match.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] Task light_2: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0337s, Parallel total: 0.1997s\n",
            "Speedup (sum-of-times): 0.17x\n",
            "Naive Throughput: 118.57 tasks/s, Parallel Throughput: 20.03 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.0764s, Parallel makespan: 0.0590s\n",
            "Speedup (makespan): 1.30x\n",
            "Naive Throughput (makespan): 52.35 tasks/s, Parallel Throughput (makespan): 67.85 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task heavy_1: Naive finish: 0.0385s, Parallel finish: 0.0466s\n",
            "Task heavy_2: Naive finish: 0.0725s, Parallel finish: 0.0545s\n",
            "Task light_1: Naive finish: 0.0745s, Parallel finish: 0.0565s\n",
            "Task light_2: Naive finish: 0.0763s, Parallel finish: 0.0583s\n",
            "\n",
            "Speedup for ratio 0.6: 1.30\n",
            "Parallel Throughput for ratio 0.6: 67.85\n",
            "Naive Throughput for ratio 0.6: 52.35\n",
            "Makespan for ratio 0.6: 0.06\n",
            "\n",
            "Running experiment with 2 heavy and 2 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 2 heavy tasks and 2 light tasks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Starting profiling for Task 'heavy_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'heavy_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on CPU-0.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for SimpleCNN on CPU-0.\n",
            "Measured max transfer penalty: 0.001533 s\n",
            "=== Stage Allocations for Task heavy_1 ===\n",
            "heavy_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1'], Deps=[]\n",
            "heavy_1-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_1-stage-1']\n",
            "=== Stage Allocations for Task heavy_2 ===\n",
            "heavy_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1'], Deps=[]\n",
            "heavy_2-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_2-stage-1']\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "=== Stage Allocations for Task light_2 ===\n",
            "light_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_2-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_2-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task heavy_1: Naive exec time: 0.0164s\n",
            "[Evaluator] Task heavy_2: Naive exec time: 0.0163s\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0006s\n",
            "[Evaluator] Task light_2: Naive exec time: 0.0006s\n",
            "[Evaluator] Naive makespan: 0.0785s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task heavy_1\n",
            "[Taskset] Starting Task heavy_2\n",
            "[Taskset] Starting Task light_1[Taskset] Starting Task light_2\n",
            "\n",
            "[Stage] heavy_1-stage-1: Executed on GPU-0-CPU-1 in 0.0132 s, Transfer: 0.0002 s.\n",
            "[Stage] heavy_2-stage-1: Executed on GPU-0-CPU-1 in 0.0110 s, Transfer: 0.0001 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0024 s, Transfer: 0.0000 s.\n",
            "[Stage] light_2-stage-1: Executed on GPU-0-CPU-1 in 0.0006 s, Transfer: 0.0000 s.\n",
            "[Stage] heavy_1-stage-2: Executed on GPU-0-CPU-1 in 0.0113 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_1 in 0.04 s\n",
            "[Stage] heavy_2-stage-2: Executed on GPU-0-CPU-1 in 0.0079 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_2 in 0.05 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0015 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.05 s\n",
            "[Stage] light_2-stage-2: Executed on GPU-0-CPU-1 in 0.0012 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_2 in 0.05 s\n",
            "[Evaluator] Parallel makespan: 0.0563s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task heavy_1: Outputs match.\n",
            "[Evaluator] Task heavy_2: Outputs match.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] Task light_2: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0339s, Parallel total: 0.1886s\n",
            "Speedup (sum-of-times): 0.18x\n",
            "Naive Throughput: 117.85 tasks/s, Parallel Throughput: 21.21 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.0785s, Parallel makespan: 0.0563s\n",
            "Speedup (makespan): 1.39x\n",
            "Naive Throughput (makespan): 50.97 tasks/s, Parallel Throughput (makespan): 71.07 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task heavy_1: Naive finish: 0.0407s, Parallel finish: 0.0434s\n",
            "Task heavy_2: Naive finish: 0.0743s, Parallel finish: 0.0519s\n",
            "Task light_1: Naive finish: 0.0765s, Parallel finish: 0.0538s\n",
            "Task light_2: Naive finish: 0.0784s, Parallel finish: 0.0556s\n",
            "\n",
            "Speedup for ratio 0.7: 1.39\n",
            "Parallel Throughput for ratio 0.7: 71.07\n",
            "Naive Throughput for ratio 0.7: 50.97\n",
            "Makespan for ratio 0.7: 0.06\n",
            "\n",
            "Running experiment with 3 heavy and 1 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 3 heavy tasks and 1 light tasks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Starting profiling for Task 'heavy_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'heavy_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on CPU-0.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on CPU-0.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "Measured max transfer penalty: 0.001534 s\n",
            "=== Stage Allocations for Task heavy_1 ===\n",
            "heavy_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu'], Deps=[]\n",
            "heavy_1-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_1-stage-1']\n",
            "=== Stage Allocations for Task heavy_2 ===\n",
            "heavy_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu'], Deps=[]\n",
            "heavy_2-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_2-stage-1']\n",
            "=== Stage Allocations for Task heavy_3 ===\n",
            "heavy_3-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu'], Deps=[]\n",
            "heavy_3-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1', 'resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_3-stage-1']\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task heavy_1: Naive exec time: 0.0163s\n",
            "[Evaluator] Task heavy_2: Naive exec time: 0.0162s\n",
            "[Evaluator] Task heavy_3: Naive exec time: 0.0162s\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0007s\n",
            "[Evaluator] Naive makespan: 0.1082s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task heavy_1\n",
            "[Taskset] Starting Task heavy_2\n",
            "[Taskset] Starting Task heavy_3\n",
            "[Taskset] Starting Task light_1\n",
            "[Stage] heavy_1-stage-1: Executed on GPU-0-CPU-1 in 0.0118 s, Transfer: 0.0001 s.\n",
            "[Stage] heavy_2-stage-1: Executed on GPU-0-CPU-1 in 0.0102 s, Transfer: 0.0001 s.\n",
            "[Stage] heavy_3-stage-1: Executed on GPU-0-CPU-1 in 0.0104 s, Transfer: 0.0001 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0021 s, Transfer: 0.0000 s.\n",
            "[Stage] heavy_1-stage-2: Executed on GPU-0-CPU-1 in 0.0117 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_1 in 0.05 s\n",
            "[Stage] heavy_2-stage-2: Executed on GPU-0-CPU-1 in 0.0087 s, Transfer: 0.0002 s.\n",
            "[Taskset] Completed Task heavy_2 in 0.06 s\n",
            "[Stage] heavy_3-stage-2: Executed on GPU-0-CPU-1 in 0.0086 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_3 in 0.07 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0016 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.07 s\n",
            "[Evaluator] Parallel makespan: 0.0734s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task heavy_1: Outputs match.\n",
            "[Evaluator] Task heavy_2: Outputs match.\n",
            "[Evaluator] Task heavy_3: Outputs match.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0494s, Parallel total: 0.2483s\n",
            "Speedup (sum-of-times): 0.20x\n",
            "Naive Throughput: 80.97 tasks/s, Parallel Throughput: 16.11 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.1082s, Parallel makespan: 0.0734s\n",
            "Speedup (makespan): 1.47x\n",
            "Naive Throughput (makespan): 36.98 tasks/s, Parallel Throughput (makespan): 54.50 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task heavy_1: Naive finish: 0.0393s, Parallel finish: 0.0523s\n",
            "Task heavy_2: Naive finish: 0.0720s, Parallel finish: 0.0617s\n",
            "Task heavy_3: Naive finish: 0.1060s, Parallel finish: 0.0705s\n",
            "Task light_1: Naive finish: 0.1081s, Parallel finish: 0.0727s\n",
            "\n",
            "Speedup for ratio 0.8: 1.47\n",
            "Parallel Throughput for ratio 0.8: 54.50\n",
            "Naive Throughput for ratio 0.8: 36.98\n",
            "Makespan for ratio 0.8: 0.07\n",
            "\n",
            "Running experiment with 3 heavy and 1 light tasks.\n",
            "The profiling file was removed.\n",
            "Seed set to 42\n",
            "Using 2 nodes: [Node(GPU-0-CPU-1, cpus=(1,), gpu=0), Node(CPU-0, cpus=(0,), gpu=None)]\n",
            "Creating 3 heavy tasks and 1 light tasks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Starting profiling for Task 'heavy_1' on GPU-0-CPU-1 (device=cuda:0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae95a043dc47>:202: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'heavy_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on CPU-0.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on GPU-0-CPU-1.\n",
            "[Profiler] Reused cached profiling data for PretrainedResNet18 on CPU-0.\n",
            "[Profiler] Starting profiling for Task 'light_1' on GPU-0-CPU-1 (device=cuda:0).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "[Profiler] Starting profiling for Task 'light_1' on CPU-0 (device=cpu).\n",
            "[Profiler] Profiling complete. Data saved to profiling_results.csv.\n",
            "Measured max transfer penalty: 0.001558 s\n",
            "=== Stage Allocations for Task heavy_1 ===\n",
            "heavy_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1'], Deps=[]\n",
            "heavy_1-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_1-stage-1']\n",
            "=== Stage Allocations for Task heavy_2 ===\n",
            "heavy_2-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1'], Deps=[]\n",
            "heavy_2-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_2-stage-1']\n",
            "=== Stage Allocations for Task heavy_3 ===\n",
            "heavy_3-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'resnet18_conv1', 'resnet18_bn1', 'resnet18_relu', 'resnet18_maxpool', 'resnet18_layer1_0_conv1', 'resnet18_layer1_0_bn1', 'resnet18_layer1_0_relu', 'resnet18_layer1_0_conv2', 'resnet18_layer1_0_bn2', 'add', 'resnet18_layer1_0_relu_1', 'resnet18_layer1_1_conv1', 'resnet18_layer1_1_bn1', 'resnet18_layer1_1_relu', 'resnet18_layer1_1_conv2', 'resnet18_layer1_1_bn2', 'add_1', 'resnet18_layer1_1_relu_1', 'resnet18_layer2_0_conv1', 'resnet18_layer2_0_bn1', 'resnet18_layer2_0_relu', 'resnet18_layer2_0_conv2', 'resnet18_layer2_0_bn2', 'resnet18_layer2_0_downsample_0', 'resnet18_layer2_0_downsample_1', 'add_2', 'resnet18_layer2_0_relu_1', 'resnet18_layer2_1_conv1', 'resnet18_layer2_1_bn1', 'resnet18_layer2_1_relu', 'resnet18_layer2_1_conv2', 'resnet18_layer2_1_bn2', 'add_3', 'resnet18_layer2_1_relu_1', 'resnet18_layer3_0_conv1'], Deps=[]\n",
            "heavy_3-stage-2: Node=GPU-0-CPU-1, Layers=['resnet18_layer3_0_bn1', 'resnet18_layer3_0_relu', 'resnet18_layer3_0_conv2', 'resnet18_layer3_0_bn2', 'resnet18_layer3_0_downsample_0', 'resnet18_layer3_0_downsample_1', 'add_4', 'resnet18_layer3_0_relu_1', 'resnet18_layer3_1_conv1', 'resnet18_layer3_1_bn1', 'resnet18_layer3_1_relu', 'resnet18_layer3_1_conv2', 'resnet18_layer3_1_bn2', 'add_5', 'resnet18_layer3_1_relu_1', 'resnet18_layer4_0_conv1', 'resnet18_layer4_0_bn1', 'resnet18_layer4_0_relu', 'resnet18_layer4_0_conv2', 'resnet18_layer4_0_bn2', 'resnet18_layer4_0_downsample_0', 'resnet18_layer4_0_downsample_1', 'add_6', 'resnet18_layer4_0_relu_1', 'resnet18_layer4_1_conv1', 'resnet18_layer4_1_bn1', 'resnet18_layer4_1_relu', 'resnet18_layer4_1_conv2', 'resnet18_layer4_1_bn2', 'add_7', 'resnet18_layer4_1_relu_1', 'resnet18_avgpool', 'flatten', 'resnet18_fc', 'output'], Deps=['heavy_3-stage-1']\n",
            "=== Stage Allocations for Task light_1 ===\n",
            "light_1-stage-1: Node=GPU-0-CPU-1, Layers=['x', 'conv1', 'relu', 'conv2'], Deps=[]\n",
            "light_1-stage-2: Node=GPU-0-CPU-1, Layers=['relu_1', 'cat', 'flatten', 'fc', 'output'], Deps=['light_1-stage-1']\n",
            "[Evaluator] Starting Naive Execution.\n",
            "Running on cuda\n",
            "[Evaluator] Task heavy_1: Naive exec time: 0.0163s\n",
            "[Evaluator] Task heavy_2: Naive exec time: 0.0162s\n",
            "[Evaluator] Task heavy_3: Naive exec time: 0.0163s\n",
            "[Evaluator] Task light_1: Naive exec time: 0.0009s\n",
            "[Evaluator] Naive makespan: 0.1135s\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Taskset] Starting Task heavy_1[Taskset] Starting Task heavy_2\n",
            "\n",
            "[Taskset] Starting Task heavy_3\n",
            "[Taskset] Starting Task light_1\n",
            "[Stage] heavy_1-stage-1: Executed on GPU-0-CPU-1 in 0.0210 s, Transfer: 0.0002 s.\n",
            "[Stage] heavy_2-stage-1: Executed on GPU-0-CPU-1 in 0.0116 s, Transfer: 0.0001 s.\n",
            "[Stage] heavy_3-stage-1: Executed on GPU-0-CPU-1 in 0.0116 s, Transfer: 0.0001 s.\n",
            "[Stage] light_1-stage-1: Executed on GPU-0-CPU-1 in 0.0028 s, Transfer: 0.0000 s.\n",
            "[Stage] heavy_1-stage-2: Executed on GPU-0-CPU-1 in 0.0106 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_1 in 0.06 s\n",
            "[Stage] heavy_2-stage-2: Executed on GPU-0-CPU-1 in 0.0077 s, Transfer: 0.0001 s.\n",
            "[Taskset] Completed Task heavy_2 in 0.07 s\n",
            "[Stage] heavy_3-stage-2: Executed on GPU-0-CPU-1 in 0.0084 s, Transfer: 0.0002 s.\n",
            "[Taskset] Completed Task heavy_3 in 0.08 s\n",
            "[Stage] light_1-stage-2: Executed on GPU-0-CPU-1 in 0.0013 s, Transfer: 0.0000 s.\n",
            "[Taskset] Completed Task light_1 in 0.07 s\n",
            "[Evaluator] Parallel makespan: 0.0847s\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] Task heavy_1: Outputs match.\n",
            "[Evaluator] Task heavy_2: Outputs match.\n",
            "[Evaluator] Task heavy_3: Outputs match.\n",
            "[Evaluator] Task light_1: Outputs match.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup and Throughput.\n",
            "\n",
            "--- Sum-of-times ---\n",
            "Naive total: 0.0497s, Parallel total: 0.2808s\n",
            "Speedup (sum-of-times): 0.18x\n",
            "Naive Throughput: 80.52 tasks/s, Parallel Throughput: 14.25 tasks/s\n",
            "\n",
            "--- Makespan ---\n",
            "Naive makespan: 0.1135s, Parallel makespan: 0.0847s\n",
            "Speedup (makespan): 1.34x\n",
            "Naive Throughput (makespan): 35.24 tasks/s, Parallel Throughput (makespan): 47.22 tasks/s\n",
            "\n",
            "--- Task Completion Times ---\n",
            "Task heavy_1: Naive finish: 0.0399s, Parallel finish: 0.0652s\n",
            "Task heavy_2: Naive finish: 0.0729s, Parallel finish: 0.0738s\n",
            "Task heavy_3: Naive finish: 0.1083s, Parallel finish: 0.0826s\n",
            "Task light_1: Naive finish: 0.1108s, Parallel finish: 0.0846s\n",
            "\n",
            "Speedup for ratio 0.9: 1.34\n",
            "Parallel Throughput for ratio 0.9: 47.22\n",
            "Naive Throughput for ratio 0.9: 35.24\n",
            "Makespan for ratio 0.9: 0.08\n",
            "\n",
            "Final Results:\n",
            "Speedups: [0.6226771794197477, 0.1433404232897541, 1.3356707244726038, 0.9892305946436677, 1.2974821606832552, 1.2961454621926904, 1.3943279535730928, 1.4738693728519545, 1.3398640566289985]\n",
            "Parallel Throughputs: [83.24798420109857, 36.08181910072971, 99.53024370565483, 95.1952791647753, 68.92206570455545, 67.85060683390829, 71.06881857076291, 54.500146180783396, 47.22052379008993]\n",
            "Naive Throughputs: [133.6936488963264, 251.72117029257313, 74.5170511579153, 96.23163666815799, 53.119856128319356, 52.34798779384325, 50.969944616431576, 36.9775959692581, 35.242772247278104]\n",
            "Makespans: [0.048049211502075195, 0.11085915565490723, 0.04018878936767578, 0.042018890380859375, 0.05803656578063965, 0.058953046798706055, 0.05628347396850586, 0.0733942985534668, 0.08470892906188965]\n",
            "Experiment results saved to experiment_results.csv\n",
            "Best configuration: {'speedup': 1.4738693728519545, 'parallel_throughput': 54.500146180783396, 'naive_throughput': 36.9775959692581, 'makespan': 0.0733942985534668}\n",
            "Max Speedup Ratio: 0.8\n",
            "\n",
            "Plots saved to experiment_plots.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}