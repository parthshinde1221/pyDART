{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyDart Library â€“ Second Testing Checkpoint\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this iteration, I addressed retrieval issues from the previous checkpoint and began exploring DAG-based approaches for more accurate task execution representation.\n",
        "\n",
        "## Main Contributions\n",
        "\n",
        "1. **Retrieval Problem Resolution**  \n",
        "   - Fixed missing input errors identified in the last iteration.  \n",
        "   - Ensured proper retrieval of necessary data before execution.  \n",
        "\n",
        "2. **Validation of Output Generation**  \n",
        "   - Verified whether retrieval was functioning correctly.  \n",
        "   - Checked if outputs were being generated or missing due to errors in execution stages.  \n",
        "   - Identified that, in most cases, errors in running stages prevented output generation.  \n",
        "\n",
        "3. **Shift Towards DAG-Based Approaches**  \n",
        "   - Realized that simply splitting the forward pass was insufficient.  \n",
        "   - Began investigating DAG-based execution to better represent real DNN task execution.  \n",
        "\n",
        "## Iterative Development Process\n",
        "\n",
        "As with previous phases, this checkpoint involved multiple iterations while developing the required classes. The earlier formats of the classes was maintained throughput the process.\n",
        "\n",
        "---\n",
        "\n",
        "**Note**: Multiple iterations were performed during the development of these classes. The key checkpoints included here highlight the most significant developments. Subsequent iterations followed a similar approach.\n"
      ],
      "metadata": {
        "id": "NO1VQ75cS_mz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GfSILGzueLvo",
        "outputId": "98ebc67a-768a-47f7-821f-0d42bba2e472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Main] Discovered Nodes: [Node(CPU-0, cpus=(0,), gpu=None), Node(CPU-1, cpus=(1,), gpu=None), Node(GPU-0-CPU-0, cpus=(0,), gpu=0), Node(GPU-0-CPU-1, cpus=(1,), gpu=0)]\n",
            "\n",
            "[Main] Initialized Profiler.\n",
            "\n",
            "[Main] Initialized Scheduler.\n",
            "\n",
            "[Main] Created 5 Tasks.\n",
            "\n",
            "[Main] Initialized Taskset.\n",
            "\n",
            "[Main] Initialized Evaluator.\n",
            "\n",
            "[Utility] Starting Init Phase.\n",
            "[Utility] Init Phase Run 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:322: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)  # Fixed FutureWarning by checking non-empty\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Utility] Init Phase Run 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Utility] Init Phase Run 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
            "<ipython-input-1-a05ba3532947>:265: FutureWarning: `self_cuda_memory_usage` is deprecated. Use `self_device_memory_usage` instead.\n",
            "  aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Utility] Completed Init Phase after 3 runs.\n",
            "\n",
            "ProfileDB:\n",
            "     Model        Layer     Compute  Self CPU (us)  CPU Total (us) CUDA Total (us) Self CPU Mem (bytes) Self CUDA Mem (bytes)  Total Execution Time (us) Total Memory Used (bytes)\n",
            "SimpleCNN forward_pass       CPU-0     353908.825      371084.675               0                    0                     0               3.710847e+11                         0\n",
            "SimpleCNN         misc       CPU-0     353436.028      370611.878               0                    0                     0               3.706119e+11                         0\n",
            "SimpleCNN        conv1       CPU-0       8148.621        8148.621               0                    0                     0               8.148621e+09                         0\n",
            "SimpleCNN        relu1       CPU-0         76.311          76.311               0                    0                     0               7.631100e+07                         0\n",
            "SimpleCNN        conv2       CPU-0         77.788          77.788               0                    0                     0               7.778800e+07                         0\n",
            "SimpleCNN        relu2       CPU-0         65.241          65.241               0                    0                     0               6.524100e+07                         0\n",
            "SimpleCNN          fc1       CPU-0         73.395          73.395               0                    0                     0               7.339500e+07                         0\n",
            "SimpleCNN        relu3       CPU-0         48.062          48.062               0                    0                     0               4.806200e+07                         0\n",
            "SimpleCNN          fc2       CPU-0       1948.797        1948.797               0                    0                     0               1.948797e+09                         0\n",
            "SimpleCNN forward_pass       CPU-1      13055.853       26583.414               0                    0                     0               2.658341e+10                         0\n",
            "SimpleCNN         misc       CPU-1      12668.873       26196.434               0                    0                     0               2.619643e+10                         0\n",
            "SimpleCNN        conv1       CPU-1        107.784         107.784               0                    0                     0               1.077840e+08                         0\n",
            "SimpleCNN        relu1       CPU-1       5109.282        5109.282               0                    0                     0               5.109282e+09                         0\n",
            "SimpleCNN        conv2       CPU-1       2041.370        2041.370               0                    0                     0               2.041370e+09                         0\n",
            "SimpleCNN        relu2       CPU-1         69.005          69.005               0                    0                     0               6.900500e+07                         0\n",
            "SimpleCNN          fc1       CPU-1         76.428          76.428               0                    0                     0               7.642800e+07                         0\n",
            "SimpleCNN        relu3       CPU-1         95.007          95.007               0                    0                     0               9.500700e+07                         0\n",
            "SimpleCNN          fc2       CPU-1         50.758          50.758               0                    0                     0               5.075800e+07                         0\n",
            "SimpleCNN forward_pass GPU-0-CPU-0      14128.845       46451.068         291.254                    0                     0               4.674232e+10                         0\n",
            "SimpleCNN         misc GPU-0-CPU-0      13783.794       46106.017         291.254                    0                     0               4.639727e+10                         0\n",
            "SimpleCNN        conv1 GPU-0-CPU-0       2180.664        2180.664               0                    0                     0               2.180664e+09                         0\n",
            "SimpleCNN        relu1 GPU-0-CPU-0         66.975          66.975               0                    0                     0               6.697500e+07                         0\n",
            "SimpleCNN        conv2 GPU-0-CPU-0         83.587          83.587               0                    0                     0               8.358700e+07                         0\n",
            "SimpleCNN        relu2 GPU-0-CPU-0         66.555          66.555               0                    0                     0               6.655500e+07                         0\n",
            "SimpleCNN          fc1 GPU-0-CPU-0       4103.650        4103.650               0                    0                     0               4.103650e+09                         0\n",
            "SimpleCNN        relu3 GPU-0-CPU-0         75.966          75.966               0                    0                     0               7.596600e+07                         0\n",
            "SimpleCNN          fc2 GPU-0-CPU-0         68.391          68.391               0                    0                     0               6.839100e+07                         0\n",
            "SimpleCNN forward_pass GPU-0-CPU-1      20480.918       74685.988         291.616                    0                     0               7.497760e+10                         0\n",
            "SimpleCNN         misc GPU-0-CPU-1      19278.306       73483.376         291.616                    0                     0               7.377499e+10                         0\n",
            "SimpleCNN        conv1 GPU-0-CPU-1        902.846         902.846               0                    0                     0               9.028460e+08                         0\n",
            "SimpleCNN        relu1 GPU-0-CPU-1         87.053          87.053               0                    0                     0               8.705300e+07                         0\n",
            "SimpleCNN        conv2 GPU-0-CPU-1         82.648          82.648               0                    0                     0               8.264800e+07                         0\n",
            "SimpleCNN        relu2 GPU-0-CPU-1         72.625          72.625               0                    0                     0               7.262500e+07                         0\n",
            "SimpleCNN          fc1 GPU-0-CPU-1         74.772          74.772               0                    0                     0               7.477200e+07                         0\n",
            "SimpleCNN        relu3 GPU-0-CPU-1         60.798          60.798               0                    0                     0               6.079800e+07                         0\n",
            "SimpleCNN          fc2 GPU-0-CPU-1         76.578          76.578               0                    0                     0               7.657800e+07                         0\n",
            "[Utility] Observation window set to 1168595.501700 seconds (Total Forward Time: 1062359.547000 + 10.0% slack).\n",
            "\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task1'.\n",
            "[Scheduler] Created Stage 'task1-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task1-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task1-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task1-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task1-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task1-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task1-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task1'. Nodes: 7, Edges: 0.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task1':\n",
            "  - Grouped Stages 'task1-stage-0_conv1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task1-stage-1_relu1, task1-stage-2_conv2, task1-stage-3_relu2' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task1-stage-4_fc1, task1-stage-5_relu3, task1-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-4_fc1' to Node 'GPU-0-CPU-1'.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-1_relu1' to Node 'GPU-0-CPU-0'.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-2_conv2' to Node 'GPU-0-CPU-0'.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-0_conv1' to Node 'CPU-1'.\n",
            "['relu1', 'task1-stage-3_relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task1-stage-3_relu2' on Node 'GPU-0-CPU-0'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task1-stage-1_relu1, task1-stage-2_conv2, task1-stage-3_relu2' into 'task1-stage-1_relu1_to_task1-stage-3_relu2' and allocated to Node 'GPU-0-CPU-0'.\n",
            "['fc1', 'task1-stage-6_fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task1-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task1-stage-4_fc1, task1-stage-5_relu3, task1-stage-6_fc2' into 'task1-stage-4_fc1_to_task1-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task1'. Nodes: 3, Edges: 0.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task1'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task2'.\n",
            "[Scheduler] Created Stage 'task2-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task2-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task2-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task2-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task2-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task2-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task2-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task2'. Nodes: 7, Edges: 0.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task2':\n",
            "  - Grouped Stages 'task2-stage-0_conv1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task2-stage-1_relu1, task2-stage-2_conv2, task2-stage-3_relu2' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task2-stage-4_fc1, task2-stage-5_relu3, task2-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-4_fc1' to Node 'GPU-0-CPU-1'.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-1_relu1' to Node 'GPU-0-CPU-0'.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-2_conv2' to Node 'GPU-0-CPU-0'.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-0_conv1' to Node 'CPU-1'.\n",
            "['relu1', 'task2-stage-3_relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task2-stage-3_relu2' on Node 'GPU-0-CPU-0'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task2-stage-1_relu1, task2-stage-2_conv2, task2-stage-3_relu2' into 'task2-stage-1_relu1_to_task2-stage-3_relu2' and allocated to Node 'GPU-0-CPU-0'.\n",
            "['fc1', 'task2-stage-6_fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task2-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task2-stage-4_fc1, task2-stage-5_relu3, task2-stage-6_fc2' into 'task2-stage-4_fc1_to_task2-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task2'. Nodes: 3, Edges: 0.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task2'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task3'.\n",
            "[Scheduler] Created Stage 'task3-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task3-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task3-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task3-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task3-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task3-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task3-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task3'. Nodes: 7, Edges: 0.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task3':\n",
            "  - Grouped Stages 'task3-stage-0_conv1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task3-stage-1_relu1, task3-stage-2_conv2, task3-stage-3_relu2' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task3-stage-4_fc1, task3-stage-5_relu3, task3-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-4_fc1' to Node 'GPU-0-CPU-1'.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-1_relu1' to Node 'GPU-0-CPU-0'.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-2_conv2' to Node 'GPU-0-CPU-0'.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-0_conv1' to Node 'CPU-1'.\n",
            "['relu1', 'task3-stage-3_relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task3-stage-3_relu2' on Node 'GPU-0-CPU-0'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task3-stage-1_relu1, task3-stage-2_conv2, task3-stage-3_relu2' into 'task3-stage-1_relu1_to_task3-stage-3_relu2' and allocated to Node 'GPU-0-CPU-0'.\n",
            "['fc1', 'task3-stage-6_fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task3-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task3-stage-4_fc1, task3-stage-5_relu3, task3-stage-6_fc2' into 'task3-stage-4_fc1_to_task3-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task3'. Nodes: 3, Edges: 0.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task3'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task4'.\n",
            "[Scheduler] Created Stage 'task4-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task4-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task4-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task4-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task4-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task4-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task4-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task4'. Nodes: 7, Edges: 0.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task4':\n",
            "  - Grouped Stages 'task4-stage-0_conv1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task4-stage-1_relu1, task4-stage-2_conv2, task4-stage-3_relu2' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task4-stage-4_fc1, task4-stage-5_relu3, task4-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-4_fc1' to Node 'GPU-0-CPU-1'.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-1_relu1' to Node 'GPU-0-CPU-0'.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-2_conv2' to Node 'GPU-0-CPU-0'.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-0_conv1' to Node 'CPU-1'.\n",
            "['relu1', 'task4-stage-3_relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task4-stage-3_relu2' on Node 'GPU-0-CPU-0'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task4-stage-1_relu1, task4-stage-2_conv2, task4-stage-3_relu2' into 'task4-stage-1_relu1_to_task4-stage-3_relu2' and allocated to Node 'GPU-0-CPU-0'.\n",
            "['fc1', 'task4-stage-6_fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task4-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task4-stage-4_fc1, task4-stage-5_relu3, task4-stage-6_fc2' into 'task4-stage-4_fc1_to_task4-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task4'. Nodes: 3, Edges: 0.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task4'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task5'.\n",
            "[Scheduler] Created Stage 'task5-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task5-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task5-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task5-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task5-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task5-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task5-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task5'. Nodes: 7, Edges: 0.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 8148.621000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 76.311000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 77.788000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 65.241000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 73.395000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 48.062000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 1948.797000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 5109.282000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 2041.370000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 69.005000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 76.428000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 95.007000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 50.758000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 4103.650000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 75.966000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 68.391000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 902.846000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 87.053000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 82.648000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 72.625000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 2180.664000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task5':\n",
            "  - Grouped Stages 'task5-stage-0_conv1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task5-stage-1_relu1, task5-stage-2_conv2, task5-stage-3_relu2' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task5-stage-4_fc1, task5-stage-5_relu3, task5-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "['fc1']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-4_fc1' to Node 'GPU-0-CPU-1'.\n",
            "['relu3']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 60.798000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "['fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 76.578000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "['relu1']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-1_relu1' to Node 'GPU-0-CPU-0'.\n",
            "['conv2']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 83.587000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-2_conv2' to Node 'GPU-0-CPU-0'.\n",
            "['relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 66.555000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "['conv1']\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 107.784000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-0_conv1' to Node 'CPU-1'.\n",
            "['relu1', 'task5-stage-3_relu2']\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 66.975000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task5-stage-3_relu2' on Node 'GPU-0-CPU-0'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task5-stage-1_relu1, task5-stage-2_conv2, task5-stage-3_relu2' into 'task5-stage-1_relu1_to_task5-stage-3_relu2' and allocated to Node 'GPU-0-CPU-0'.\n",
            "['fc1', 'task5-stage-6_fc2']\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 74.772000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task5-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (1000.0 seconds).\n",
            "[Scheduler] Merged Stages 'task5-stage-4_fc1, task5-stage-5_relu3, task5-stage-6_fc2' into 'task5-stage-4_fc1_to_task5-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task5'. Nodes: 3, Edges: 0.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task5'.\n",
            "[Taskset/Scheduler] Scheduling all tasks onto the compute\n",
            "[Utility] Starting Evaluation Phase.\n",
            "[Evaluator] Starting Naive Execution.\n",
            "[Evaluator] Task 'task1' (Naive) executed in 0.005864 seconds.\n",
            "[Evaluator] Task 'task2' (Naive) executed in 0.000593 seconds.\n",
            "[Evaluator] Task 'task3' (Naive) executed in 0.000552 seconds.\n",
            "[Evaluator] Task 'task4' (Naive) executed in 0.000854 seconds.\n",
            "[Evaluator] Task 'task5' (Naive) executed in 0.000555 seconds.\n",
            "[Evaluator] Naive Execution Completed.\n",
            "\n",
            "[Evaluator] Cleaning up resources.\n",
            "[Evaluator] Resources cleaned up.\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Scheduler] Executing Task 'task1' with 3 stages.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-0_conv1' to Node 'CPU-1'.[Scheduler] Executing Task 'task2' with 3 stages.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-1_relu1_to_task1-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-4_fc1_to_task1-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "\n",
            "[Scheduler] Dispatched Stage 'task2-stage-0_conv1' to Node 'CPU-1'.[Scheduler] Executing Task 'task3' with 3 stages.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-0_conv1' to Node 'CPU-1'.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-1_relu1_to_task3-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-4_fc1_to_task3-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "\n",
            "[Scheduler] Dispatched Stage 'task2-stage-1_relu1_to_task2-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-4_fc1_to_task2-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Executing Task 'task4' with 3 stages.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-0_conv1' to Node 'CPU-1'.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-1_relu1_to_task4-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-4_fc1_to_task4-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Executing Task 'task5' with 3 stages.\n",
            "[Scheduler] Dispatched Stage 'task5-stage-0_conv1' to Node 'CPU-1'.\n",
            "[Scheduler] Dispatched Stage 'task5-stage-1_relu1_to_task5-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Dispatched Stage 'task5-stage-4_fc1_to_task5-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Stage] task1-stage-4_fc1_to_task1-stage-6_fc2: Error during execution: mat1 and mat2 shapes cannot be multiplied (24x8 and 2048x64)\n",
            "[Stage] task1-stage-4_fc1_to_task1-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.105742 seconds. Transfer Time: 0.000107 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task1-stage-4_fc1_to_task1-stage-6_fc2'.\n",
            "[Stage] task1-stage-1_relu1_to_task1-stage-3_relu2: Error during execution: Given groups=1, weight of size [32, 16, 3, 3], expected input[1, 3, 8, 8] to have 16 channels, but got 3 channels instead\n",
            "[Stage] task1-stage-1_relu1_to_task1-stage-3_relu2: Executed on GPU-0-CPU-0 in 0.105563 seconds. Transfer Time: 0.000303 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task1-stage-1_relu1_to_task1-stage-3_relu2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task1-stage-1_relu1_to_task1-stage-3_relu2'.\n",
            "[Stage] task3-stage-1_relu1_to_task3-stage-3_relu2: Error during execution: Given groups=1, weight of size [32, 16, 3, 3], expected input[1, 3, 8, 8] to have 16 channels, but got 3 channels instead\n",
            "[Stage] task3-stage-1_relu1_to_task3-stage-3_relu2: Executed on GPU-0-CPU-0 in 0.000587 seconds. Transfer Time: 0.000161 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task3-stage-1_relu1_to_task3-stage-3_relu2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task3-stage-1_relu1_to_task3-stage-3_relu2'.\n",
            "[Stage] task2-stage-1_relu1_to_task2-stage-3_relu2: Error during execution: Given groups=1, weight of size [32, 16, 3, 3], expected input[1, 3, 8, 8] to have 16 channels, but got 3 channels instead\n",
            "[Stage] task2-stage-1_relu1_to_task2-stage-3_relu2: Executed on GPU-0-CPU-0 in 0.000386 seconds. Transfer Time: 0.000101 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task2-stage-1_relu1_to_task2-stage-3_relu2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task2-stage-1_relu1_to_task2-stage-3_relu2'.\n",
            "[Stage] task4-stage-1_relu1_to_task4-stage-3_relu2: Error during execution: Given groups=1, weight of size [32, 16, 3, 3], expected input[1, 3, 8, 8] to have 16 channels, but got 3 channels instead\n",
            "[Stage] task4-stage-1_relu1_to_task4-stage-3_relu2: Executed on GPU-0-CPU-0 in 0.000312 seconds. Transfer Time: 0.000068 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task4-stage-1_relu1_to_task4-stage-3_relu2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task4-stage-1_relu1_to_task4-stage-3_relu2'.\n",
            "[Stage] task5-stage-1_relu1_to_task5-stage-3_relu2: Error during execution: Given groups=1, weight of size [32, 16, 3, 3], expected input[1, 3, 8, 8] to have 16 channels, but got 3 channels instead\n",
            "[Stage] task5-stage-1_relu1_to_task5-stage-3_relu2: Executed on GPU-0-CPU-0 in 0.000308 seconds. Transfer Time: 0.000063 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task5-stage-1_relu1_to_task5-stage-3_relu2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task5-stage-1_relu1_to_task5-stage-3_relu2'.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Stage' object has no attribute 'busy_time'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a05ba3532947>\u001b[0m in \u001b[0;36m<cell line: 1655>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m     \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-a05ba3532947>\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m     \u001b[0;31m# Run Evaluation Phase with Taskset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m     \u001b[0meval_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaskset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m     \u001b[0;31m# Print Performance Metrics from Taskset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a05ba3532947>\u001b[0m in \u001b[0;36meval_phase\u001b[0;34m(evaluator, taskset)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m     \u001b[0;31m# Run Parallel Execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m     \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_parallel_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m     \u001b[0;31m# Compare Outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a05ba3532947>\u001b[0m in \u001b[0;36mrun_parallel_execution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0;31m# Start parallel execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0mparallel_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m         \u001b[0mparallel_taskset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m         \u001b[0mparallel_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0mtotal_parallel_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_end_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mparallel_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a05ba3532947>\u001b[0m in \u001b[0;36mexecute_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a05ba3532947>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigned_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                 \u001b[0mnode_utilization\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusy_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mtotal_node_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Stage' object has no attribute 'busy_time'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage] task1-stage-0_conv1: Error during execution: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)\n",
            "[Stage] task1-stage-0_conv1: Executed on CPU-1 in 0.118975 seconds. Transfer Time: 0.000019 seconds.\n",
            "[Stage] task2-stage-0_conv1: Error during execution: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)\n",
            "[Stage] task2-stage-0_conv1: Executed on CPU-1 in 0.000280 seconds. Transfer Time: 0.000015 seconds.\n",
            "[Stage] task3-stage-0_conv1: Error during execution: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)\n",
            "[Stage] task3-stage-0_conv1: Executed on CPU-1 in 0.000262 seconds. Transfer Time: 0.000014 seconds.\n",
            "[Stage] task4-stage-0_conv1: Error during execution: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)\n",
            "[Stage] task4-stage-0_conv1: Executed on CPU-1 in 0.000247 seconds. Transfer Time: 0.000012 seconds.\n",
            "[Stage] task5-stage-0_conv1: Error during execution: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)\n",
            "[Stage] task5-stage-0_conv1: Executed on CPU-1 in 0.000250 seconds. Transfer Time: 0.000010 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task1-stage-4_fc1_to_task1-stage-6_fc2'.\n",
            "[Stage] task3-stage-4_fc1_to_task3-stage-6_fc2: Error during execution: mat1 and mat2 shapes cannot be multiplied (24x8 and 2048x64)\n",
            "[Stage] task3-stage-4_fc1_to_task3-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.000320 seconds. Transfer Time: 0.000090 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task3-stage-4_fc1_to_task3-stage-6_fc2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task3-stage-4_fc1_to_task3-stage-6_fc2'.\n",
            "[Stage] task2-stage-4_fc1_to_task2-stage-6_fc2: Error during execution: mat1 and mat2 shapes cannot be multiplied (24x8 and 2048x64)\n",
            "[Stage] task2-stage-4_fc1_to_task2-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.000284 seconds. Transfer Time: 0.000086 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task2-stage-4_fc1_to_task2-stage-6_fc2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task2-stage-4_fc1_to_task2-stage-6_fc2'.\n",
            "[Stage] task4-stage-4_fc1_to_task4-stage-6_fc2: Error during execution: mat1 and mat2 shapes cannot be multiplied (24x8 and 2048x64)\n",
            "[Stage] task4-stage-4_fc1_to_task4-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.000260 seconds. Transfer Time: 0.000072 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task4-stage-4_fc1_to_task4-stage-6_fc2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task4-stage-4_fc1_to_task4-stage-6_fc2'.\n",
            "[Stage] task5-stage-4_fc1_to_task5-stage-6_fc2: Error during execution: mat1 and mat2 shapes cannot be multiplied (24x8 and 2048x64)\n",
            "[Stage] task5-stage-4_fc1_to_task5-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.000248 seconds. Transfer Time: 0.000067 seconds.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task5-stage-4_fc1_to_task5-stage-6_fc2'.\n",
            "[Scheduler] Warning: Task ID not found for stage 'task5-stage-4_fc1_to_task5-stage-6_fc2'.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Unified_Taskset_Evaluation.ipynb\n",
        "\n",
        "This script implements a single Taskset approach, utilizing single tensor inputs for both profiling and evaluation phases.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import networkx as nx\n",
        "import os\n",
        "import torch\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.profiler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from typing import Callable, Any, List, Dict, Optional\n",
        "import copy\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# --- Node Class (Unchanged) ---\n",
        "class Node:\n",
        "    \"\"\"\n",
        "    Represents a computational resource: either a CPU-only node (1 CPU core)\n",
        "    or a GPU+CPU pair. Each Node has:\n",
        "      - node_id (e.g., 'CPU-0', 'GPU-0-CPU-1')\n",
        "      - A worker thread + queue to run tasks\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, node_id: str, cpus=None, gpu=None):\n",
        "        self._node_id = node_id\n",
        "        self._cpus = tuple(cpus or [])\n",
        "        self._gpu = gpu\n",
        "\n",
        "        self._original_affinity = os.sched_getaffinity(0)\n",
        "        self._task_queue = queue.Queue()\n",
        "        self._stop_signal = False\n",
        "\n",
        "        self._worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n",
        "        self._worker_thread.start()\n",
        "\n",
        "        self.current_load = 0.0  # Initialize current load\n",
        "        self.assigned_stages = []  # List to track assigned stages\n",
        "\n",
        "    @property\n",
        "    def node_id(self):\n",
        "        return self._node_id\n",
        "\n",
        "    @property\n",
        "    def cpus(self):\n",
        "        return self._cpus\n",
        "\n",
        "    @property\n",
        "    def gpu(self):\n",
        "        return self._gpu\n",
        "\n",
        "    def assign_task(self, func: Callable, *args, **kwargs) -> queue.Queue:\n",
        "        \"\"\"\n",
        "        Enqueue a function to this node. Returns a queue from which\n",
        "        the caller can retrieve the result (blocking).\n",
        "        \"\"\"\n",
        "        result_queue = queue.Queue(maxsize=1)\n",
        "        self._task_queue.put((func, args, kwargs, result_queue))\n",
        "        return result_queue\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"\n",
        "        Signal the node to stop after processing queued tasks.\n",
        "        \"\"\"\n",
        "        self._stop_signal = True\n",
        "        self._task_queue.put(None)\n",
        "        self._worker_thread.join()\n",
        "\n",
        "    def _worker_loop(self):\n",
        "        while not self._stop_signal:\n",
        "            item = self._task_queue.get()\n",
        "            if item is None:\n",
        "                break\n",
        "            func, args, kwargs, result_queue = item\n",
        "            try:\n",
        "                self._set_context()\n",
        "                result = func(*args, **kwargs)\n",
        "            except Exception as e:\n",
        "                result = e\n",
        "            finally:\n",
        "                self._reset_context()\n",
        "\n",
        "            result_queue.put(result)\n",
        "\n",
        "    def _set_context(self):\n",
        "        if self._cpus:\n",
        "            os.sched_setaffinity(0, self._cpus)\n",
        "        if self._gpu is not None and torch.cuda.is_available():\n",
        "            torch.cuda.set_device(self._gpu)\n",
        "\n",
        "    def _reset_context(self):\n",
        "        os.sched_setaffinity(0, self._original_affinity)\n",
        "        # Optionally reset GPU device if needed\n",
        "\n",
        "    @staticmethod\n",
        "    def discover_nodes() -> List['Node']:\n",
        "        \"\"\"\n",
        "        Create a Node for each CPU core, and for each GPU+CPU pair.\n",
        "        \"\"\"\n",
        "        nodes = []\n",
        "        num_cpus = os.cpu_count() or 1\n",
        "        ngpus = torch.cuda.device_count()\n",
        "\n",
        "        # CPU-only nodes\n",
        "        for core_id in range(num_cpus):\n",
        "            node = Node(node_id=f\"CPU-{core_id}\", cpus=[core_id])\n",
        "            nodes.append(node)\n",
        "\n",
        "        # GPU+CPU nodes\n",
        "        for g in range(ngpus):\n",
        "            for core_id in range(num_cpus):\n",
        "                node = Node(node_id=f\"GPU-{g}-CPU-{core_id}\", cpus=[core_id], gpu=g)\n",
        "                nodes.append(node)\n",
        "\n",
        "        return nodes\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Node({self._node_id}, cpus={self._cpus}, gpu={self._gpu})\"\n",
        "\n",
        "# --- Profiler Class (Modified) ---\n",
        "class Profiler:\n",
        "    \"\"\"\n",
        "    In 'init' mode: Gather detailed profiling info for each leaf layer on each Node,\n",
        "    storing results in a CSV-based ProfileDB.\n",
        "    In 'runtime' mode: Potentially gather minimal logs (optional).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode: str, profile_db_path='profiling_results.csv', log_dir='logs'):\n",
        "        assert mode in ['init', 'runtime']\n",
        "        self.mode = mode\n",
        "        self.profile_db_path = profile_db_path\n",
        "        self.log_dir = log_dir\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "\n",
        "        columns = [\n",
        "            'Model', 'Layer', 'Compute',\n",
        "            'Self CPU (us)', 'CPU Total (us)', 'CUDA Total (us)',\n",
        "            'Self CPU Mem (bytes)', 'Self CUDA Mem (bytes)',\n",
        "            'Total Execution Time (us)', 'Total Memory Used (bytes)'\n",
        "        ]\n",
        "        if os.path.exists(self.profile_db_path):\n",
        "            self.profile_db = pd.read_csv(self.profile_db_path)\n",
        "        else:\n",
        "            self.profile_db = pd.DataFrame(columns=columns)\n",
        "\n",
        "        self.runtime_csv = os.path.join(self.log_dir, 'runtime_results.csv')\n",
        "        if not os.path.exists(self.runtime_csv):\n",
        "            rt_cols = ['Model', 'Layer', 'Compute', 'Execution Time (us)']\n",
        "            pd.DataFrame(columns=rt_cols).to_csv(self.runtime_csv, index=False)\n",
        "\n",
        "    def _register_hooks(self, model: nn.Module):\n",
        "        def hook_wrapper(layer_name):\n",
        "            def hook(mod, inp, out):\n",
        "                with torch.profiler.record_function(layer_name):\n",
        "                    pass\n",
        "            return hook\n",
        "\n",
        "        for idx, (name, layer) in enumerate(model.named_modules()):\n",
        "            if not isinstance(layer, nn.Sequential) and not isinstance(layer, nn.ModuleList) and layer != model:\n",
        "                layer.register_forward_hook(hook_wrapper(f\"{name}_{idx}\"))\n",
        "\n",
        "    def profile_model(self, model: nn.Module, input_data: Any, node, model_name: str, warmup_iters=3):\n",
        "        \"\"\"\n",
        "        Schedule a profiling task on 'node'. In 'init' mode, we gather\n",
        "        full per-layer times.\n",
        "        \"\"\"\n",
        "        def profiling_task():\n",
        "            device = torch.device(f\"cuda:{node.gpu}\" if node.gpu is not None and torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "\n",
        "            if self.mode == 'init':\n",
        "                # Warmup\n",
        "                with torch.no_grad():\n",
        "                    for _ in range(warmup_iters):\n",
        "                        model(input_data.to(device))\n",
        "                self._profile_init(model, input_data, node, model_name, device)\n",
        "            else:\n",
        "                self._profile_runtime(model, input_data, node, model_name, device)\n",
        "\n",
        "        rq = node.assign_task(profiling_task)\n",
        "        rq.get()  # block\n",
        "\n",
        "    def _profile_init(self, model, input_data, node, model_name, device):\n",
        "        self._register_hooks(model)\n",
        "        with torch.profiler.profile(\n",
        "            activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
        "            profile_memory=True\n",
        "        ) as prof:\n",
        "            with torch.no_grad():\n",
        "                model(input_data.to(device))\n",
        "                prof.step()\n",
        "\n",
        "        stats = self._process_events(prof, model, node, runtime=False)\n",
        "        self._update_profile_db(stats, model_name, node, runtime=False)\n",
        "\n",
        "    def _profile_runtime(self, model, input_data, node, model_name, device):\n",
        "        self._register_hooks(model)\n",
        "        with torch.no_grad():\n",
        "            with torch.profiler.profile(\n",
        "                activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA]\n",
        "            ) as prof:\n",
        "                model(input_data.to(device))\n",
        "                prof.step()\n",
        "            stats = self._process_events(prof, model, node, runtime=True)\n",
        "            self._append_runtime_csv(stats, model_name, node)\n",
        "\n",
        "    def _process_events(self, profiler, model, node, runtime=False):\n",
        "        recognized = set()\n",
        "        for n, m in model.named_modules():\n",
        "            if n:\n",
        "                recognized.add(n)\n",
        "\n",
        "        aggregated = {\n",
        "            'forward_pass': dict(self_cpu_time_total=0, cpu_time_total=0, cuda_time_total=0,\n",
        "                                 self_cpu_memory_usage=0, self_cuda_memory_usage=0, compute=node.node_id),\n",
        "            'misc': dict(self_cpu_time_total=0, cpu_time_total=0, cuda_time_total=0,\n",
        "                         self_cpu_memory_usage=0, self_cuda_memory_usage=0, compute=node.node_id)\n",
        "        }\n",
        "\n",
        "        events = list(profiler.events())\n",
        "        found_root = False\n",
        "\n",
        "        def strip_suffix(s):\n",
        "            return re.sub(r'(\\.|_)\\d+$', '', s)\n",
        "\n",
        "        for e in events:\n",
        "            if e.name == \"\":\n",
        "                found_root = True\n",
        "                aggregated['forward_pass']['self_cpu_time_total'] += e.self_cpu_time_total\n",
        "                aggregated['forward_pass']['cpu_time_total'] += e.cpu_time_total\n",
        "                aggregated['forward_pass']['cuda_time_total'] += e.device_time_total\n",
        "                if not runtime:\n",
        "                    aggregated['forward_pass']['self_cpu_memory_usage'] += e.self_cpu_memory_usage\n",
        "                    aggregated['forward_pass']['self_cuda_memory_usage'] += e.self_device_memory_usage  # Updated\n",
        "            else:\n",
        "                base = strip_suffix(e.name)\n",
        "                if base in recognized:\n",
        "                    if base not in aggregated:\n",
        "                        aggregated[base] = dict(\n",
        "                            self_cpu_time_total=0, cpu_time_total=0, cuda_time_total=0,\n",
        "                            self_cpu_memory_usage=0, self_cuda_memory_usage=0,\n",
        "                            compute=node.node_id\n",
        "                        )\n",
        "                    aggregated[base]['self_cpu_time_total'] += e.self_cpu_time_total\n",
        "                    aggregated[base]['cpu_time_total'] += e.cpu_time_total\n",
        "                    aggregated[base]['cuda_time_total'] += e.device_time_total\n",
        "                    if not runtime:\n",
        "                        aggregated[base]['self_cpu_memory_usage'] += e.self_cpu_memory_usage\n",
        "                        aggregated[base]['self_cuda_memory_usage'] += e.self_device_memory_usage\n",
        "                else:\n",
        "                    aggregated['misc']['self_cpu_time_total'] += e.self_cpu_time_total\n",
        "                    aggregated['misc']['cpu_time_total'] += e.cpu_time_total\n",
        "                    aggregated['misc']['cuda_time_total'] += e.device_time_total\n",
        "                    if not runtime:\n",
        "                        aggregated['misc']['self_cpu_memory_usage'] += e.self_cpu_memory_usage\n",
        "                        aggregated['misc']['self_cuda_memory_usage'] += e.self_cuda_memory_usage  # Updated\n",
        "\n",
        "        # If no root event found, sum all into forward_pass\n",
        "        if not found_root:\n",
        "            for k in list(aggregated.keys()):\n",
        "                if k not in ('forward_pass', 'misc'):\n",
        "                    aggregated['forward_pass']['self_cpu_time_total'] += aggregated[k]['self_cpu_time_total']\n",
        "                    aggregated['forward_pass']['cpu_time_total'] += aggregated[k]['cpu_time_total']\n",
        "                    aggregated['forward_pass']['cuda_time_total'] += aggregated[k]['cuda_time_total']\n",
        "                    if not runtime:\n",
        "                        aggregated['forward_pass']['self_cpu_memory_usage'] += aggregated[k]['self_cpu_memory_usage']\n",
        "                        aggregated['forward_pass']['self_cuda_memory_usage'] += aggregated[k]['self_cuda_memory_usage']\n",
        "\n",
        "            aggregated['forward_pass']['self_cpu_time_total'] += aggregated['misc']['self_cpu_time_total']\n",
        "            aggregated['forward_pass']['cpu_time_total'] += aggregated['misc']['cpu_time_total']\n",
        "            aggregated['forward_pass']['cuda_time_total'] += aggregated['misc']['cuda_time_total']\n",
        "            if not runtime:\n",
        "                aggregated['forward_pass']['self_cpu_memory_usage'] += aggregated['misc']['self_cpu_memory_usage']\n",
        "                aggregated['forward_pass']['self_cuda_memory_usage'] += aggregated['misc']['self_cuda_memory_usage']\n",
        "\n",
        "        return aggregated\n",
        "\n",
        "    def _update_profile_db(self, stats, model_name, node, runtime=False):\n",
        "        if runtime:\n",
        "            return\n",
        "        for layer_name, data in stats.items():\n",
        "            total_t = data['cpu_time_total'] + data['cuda_time_total']\n",
        "            total_m = data['self_cpu_memory_usage'] + data['self_cuda_memory_usage']\n",
        "            row = {\n",
        "                'Model': model_name,\n",
        "                'Layer': layer_name,\n",
        "                'Compute': data['compute'],\n",
        "                'Self CPU (us)': data['self_cpu_time_total'],\n",
        "                'CPU Total (us)': data['cpu_time_total'],\n",
        "                'CUDA Total (us)': data['cuda_time_total'],\n",
        "                'Self CPU Mem (bytes)': data['self_cpu_memory_usage'],\n",
        "                'Self CUDA Mem (bytes)': data['self_cuda_memory_usage'],\n",
        "                'Total Execution Time (us)': total_t * 1_000_000,  # Convert to microseconds\n",
        "                'Total Memory Used (bytes)': total_m\n",
        "            }\n",
        "            self.profile_db = self._upsert(self.profile_db, row)\n",
        "        self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "\n",
        "    def _upsert(self, df, row):\n",
        "        mask = (\n",
        "            (df['Model'] == row['Model']) &\n",
        "            (df['Layer'] == row['Layer']) &\n",
        "            (df['Compute'] == row['Compute'])\n",
        "        )\n",
        "        if not df[mask].empty:\n",
        "            existing_time = df.loc[mask, 'Total Execution Time (us)'].max()\n",
        "            if row['Total Execution Time (us)'] > existing_time:\n",
        "                for k, v in row.items():\n",
        "                    df.loc[mask, k] = v\n",
        "        else:\n",
        "            new_row = pd.DataFrame([row])\n",
        "            if not new_row.dropna().empty:\n",
        "                df = pd.concat([df, new_row], ignore_index=True)  # Fixed FutureWarning by checking non-empty\n",
        "        return df\n",
        "\n",
        "    def _append_runtime_csv(self, stats, model_name, node):\n",
        "        rows = []\n",
        "        for layer_name, data in stats.items():\n",
        "            exec_time = data['cpu_time_total'] + data['cuda_time_total']\n",
        "            rows.append({\n",
        "                'Model': model_name,\n",
        "                'Layer': layer_name,\n",
        "                'Compute': data['compute'],\n",
        "                'Execution Time (us)': exec_time * 1_000_000  # Convert to microseconds\n",
        "            })\n",
        "        if rows:\n",
        "            rdf = pd.read_csv(self.runtime_csv)\n",
        "            rdf = pd.concat([rdf, pd.DataFrame(rows)], ignore_index=True)\n",
        "            rdf.to_csv(self.runtime_csv, index=False)\n",
        "\n",
        "    def get_profile_db(self):\n",
        "        return self.profile_db\n",
        "\n",
        "    def print_profile_db(self):\n",
        "        if self.profile_db.empty:\n",
        "            print(\"ProfileDB is empty.\")\n",
        "        else:\n",
        "            print(\"ProfileDB:\\n\", self.profile_db.to_string(index=False))\n",
        "\n",
        "# --- Stage Class (Unchanged) ---\n",
        "class Stage:\n",
        "    \"\"\"\n",
        "    Represents a partitioned segment of a model, assigned to a specific Node.\n",
        "\n",
        "    Attributes:\n",
        "        stage_id (str): Unique identifier for the stage.\n",
        "        layers (nn.ModuleList): The layers assigned to this stage.\n",
        "        assigned_node (Node): The Node responsible for executing this stage.\n",
        "        dependencies (List[str]): List of stage_ids that this stage depends on.\n",
        "        dependents (List[str]): List of stage_ids that depend on this stage.\n",
        "        execution_time (Optional[float]): Time taken to execute this stage.\n",
        "        input_data (Optional[torch.Tensor]): Input tensor for this stage.\n",
        "        output_data (Optional[torch.Tensor]): Output tensor from this stage.\n",
        "        transfer_time (float): Time spent on data transfers (in seconds).\n",
        "        task (Task): Reference to the Task instance this stage belongs to.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stage_id: str, layers: nn.ModuleList, assigned_node: 'Node', task: 'Task'):\n",
        "        \"\"\"\n",
        "        Initializes the Stage object.\n",
        "\n",
        "        Args:\n",
        "            stage_id (str): Unique identifier for the stage.\n",
        "            layers (nn.ModuleList): The layers assigned to this stage.\n",
        "            assigned_node (Node): The Node responsible for executing this stage.\n",
        "            task (Task): The Task instance this stage belongs to.\n",
        "        \"\"\"\n",
        "        self.stage_id = stage_id\n",
        "        self.layers = layers\n",
        "        self.assigned_node = assigned_node\n",
        "\n",
        "        self.dependencies: List[str] = []\n",
        "        self.dependents: List[str] = []\n",
        "\n",
        "        self.execution_time: Optional[float] = None\n",
        "        self.input_data: Optional[torch.Tensor] = None\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "\n",
        "        self.transfer_time: float = 0.0\n",
        "\n",
        "        self.task = task  # Reference to the Task\n",
        "\n",
        "    def add_dependency(self, stage_id: str):\n",
        "        \"\"\"\n",
        "        Adds a dependency to this stage.\n",
        "\n",
        "        Args:\n",
        "            stage_id (str): The stage_id that this stage depends on.\n",
        "        \"\"\"\n",
        "        self.dependencies.append(stage_id)\n",
        "\n",
        "    def add_dependent(self, stage_id: str):\n",
        "        \"\"\"\n",
        "        Adds a dependent to this stage.\n",
        "\n",
        "        Args:\n",
        "            stage_id (str): The stage_id that depends on this stage.\n",
        "        \"\"\"\n",
        "        self.dependents.append(stage_id)\n",
        "\n",
        "    def run_stage(self):\n",
        "        \"\"\"\n",
        "        Executes the stage's layers on the assigned node.\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        transfer_start = time.time()\n",
        "        try:\n",
        "            device = torch.device(\n",
        "                f\"cuda:{self.assigned_node.gpu}\" if self.assigned_node.gpu is not None and torch.cuda.is_available()\n",
        "                else \"cpu\"\n",
        "            )\n",
        "\n",
        "            if self.input_data is None:\n",
        "                print(f\"[Stage] {self.stage_id}: No input data provided. Executing with empty tensor.\")\n",
        "                out = torch.tensor([])\n",
        "                transfer_end = time.time()\n",
        "                self.transfer_time += transfer_end - transfer_start\n",
        "            else:\n",
        "                inp = self.input_data.to(device)\n",
        "                transfer_end = time.time()\n",
        "                self.transfer_time += transfer_end - transfer_start\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    out = inp\n",
        "                    for layer in self.layers:\n",
        "                        out = layer(out)\n",
        "\n",
        "                if device.type == 'cuda':\n",
        "                    transfer_start = time.time()\n",
        "                    out = out.cpu()\n",
        "                    transfer_end = time.time()\n",
        "                    self.transfer_time += transfer_end - transfer_start\n",
        "\n",
        "            self.output_data = out\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage] {self.stage_id}: Error during execution: {e}\")\n",
        "            self.output_data = None\n",
        "        finally:\n",
        "            end_time = time.time()\n",
        "            self.execution_time = end_time - start_time\n",
        "            print(f\"[Stage] {self.stage_id}: Executed on {self.assigned_node.node_id} in {self.execution_time:.6f} seconds. Transfer Time: {self.transfer_time:.6f} seconds.\")\n",
        "\n",
        "            # Update Task's busy time with both execution and transfer times\n",
        "            self.task.update_busy_time(self.execution_time, self.transfer_time)\n",
        "\n",
        "            # If this is the final stage, set the Task's output data\n",
        "            if not self.dependents:\n",
        "                self.task.set_output_data(self.output_data)\n",
        "\n",
        "            # Notify Scheduler of stage completion\n",
        "            self.task.scheduler.stage_completed(self.stage_id)\n",
        "\n",
        "        return self.output_data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Stage(stage_id={self.stage_id}, assigned_node={self.assigned_node.node_id}, \"\n",
        "                f\"dependencies={self.dependencies}, dependents={self.dependents}, \"\n",
        "                f\"execution_time={self.execution_time:.6f if self.execution_time else 'N/A'}, \"\n",
        "                f\"transfer_time={self.transfer_time:.6f}, output_data_present={self.output_data is not None})\")\n",
        "\n",
        "    def __deepcopy__(self, memo):\n",
        "        \"\"\"\n",
        "        Create a new Stage, copying only what we need, while referencing the same Node.\n",
        "        \"\"\"\n",
        "        # 1) Create the new Stage without doing a deepcopy on 'assigned_node'\n",
        "        new_stage = Stage(\n",
        "            stage_id = copy.deepcopy(self.stage_id, memo),\n",
        "            layers   = copy.deepcopy(self.layers, memo),\n",
        "            assigned_node = self.assigned_node,  # <-- same Node object\n",
        "            task = None  # or self.task if you want the same reference or plan to reassign later\n",
        "        )\n",
        "\n",
        "        # 2) Copy lists and basic attributes\n",
        "        new_stage.dependencies   = copy.deepcopy(self.dependencies, memo)\n",
        "        new_stage.dependents     = copy.deepcopy(self.dependents, memo)\n",
        "        new_stage.execution_time = self.execution_time\n",
        "        new_stage.transfer_time  = self.transfer_time\n",
        "\n",
        "        # 3) Decide whether to copy input_data/output_data\n",
        "        #    For final input/output analysis, you might want to do the following:\n",
        "        new_stage.input_data  = copy.deepcopy(self.input_data, memo)\n",
        "        new_stage.output_data = copy.deepcopy(self.output_data, memo)\n",
        "        #\n",
        "        # But if your pipeline is re-initialized or you always supply fresh input_data, do this:\n",
        "        # new_stage.input_data  = None\n",
        "        # new_stage.output_data = None\n",
        "\n",
        "        return new_stage\n",
        "\n",
        "\n",
        "# --- Task Class (Unchanged) ---\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Represents a single DNN inference task.\n",
        "\n",
        "    Attributes:\n",
        "        task_id (str): Unique identifier for the task.\n",
        "        model (nn.Module): The DNN model to be executed.\n",
        "        input_data (torch.Tensor): The input tensor for the model.\n",
        "        model_name (str): Name of the model (used for profiling).\n",
        "        stages (Dict[str, Stage]): Dictionary of Stage objects representing the task's execution stages.\n",
        "        scheduler (Scheduler): Reference to the Scheduler handling this task.\n",
        "        start_time (Optional[float]): Timestamp when the task started execution.\n",
        "        finish_time (Optional[float]): Timestamp when the task finished execution.\n",
        "        output_data (Optional[torch.Tensor]): The final output tensor after executing all stages.\n",
        "        busy_time (float): Total time spent executing stages (in seconds).\n",
        "        computation_time (float): Total time spent on computations (in seconds).\n",
        "        transfer_time (float): Total time spent on data transfers (in seconds).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_id: str, model: nn.Module, input_data: torch.Tensor, model_name: str, scheduler: 'Scheduler'):\n",
        "        \"\"\"\n",
        "            Initializes the Task object.\n",
        "\n",
        "            Args:\n",
        "                task_id (str): Unique identifier for the task.\n",
        "                model (nn.Module): The DNN model to be executed.\n",
        "                input_data (torch.Tensor): The input tensor for the model.\n",
        "                model_name (str): Name of the model (used for profiling).\n",
        "                scheduler (Scheduler): Reference to the Scheduler handling this task.\n",
        "        \"\"\"\n",
        "        self.task_id = task_id\n",
        "        self.model = model\n",
        "        self.input_data = input_data\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.scheduler = scheduler  # Reference to the Scheduler\n",
        "\n",
        "        self.stages: Dict[str, Stage] = {}\n",
        "\n",
        "        self.start_time: Optional[float] = None\n",
        "        self.finish_time: Optional[float] = None\n",
        "\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "        self.busy_time: float = 0.0\n",
        "        self.computation_time: float = 0.0\n",
        "        self.transfer_time: float = 0.0\n",
        "\n",
        "    def add_stage(self, stage: 'Stage'):\n",
        "        \"\"\"\n",
        "        Adds a Stage object to the task.\n",
        "\n",
        "        Args:\n",
        "            stage (Stage): The Stage object to be added.\n",
        "        \"\"\"\n",
        "        if stage.stage_id in self.stages:\n",
        "            raise ValueError(f\"Stage ID {stage.stage_id} already exists in Task {self.task_id}.\")\n",
        "        self.stages[stage.stage_id] = stage\n",
        "\n",
        "    def get_stage(self, stage_id: str) -> Optional['Stage']:\n",
        "        \"\"\"\n",
        "        Retrieves a Stage object by its stage_id.\n",
        "\n",
        "        Args:\n",
        "            stage_id (str): The unique identifier of the stage.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Stage]: The Stage object if found, else None.\n",
        "        \"\"\"\n",
        "        return self.stages.get(stage_id, None)\n",
        "\n",
        "    def get_total_execution_time(self) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the total execution time of the task.\n",
        "\n",
        "        Returns:\n",
        "            float: Total execution time in seconds.\n",
        "        \"\"\"\n",
        "        if self.start_time and self.finish_time:\n",
        "            return self.finish_time - self.start_time\n",
        "        return 0.0\n",
        "\n",
        "    def update_busy_time(self, stage_execution_time: float, stage_transfer_time: float = 0.0):\n",
        "        \"\"\"\n",
        "        Updates the cumulative busy time of the task.\n",
        "\n",
        "        Args:\n",
        "            stage_execution_time (float): Execution time of a stage in seconds.\n",
        "            stage_transfer_time (float, optional): Transfer time of a stage in seconds. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        self.busy_time += stage_execution_time\n",
        "        self.transfer_time += stage_transfer_time\n",
        "        self.computation_time += (stage_execution_time - stage_transfer_time)\n",
        "\n",
        "    def set_output_data(self, output: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Sets the final output data of the task.\n",
        "\n",
        "        Args:\n",
        "            output (torch.Tensor): The final output tensor after all stages.\n",
        "        \"\"\"\n",
        "        self.output_data = output\n",
        "        self.finish_time = time.time()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Task(task_id={self.task_id}, model_name={self.model_name}, \"\n",
        "                f\"stages={list(self.stages.keys())}, \"\n",
        "                f\"start_time={self.start_time}, finish_time={self.finish_time}, \"\n",
        "                f\"busy_time={self.busy_time:.6f}, computation_time={self.computation_time:.6f}, \"\n",
        "                f\"transfer_time={self.transfer_time:.6f}, output_data_present={self.output_data is not None})\")\n",
        "\n",
        "    def __deepcopy__(self, memo):\n",
        "        # Create a new Task instance without the scheduler reference\n",
        "        new_task = Task(\n",
        "            task_id=copy.deepcopy(self.task_id, memo),\n",
        "            model=copy.deepcopy(self.model, memo),\n",
        "            input_data=copy.deepcopy(self.input_data, memo),\n",
        "            model_name=copy.deepcopy(self.model_name, memo),\n",
        "            scheduler=None  # Exclude scheduler to prevent deepcopy issues\n",
        "        )\n",
        "        # Deepcopy stages\n",
        "        new_task.stages = copy.deepcopy(self.stages, memo)\n",
        "        # Copy other attributes\n",
        "        new_task.start_time = self.start_time\n",
        "        new_task.finish_time = self.finish_time\n",
        "        new_task.output_data = self.output_data\n",
        "        new_task.busy_time = self.busy_time\n",
        "        new_task.computation_time = self.computation_time\n",
        "        new_task.transfer_time = self.transfer_time\n",
        "        return new_task\n",
        "\n",
        "# --- Taskset Class ---\n",
        "class Taskset:\n",
        "    \"\"\"\n",
        "    Manages a collection of Tasks and orchestrates their execution using the Scheduler.\n",
        "\n",
        "    Attributes:\n",
        "        tasks (List[Task]): A list of Task instances to be executed.\n",
        "        scheduler (Scheduler): The Scheduler responsible for decomposing and allocating tasks.\n",
        "        total_utilization (float): Overall resource utilization of the taskset.\n",
        "        average_turnaround_time (float): Average turnaround time of all tasks.\n",
        "        throughput (float): Number of tasks completed per unit time.\n",
        "        makespan (float): Total time to complete all tasks.\n",
        "        task_completion_rate (float): Ratio of completed tasks to total tasks.\n",
        "        average_resource_utilization_per_node (Dict[str, float]): Average utilization per node.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tasks: List['Task'], scheduler: 'Scheduler'):\n",
        "        \"\"\"\n",
        "        Initializes the Taskset object.\n",
        "\n",
        "        Args:\n",
        "            tasks (List[Task]): A list of Task instances to be managed.\n",
        "            scheduler (Scheduler): The Scheduler responsible for task decomposition and allocation.\n",
        "        \"\"\"\n",
        "        self.tasks = tasks\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        # Performance Metrics\n",
        "        self.total_utilization: float = 0.0\n",
        "        self.average_turnaround_time: float = 0.0\n",
        "        self.throughput: float = 0.0\n",
        "        self.makespan: float = 0.0\n",
        "        self.task_completion_rate: float = 0.0\n",
        "        self.average_resource_utilization_per_node: Dict[str, float] = {}\n",
        "\n",
        "    def schedule_all_tasks(self):\n",
        "        \"\"\"\n",
        "        Decompose and allocate all tasks using the Scheduler.\n",
        "        \"\"\"\n",
        "        for task in self.tasks:\n",
        "            self.scheduler.decompose_and_allocate_task(task)\n",
        "\n",
        "    def execute_all(self):\n",
        "        \"\"\"\n",
        "        Execute all tasks in the Taskset concurrently using threading based on the precomputed allocation strategy.\n",
        "        \"\"\"\n",
        "        threads = []\n",
        "        for task in self.tasks:\n",
        "            # thread = threading.Thread(target=self.scheduler.execute_task_with_graph, args=(task,))\n",
        "            thread = threading.Thread(target=self.scheduler.execute_task, args=(task,))\n",
        "            thread.start()\n",
        "            threads.append(thread)\n",
        "\n",
        "        for thread in threads:\n",
        "            thread.join()\n",
        "\n",
        "        self.calculate_metrics()\n",
        "\n",
        "    def calculate_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculates all performance metrics for the taskset.\n",
        "        \"\"\"\n",
        "        # Total Utilization\n",
        "        total_busy_time = sum(task.busy_time for task in self.tasks)\n",
        "        total_available_time = self.scheduler.observation_window * len(self.scheduler.nodes)\n",
        "        self.total_utilization = total_busy_time / total_available_time if total_available_time > 0 else 0.0\n",
        "\n",
        "        # Average Turnaround Time\n",
        "        turnaround_times = [task.get_total_execution_time() for task in self.tasks]\n",
        "        self.average_turnaround_time = sum(turnaround_times) / len(turnaround_times) if turnaround_times else 0.0\n",
        "\n",
        "        # Throughput\n",
        "        self.throughput = len(self.tasks) / self.makespan if self.makespan > 0 else 0.0\n",
        "\n",
        "        # Makespan\n",
        "        start_times = [task.start_time for task in self.tasks if task.start_time is not None]\n",
        "        finish_times = [task.finish_time for task in self.tasks if task.finish_time is not None]\n",
        "        if start_times and finish_times:\n",
        "            earliest_start = min(start_times)\n",
        "            latest_finish = max(finish_times)\n",
        "            self.makespan = latest_finish - earliest_start\n",
        "        else:\n",
        "            self.makespan = 0.0\n",
        "\n",
        "        # Task Completion Rate\n",
        "        completed_tasks = [task for task in self.tasks if task.output_data is not None]\n",
        "        self.task_completion_rate = len(completed_tasks) / len(self.tasks) if self.tasks else 0.0\n",
        "\n",
        "        # Average Resource Utilization per Node\n",
        "        node_utilization = {node.node_id: 0.0 for node in self.scheduler.nodes}\n",
        "        for task in self.tasks:\n",
        "            for stage in task.stages.values():\n",
        "                node_id = stage.assigned_node.node_id\n",
        "                node_utilization[node_id] += stage.busy_time\n",
        "        for node in self.scheduler.nodes:\n",
        "            total_node_time = self.scheduler.observation_window\n",
        "            self.average_resource_utilization_per_node[node.node_id] = (\n",
        "                node_utilization[node.node_id] / total_node_time if total_node_time > 0 else 0.0\n",
        "            )\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"Taskset(total_tasks={len(self.tasks)}, \"\n",
        "            f\"total_utilization={self.total_utilization:.2%}, \"\n",
        "            f\"average_turnaround_time={self.average_turnaround_time:.6f} seconds, \"\n",
        "            f\"throughput={self.throughput:.2f} tasks/sec, \"\n",
        "            f\"makespan={self.makespan:.6f} seconds, \"\n",
        "            f\"task_completion_rate={self.task_completion_rate:.2%}, \"\n",
        "            f\"average_resource_utilization_per_node={self.average_resource_utilization_per_node})\"\n",
        "        )\n",
        "\n",
        "# --- Scheduler Class (Unchanged, but ensure execution graphs are built correctly) ---\n",
        "class Scheduler:\n",
        "    \"\"\"\n",
        "    Scheduler class responsible for decomposing tasks into stages,\n",
        "    allocating stages to nodes using Dynamic Programming to minimize\n",
        "    maximum node utilization, dispatching stages for execution,\n",
        "    and managing dependencies between stages via an execution graph.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nodes: List['Node'],\n",
        "        profiler: 'Profiler',\n",
        "        observation_window: float = 1000.0,\n",
        "        load_metric_func: Optional[Callable[[float, float], float]] = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the Scheduler.\n",
        "\n",
        "        Args:\n",
        "            nodes (List[Node]): List of available Node instances.\n",
        "            profiler (Profiler): Profiler instance used for gathering execution times.\n",
        "            observation_window (float, optional): Time window for utilization calculations. Defaults to 1000.0.\n",
        "            load_metric_func (Callable, optional): User-defined load metric function. Defaults to None.\n",
        "        \"\"\"\n",
        "        self.nodes = nodes\n",
        "        self.profiler = profiler\n",
        "        self.observation_window = observation_window\n",
        "        self.load_metric = load_metric_func if load_metric_func else self.default_load_metric\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "        self.tasks: Dict[str, Task] = {}  # task_id -> Task\n",
        "        self.stage_map: Dict[str, Stage] = {}  # stage_id -> Stage\n",
        "        self.completed_stages: set = set()\n",
        "\n",
        "        # Execution Graphs: task_id -> DiGraph\n",
        "        self.execution_graphs: Dict[str, nx.DiGraph] = {}\n",
        "\n",
        "    def default_load_metric(self, execution_time: float, observation_window: float) -> float:\n",
        "        \"\"\"\n",
        "        Default load metric: execution_time divided by observation_window.\n",
        "\n",
        "        Args:\n",
        "            execution_time (float): Execution time of the stage.\n",
        "            observation_window (float): Observation window.\n",
        "\n",
        "        Returns:\n",
        "            float: Utilization.\n",
        "        \"\"\"\n",
        "        return execution_time / observation_window\n",
        "\n",
        "    def decompose_and_allocate_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Decomposes the Task into Stages, builds the execution graph, and allocates each Stage to a Node based on the DP allocation strategy.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance to decompose and allocate.\n",
        "        \"\"\"\n",
        "        with self.lock:\n",
        "            self.tasks[task.task_id] = task\n",
        "            task.start_time = time.time()\n",
        "\n",
        "            print(f\"[Scheduler] Starting decomposition and allocation for Task '{task.task_id}'.\")\n",
        "\n",
        "            # Decompose task into stages\n",
        "            stages = self.decompose_task_into_stages(task)\n",
        "\n",
        "            # Build execution graph for the task\n",
        "            exec_graph = self.build_execution_graph(task)\n",
        "            self.execution_graphs[task.task_id] = exec_graph\n",
        "            print(f\"[Scheduler] Built execution graph for Task '{task.task_id}'. Nodes: {exec_graph.number_of_nodes()}, Edges: {exec_graph.number_of_edges()}.\")\n",
        "\n",
        "            # Allocate stages to nodes with dynamic grouping\n",
        "            allocation = self.dp_allocate(task, stages)\n",
        "\n",
        "            # Assign stages to nodes and update node loads\n",
        "            for stage_id, node in allocation.items():\n",
        "                stage = task.get_stage(stage_id)\n",
        "                stage.assigned_node = node\n",
        "                self.stage_map[stage_id] = stage\n",
        "                node.assigned_stages.append(stage_id)\n",
        "                node.current_load += self.load_metric(\n",
        "                    self.get_execution_time(stage, node),\n",
        "                    self.observation_window\n",
        "                )\n",
        "                # Print allocation details\n",
        "                print(f\"[Scheduler] Allocated Stage '{stage_id}' to Node '{node.node_id}'.\")\n",
        "\n",
        "            # Perform grouping of allocated stages\n",
        "            grouped_allocation = self.group_allocated_stages(task, allocation)\n",
        "\n",
        "            print(f\"[Scheduler] Completed allocation and grouping for Task '{task.task_id}'.\")\n",
        "\n",
        "    def decompose_task_into_stages(self, task: Task) -> List[Stage]:\n",
        "        \"\"\"\n",
        "        Decomposes a Task into multiple Stages (groups of layers).\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance to decompose.\n",
        "\n",
        "        Returns:\n",
        "            List[Stage]: List of Stage instances.\n",
        "        \"\"\"\n",
        "        stages = []\n",
        "        for idx, (name, layer) in enumerate(task.model.named_children()):\n",
        "            # Incorporate layer name into stage_id for easier profiling lookup\n",
        "            stage_id = f\"{task.task_id}-stage-{idx}_{name}\"\n",
        "            stage = Stage(stage_id=stage_id, layers=nn.ModuleList([layer]), assigned_node=None, task=task)\n",
        "            task.add_stage(stage)\n",
        "            stages.append(stage)\n",
        "            # Print stage creation details\n",
        "            print(f\"[Scheduler] Created Stage '{stage_id}' with Layer '{name}'.\")\n",
        "        return stages\n",
        "\n",
        "    def dp_allocate(self, task: Task, stages: List[Stage]) -> Dict[str, 'Node']:\n",
        "        \"\"\"\n",
        "        Allocates stages to nodes using the Dynamic Programming algorithm to minimize maximum node utilization.\n",
        "        Allows grouping of consecutive stages for better load balancing.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance.\n",
        "            stages (List[Stage]): List of Stage instances to allocate.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Node]: Mapping from stage_id to Node.\n",
        "        \"\"\"\n",
        "        num_stages = len(stages)\n",
        "        num_nodes = len(self.nodes)\n",
        "\n",
        "        # Initialize current node loads\n",
        "        w = [node.current_load for node in self.nodes]\n",
        "\n",
        "        # Initialize DP table\n",
        "        M = [[math.inf for _ in range(num_nodes + 1)] for _ in range(num_stages + 1)]\n",
        "        # Base cases\n",
        "        for k in range(num_nodes + 1):\n",
        "            M[0][k] = 0.0\n",
        "\n",
        "        # Fill DP table\n",
        "        for n in range(1, num_stages + 1):\n",
        "            for k in range(1, num_nodes + 1):\n",
        "                for x in range(0, n):\n",
        "                    # Calculate total execution time for grouping stages x to n-1 on node k-1\n",
        "                    grouped_execution_time = sum(\n",
        "                        self.get_execution_time(stages[y], self.nodes[k - 1]) for y in range(x, n)\n",
        "                    )\n",
        "                    util_sum = self.load_metric(grouped_execution_time, self.observation_window)\n",
        "                    current_max = max(M[x][k - 1], w[k - 1] + util_sum)\n",
        "                    if current_max < M[n][k]:\n",
        "                        M[n][k] = current_max\n",
        "\n",
        "        # Backtrack to find allocation\n",
        "        allocation = {}\n",
        "        n = num_stages\n",
        "        k = num_nodes\n",
        "\n",
        "        while n > 0 and k > 0:\n",
        "            for x in range(0, n):\n",
        "                grouped_execution_time = sum(\n",
        "                    self.get_execution_time(stages[y], self.nodes[k - 1]) for y in range(x, n)\n",
        "                )\n",
        "                util_sum = self.load_metric(grouped_execution_time, self.observation_window)\n",
        "                current_max = max(M[x][k - 1], w[k - 1] + util_sum)\n",
        "                if math.isclose(current_max, M[n][k], rel_tol=1e-6):\n",
        "                    # Assign stages x to n-1 to node k-1\n",
        "                    for y in range(x, n):\n",
        "                        stage_id = stages[y].stage_id\n",
        "                        allocation[stage_id] = self.nodes[k - 1]\n",
        "                    n = x\n",
        "                    k = k - 1\n",
        "                    break\n",
        "\n",
        "        # Print allocation details\n",
        "        if allocation:\n",
        "            print(f\"[Scheduler] Allocation Mapping for Task '{task.task_id}':\")\n",
        "            current_node = None\n",
        "            current_group = []\n",
        "            # Sort allocation based on stage index for proper grouping\n",
        "            sorted_allocation = sorted(allocation.items(), key=lambda x: int(x[0].split(\"-stage-\")[1].split(\"_\")[0]))\n",
        "            for stage_id, node in sorted_allocation:\n",
        "                if node != current_node:\n",
        "                    if current_group:\n",
        "                        print(f\"  - Grouped Stages '{', '.join(current_group)}' allocated to Node '{current_node.node_id}'.\")\n",
        "                        current_group = []\n",
        "                    current_node = node\n",
        "                current_group.append(stage_id)\n",
        "            if current_group:\n",
        "                print(f\"  - Grouped Stages '{', '.join(current_group)}' allocated to Node '{current_node.node_id}'.\")\n",
        "        else:\n",
        "            print(f\"[Scheduler] No allocation performed for Task '{task.task_id}'.\")\n",
        "\n",
        "        return allocation\n",
        "\n",
        "    def group_allocated_stages(self, task: Task, allocation: Dict[str, 'Node']) -> Dict[str, 'Node']:\n",
        "        \"\"\"\n",
        "        Groups allocated stages into a single parent stage by merging layers.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance.\n",
        "            allocation (Dict[str, 'Node']): Mapping from stage_id to Node.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, 'Node']: Updated mapping from new grouped stage_id to Node.\n",
        "        \"\"\"\n",
        "        # Identify groups based on allocation\n",
        "        groups = {}\n",
        "        current_node = None\n",
        "        current_group = []\n",
        "        sorted_allocation = sorted(allocation.items(), key=lambda x: int(x[0].split(\"-stage-\")[1].split(\"_\")[0]))\n",
        "        for stage_id, node in sorted_allocation:\n",
        "            if node != current_node:\n",
        "                if current_group:\n",
        "                    if current_node.node_id not in groups:\n",
        "                        groups[current_node.node_id] = []\n",
        "                    groups[current_node.node_id].append(current_group.copy())\n",
        "                    current_group = []\n",
        "                current_node = node\n",
        "                if current_node.node_id not in groups:\n",
        "                    groups[current_node.node_id] = []\n",
        "            current_group.append(stage_id)\n",
        "        if current_group:\n",
        "            if current_node.node_id not in groups:\n",
        "                groups[current_node.node_id] = []\n",
        "            groups[current_node.node_id].append(current_group.copy())\n",
        "\n",
        "        # Merge groups into new parent stages\n",
        "        new_allocation = {}\n",
        "        for node_id, stage_groups in groups.items():\n",
        "            for group in stage_groups:\n",
        "                if len(group) == 1:\n",
        "                    # Single stage, no need to merge\n",
        "                    stage_id = group[0]\n",
        "                    new_allocation[stage_id] = self.nodes[self.get_node_index(node_id)]\n",
        "                else:\n",
        "                    # Merge stages\n",
        "                    new_stage_id = f\"{group[0]}_to_{group[-1]}\"\n",
        "                    merged_layers = nn.ModuleList()\n",
        "                    for stage_id in group:\n",
        "                        stage = task.get_stage(stage_id)\n",
        "                        merged_layers.extend(stage.layers)\n",
        "                    # Create new merged stage\n",
        "                    merged_stage = Stage(stage_id=new_stage_id, layers=merged_layers, assigned_node=self.nodes[self.get_node_index(node_id)], task=task)\n",
        "                    # Update dependencies\n",
        "                    first_stage = task.get_stage(group[0])\n",
        "                    last_stage = task.get_stage(group[-1])\n",
        "\n",
        "                    # Set dependencies\n",
        "                    merged_stage.dependencies = first_stage.dependencies.copy()\n",
        "                    for dep in merged_stage.dependencies:\n",
        "                        dep_stage = task.get_stage(dep)\n",
        "                        dep_stage.dependents.remove(group[0])\n",
        "                        dep_stage.dependents.append(new_stage_id)\n",
        "\n",
        "                    # Set dependents\n",
        "                    merged_stage.dependents = last_stage.dependents.copy()\n",
        "                    for dep in merged_stage.dependents:\n",
        "                        dep_stage = task.get_stage(dep)\n",
        "                        dep_stage.dependencies.remove(group[-1])\n",
        "                        dep_stage.dependencies.append(new_stage_id)\n",
        "\n",
        "                    # Add merged stage to task\n",
        "                    task.add_stage(merged_stage)\n",
        "\n",
        "                    # Remove old stages from task and execution graph\n",
        "                    for stage_id in group:\n",
        "                        del task.stages[stage_id]\n",
        "                        if stage_id in self.stage_map:\n",
        "                            del self.stage_map[stage_id]\n",
        "                        if stage_id in self.execution_graphs[task.task_id]:\n",
        "                            self.execution_graphs[task.task_id].remove_node(stage_id)\n",
        "                        # Remove from node's assigned stages\n",
        "                        node = self.nodes[self.get_node_index(node_id)]\n",
        "                        if stage_id in node.assigned_stages:\n",
        "                            node.assigned_stages.remove(stage_id)\n",
        "\n",
        "                    # Assign merged stage to node\n",
        "                    new_allocation[new_stage_id] = self.nodes[self.get_node_index(node_id)]\n",
        "                    self.stage_map[new_stage_id] = merged_stage\n",
        "                    node = self.nodes[self.get_node_index(node_id)]\n",
        "                    node.assigned_stages.append(new_stage_id)\n",
        "                    node.current_load += self.load_metric(\n",
        "                        self.get_execution_time(merged_stage, node),\n",
        "                        self.observation_window\n",
        "                    )\n",
        "                    print(f\"[Scheduler] Merged Stages '{', '.join(group)}' into '{new_stage_id}' and allocated to Node '{node.node_id}'.\")\n",
        "\n",
        "        # Update execution graph to include merged stages\n",
        "        self.update_execution_graph_after_grouping(task)\n",
        "\n",
        "        return new_allocation\n",
        "\n",
        "    def get_node_index(self, node_id: str) -> int:\n",
        "        \"\"\"\n",
        "        Retrieves the index of a node based on its node_id.\n",
        "\n",
        "        Args:\n",
        "            node_id (str): The Node ID.\n",
        "\n",
        "        Returns:\n",
        "            int: Index of the node in the nodes list.\n",
        "        \"\"\"\n",
        "        for idx, node in enumerate(self.nodes):\n",
        "            if node.node_id == node_id:\n",
        "                return idx\n",
        "        raise ValueError(f\"Node with ID '{node_id}' not found.\")\n",
        "\n",
        "    def update_execution_graph_after_grouping(self, task: Task):\n",
        "        \"\"\"\n",
        "        Updates the execution graph after stages have been merged.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance.\n",
        "        \"\"\"\n",
        "        G = self.execution_graphs.get(task.task_id, None)\n",
        "        if not G:\n",
        "            print(f\"[Scheduler] No execution graph found for Task '{task.task_id}' to update.\")\n",
        "            return\n",
        "\n",
        "        # Rebuild the execution graph based on the updated stages\n",
        "        G.clear()\n",
        "        for stage_id, stage in task.stages.items():\n",
        "            G.add_node(stage_id)\n",
        "            for dep in stage.dependencies:\n",
        "                G.add_edge(dep, stage_id)\n",
        "\n",
        "        print(f\"[Scheduler] Updated execution graph for Task '{task.task_id}'. Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}.\")\n",
        "\n",
        "    def visualize_execution_graph(self, task_id: str):\n",
        "        \"\"\"\n",
        "        Visualizes the execution graph for a given Task.\n",
        "\n",
        "        Args:\n",
        "            task_id (str): The Task ID whose execution graph is to be visualized.\n",
        "        \"\"\"\n",
        "        if task_id not in self.execution_graphs:\n",
        "            print(f\"[Scheduler] No execution graph found for Task '{task_id}'.\")\n",
        "            return\n",
        "\n",
        "        G = self.execution_graphs[task_id]\n",
        "        pos = nx.spring_layout(G)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        nx.draw(\n",
        "            G, pos, with_labels=True,\n",
        "            node_color='lightblue', edge_color='gray',\n",
        "            node_size=2000, font_size=10, arrows=True\n",
        "        )\n",
        "        plt.title(f\"Execution Graph for Task '{task_id}'\")\n",
        "        plt.show()\n",
        "\n",
        "    def get_execution_time(self, stage: Stage, node: 'Node') -> float:\n",
        "        \"\"\"\n",
        "        Retrieves the execution time of a stage on a node by querying the Profiler's profile database.\n",
        "\n",
        "        Args:\n",
        "            stage (Stage): The Stage instance.\n",
        "            node (Node): The Node instance.\n",
        "\n",
        "        Returns:\n",
        "            float: Execution time in seconds. Returns observation_window if not found.\n",
        "        \"\"\"\n",
        "        # Extract layer names from stage_id\n",
        "        try:\n",
        "            # print(stage.stage_id.split('_')[-1])\n",
        "            layer_info = stage.stage_id.split('_',1)[-1]\n",
        "            # Handle grouped stages by splitting '_to_'\n",
        "            layer_names = layer_info.split(\"_to_\")\n",
        "            print(layer_names)\n",
        "        except ValueError:\n",
        "            print(f\"[Scheduler] Warning: Unable to parse layer names from stage_id '{stage.stage_id}'. Assigning max execution time.\")\n",
        "            return self.observation_window\n",
        "\n",
        "        # Sum execution times of all layers in the group\n",
        "        total_exec_time = 0.0\n",
        "        for layer_name in layer_names:\n",
        "            # Remove stage identifier suffix if present\n",
        "            base_layer_name = re.sub(r'(\\.|_)\\d+$', '', layer_name)\n",
        "            query = (\n",
        "                (self.profiler.profile_db['Model'] == stage.task.model_name) &\n",
        "                (self.profiler.profile_db['Layer'] == base_layer_name) &\n",
        "                (self.profiler.profile_db['Compute'] == node.node_id)\n",
        "            )\n",
        "            execution_time_us = self.profiler.profile_db.loc[query, 'Total Execution Time (us)']\n",
        "            if not execution_time_us.empty:\n",
        "                exec_time = execution_time_us.values[0] / 1_000_000  # Convert microseconds to seconds\n",
        "                total_exec_time += exec_time\n",
        "                print(f\"[Scheduler] Retrieved execution time for Layer '{base_layer_name}' on Node '{node.node_id}': {exec_time:.6f} seconds.\")\n",
        "            else:\n",
        "                print(f\"[Scheduler] Warning: No profiling data for Layer '{base_layer_name}' on Node '{node.node_id}'. Assigning max execution time ({self.observation_window} seconds).\")\n",
        "                total_exec_time += self.observation_window\n",
        "\n",
        "        return total_exec_time\n",
        "\n",
        "    def dispatch_allocation(self, allocation: Dict[str, 'Node']):\n",
        "        \"\"\"\n",
        "        Dispatches all allocated stages to their respective nodes for execution.\n",
        "\n",
        "        Args:\n",
        "            allocation (Dict[str, Node]): Mapping from stage_id to Node.\n",
        "        \"\"\"\n",
        "        for stage_id, node in allocation.items():\n",
        "            stage = self.stage_map[stage_id]\n",
        "            self.dispatch_stage(stage)\n",
        "\n",
        "    def dispatch_stage(self, stage: Stage):\n",
        "        \"\"\"\n",
        "        Dispatches a single stage to its assigned node for execution.\n",
        "\n",
        "        Args:\n",
        "            stage (Stage): The Stage instance to dispatch.\n",
        "        \"\"\"\n",
        "        # Set stage.input_data based on dependencies\n",
        "        if stage.dependencies:\n",
        "            # Assuming single dependency\n",
        "            dep_stage_id = stage.dependencies[0]\n",
        "            dep_stage = self.stage_map.get(dep_stage_id, None)\n",
        "            if dep_stage and dep_stage.output_data is not None:\n",
        "                stage.input_data = dep_stage.output_data\n",
        "            else:\n",
        "                print(f\"[Scheduler] Warning: Dependency stage '{dep_stage_id}' output data is None for Stage '{stage.stage_id}'.\")\n",
        "        else:\n",
        "            # For initial stages, input_data is from Task's input_data\n",
        "            stage.input_data = stage.task.input_data\n",
        "\n",
        "        def stage_execution():\n",
        "            try:\n",
        "                stage.run_stage()\n",
        "            finally:\n",
        "                self.stage_completed(stage.stage_id)\n",
        "\n",
        "        # Assign the stage's run_stage method to the node's task queue\n",
        "        node_queue = stage.assigned_node.assign_task(stage_execution)\n",
        "        # Print dispatching details\n",
        "        print(f\"[Scheduler] Dispatched Stage '{stage.stage_id}' to Node '{stage.assigned_node.node_id}'.\")\n",
        "\n",
        "    def execute_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Executes a single Task by dispatching its allocated Stages.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance to execute.\n",
        "        \"\"\"\n",
        "        allocation = {stage_id: stage.assigned_node for stage_id, stage in task.stages.items()}\n",
        "        print(f\"[Scheduler] Executing Task '{task.task_id}' with {len(allocation)} stages.\")\n",
        "        self.dispatch_allocation(allocation)\n",
        "\n",
        "    def execute_task_with_graph(self, task: Task):\n",
        "        \"\"\"\n",
        "        Executes a Task using its execution graph to manage dependencies.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance to execute.\n",
        "        \"\"\"\n",
        "        execution_graph = self.execution_graphs.get(task.task_id, None)\n",
        "        if not execution_graph:\n",
        "            print(f\"[Scheduler] No execution graph found for Task '{task.task_id}'. Cannot execute with graph.\")\n",
        "            return\n",
        "\n",
        "        print(f\"[Scheduler] Starting execution of Task '{task.task_id}' using execution graph.\")\n",
        "\n",
        "        # Perform topological sort to determine execution order\n",
        "        try:\n",
        "            sorted_stages = list(nx.topological_sort(execution_graph))\n",
        "        except nx.NetworkXUnfeasible:\n",
        "            print(f\"[Scheduler] Error: Execution graph for Task '{task.task_id}' has cycles. Cannot proceed.\")\n",
        "            return\n",
        "\n",
        "        for stage_id in sorted_stages:\n",
        "            stage = task.get_stage(stage_id)\n",
        "            if all(dep in self.completed_stages for dep in stage.dependencies):\n",
        "                self.dispatch_stage(stage)\n",
        "\n",
        "        print(f\"[Scheduler] Completed execution dispatch for Task '{task.task_id}'.\")\n",
        "\n",
        "    def stage_completed(self, stage_id: str):\n",
        "        \"\"\"\n",
        "        Called when a stage is completed to trigger dependent stages.\n",
        "\n",
        "        Args:\n",
        "            stage_id (str): The ID of the completed stage.\n",
        "        \"\"\"\n",
        "        with self.lock:\n",
        "            self.completed_stages.add(stage_id)\n",
        "            task_id = self.get_task_id_from_stage(stage_id)\n",
        "            if not task_id:\n",
        "                print(f\"[Scheduler] Warning: Task ID not found for stage '{stage_id}'.\")\n",
        "                return\n",
        "            task = self.tasks.get(task_id)\n",
        "            if not task:\n",
        "                print(f\"[Scheduler] Warning: Task '{task_id}' not found for stage '{stage_id}'.\")\n",
        "                return\n",
        "            stage = task.get_stage(stage_id)\n",
        "            if not stage:\n",
        "                print(f\"[Scheduler] Warning: Stage '{stage_id}' not found in Task '{task_id}'.\")\n",
        "                return\n",
        "            # Trigger dependent stages if all their dependencies are met\n",
        "            for dependent_stage_id in stage.dependents:\n",
        "                dependent_stage = task.get_stage(dependent_stage_id)\n",
        "                if dependent_stage and all(dep in self.completed_stages for dep in dependent_stage.dependencies):\n",
        "                    print(f\"[Scheduler] Dependencies met for Stage '{dependent_stage_id}'. Dispatching for execution.\")\n",
        "                    self.dispatch_stage(dependent_stage)\n",
        "\n",
        "    def get_task_id_from_stage(self, stage_id: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Retrieves the Task ID from a given Stage ID.\n",
        "\n",
        "        Args:\n",
        "            stage_id (str): The Stage ID.\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: The corresponding Task ID, or None if not found.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            task_id, _ = stage_id.split(\"-stage-\")\n",
        "            return task_id\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "    def shutdown(self):\n",
        "        \"\"\"\n",
        "        Shuts down the Scheduler gracefully by stopping all Nodes.\n",
        "        \"\"\"\n",
        "        print(\"[Scheduler] Shutting down all Nodes.\")\n",
        "        for node in self.nodes:\n",
        "            node.stop()\n",
        "        print(\"[Scheduler] All Nodes have been shut down.\")\n",
        "\n",
        "    def calculate_average_utilization(self, task: Task) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the average utilization of a task across all nodes.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance.\n",
        "\n",
        "        Returns:\n",
        "            float: Average utilization.\n",
        "        \"\"\"\n",
        "        total_U = 0.0\n",
        "        count = 0\n",
        "        for stage in task.stages.values():\n",
        "            for node in self.nodes:\n",
        "                total_U += self.load_metric(\n",
        "                    self.get_execution_time(stage, node),\n",
        "                    self.observation_window\n",
        "                )\n",
        "                count += 1\n",
        "        return total_U / count if count > 0 else 0.0\n",
        "\n",
        "    def build_execution_graph(self, task: Task) -> nx.DiGraph:\n",
        "        \"\"\"\n",
        "        Builds an execution graph for a given Task.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The Task instance.\n",
        "\n",
        "        Returns:\n",
        "            nx.DiGraph: Directed graph representing Stage dependencies.\n",
        "        \"\"\"\n",
        "        G = nx.DiGraph()\n",
        "        for stage_id, stage in task.stages.items():\n",
        "            G.add_node(stage_id)\n",
        "            for dep in stage.dependencies:\n",
        "                G.add_edge(dep, stage_id)\n",
        "        return G\n",
        "\n",
        "# --- Evaluator Class ---\n",
        "class Evaluator:\n",
        "    \"\"\"\n",
        "    Evaluator class responsible for running tasks using both naive PyTorch execution and\n",
        "    the custom parallel and pipeline approach. It analyzes speedup, throughput, and\n",
        "    verifies output correctness.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scheduler: 'Scheduler', taskset: 'Taskset', profiler: 'Profiler'):\n",
        "        \"\"\"\n",
        "        Initializes the Evaluator.\n",
        "\n",
        "        Args:\n",
        "            scheduler (Scheduler): The Scheduler instance handling task allocation.\n",
        "            taskset (Taskset): The Taskset containing all tasks to be evaluated.\n",
        "            profiler (Profiler): The Profiler instance for gathering execution metrics.\n",
        "        \"\"\"\n",
        "        self.scheduler = scheduler\n",
        "        self.taskset = taskset\n",
        "        self.profiler = profiler\n",
        "\n",
        "        # Dictionaries to store outputs from both execution methods\n",
        "        self.naive_outputs: Dict[str, torch.Tensor] = {}\n",
        "        self.parallel_outputs: Dict[str, torch.Tensor] = {}\n",
        "\n",
        "        # Execution times\n",
        "        self.naive_execution_times: Dict[str, float] = {}\n",
        "        self.parallel_execution_times: Dict[str, float] = {}\n",
        "\n",
        "    def run_evaluation(self):\n",
        "        \"\"\"\n",
        "        Runs the entire evaluation process: profiling, naive execution, parallel execution,\n",
        "        output comparison, and performance analysis.\n",
        "        \"\"\"\n",
        "        print(\"=== Starting Evaluation ===\\n\")\n",
        "\n",
        "        # Step 1: Set Observation Time\n",
        "        # (Already set in init_phase)\n",
        "\n",
        "        # Step 2: Run Evaluation Phase\n",
        "        # (Handled externally via eval_phase utility function)\n",
        "\n",
        "        print(\"=== Evaluation Completed ===\\n\")\n",
        "\n",
        "    def run_naive_execution(self):\n",
        "        \"\"\"\n",
        "        Executes all evaluation tasks sequentially on a single device (CPU or GPU).\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Starting Naive Execution.\")\n",
        "        for task in self.taskset.tasks:\n",
        "            model = task.model\n",
        "            input_tensor = task.input_data  # Now a single Tensor for evaluation\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)  # Move model to device\n",
        "            input_tensor = input_tensor.to(device)  # Move input to device\n",
        "\n",
        "            start_time = time.time()\n",
        "            with torch.no_grad():\n",
        "                output = model(input_tensor)\n",
        "            end_time = time.time()\n",
        "            exec_time = end_time - start_time\n",
        "            print(f\"[Evaluator] Task '{task.task_id}' (Naive) executed in {exec_time:.6f} seconds.\")\n",
        "            self.naive_execution_times[task.task_id] = exec_time\n",
        "            self.naive_outputs[task.task_id] = output\n",
        "\n",
        "        print(\"[Evaluator] Naive Execution Completed.\\n\")\n",
        "\n",
        "        # Clean up resources\n",
        "        self.cleanup_resources()\n",
        "\n",
        "    def run_parallel_execution(self):\n",
        "        \"\"\"\n",
        "        Executes all tasks in the taskset using the Scheduler's parallel and pipeline approach.\n",
        "        Stores the outputs and execution times for comparison.\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Starting Parallel Execution.\")\n",
        "\n",
        "        # Reset outputs and execution times\n",
        "        self.parallel_outputs = {}\n",
        "        self.parallel_execution_times = {}\n",
        "\n",
        "        # Deep copy tasks to avoid interference\n",
        "        parallel_tasks = copy.deepcopy(self.taskset.tasks)\n",
        "\n",
        "        # Reassign the scheduler to the copied tasks\n",
        "        for task in parallel_tasks:\n",
        "            task.scheduler = self.scheduler\n",
        "\n",
        "        # Assign a separate Taskset for parallel execution\n",
        "        parallel_taskset = Taskset(tasks=parallel_tasks, scheduler=self.scheduler)\n",
        "\n",
        "        # Start parallel execution\n",
        "        parallel_start_time = time.time()\n",
        "        parallel_taskset.execute_all()\n",
        "        parallel_end_time = time.time()\n",
        "        total_parallel_time = parallel_end_time - parallel_start_time\n",
        "\n",
        "        # Collect outputs and execution times\n",
        "        for task in parallel_tasks:\n",
        "            self.parallel_outputs[task.task_id] = task.output_data\n",
        "            self.parallel_execution_times[task.task_id] = task.get_total_execution_time()\n",
        "\n",
        "        print(f\"[Evaluator] Parallel Execution Completed in {total_parallel_time:.6f} seconds.\\n\")\n",
        "\n",
        "        # Clean up resources\n",
        "        self.cleanup_resources()\n",
        "\n",
        "    def compare_outputs(self):\n",
        "        \"\"\"\n",
        "        Compares the outputs from naive and parallel executions to verify correctness.\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Comparing Outputs for Correctness.\")\n",
        "\n",
        "        all_match = True\n",
        "        for task_id in self.naive_outputs:\n",
        "            naive_output = self.naive_outputs.get(task_id)\n",
        "            parallel_output = self.parallel_outputs.get(task_id)\n",
        "\n",
        "            if naive_output is None or parallel_output is None:\n",
        "                print(f\"[Evaluator] Task '{task_id}' missing output in one of the executions.\")\n",
        "                all_match = False\n",
        "                continue\n",
        "\n",
        "            if torch.equal(naive_output, parallel_output):\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs match exactly.\")\n",
        "            elif torch.allclose(naive_output, parallel_output, atol=1e-6):\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs are close within tolerance.\")\n",
        "            else:\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs do NOT match.\")\n",
        "                all_match = False\n",
        "\n",
        "        if all_match:\n",
        "            print(\"[Evaluator] All task outputs match between naive and parallel executions.\\n\")\n",
        "        else:\n",
        "            print(\"[Evaluator] Some task outputs do not match. Investigate discrepancies.\\n\")\n",
        "\n",
        "    def analyze_speedup_throughput(self):\n",
        "        \"\"\"\n",
        "        Analyzes speedup and throughput between naive and parallel executions.\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Analyzing Speedup and Throughput.\")\n",
        "\n",
        "        # Calculate total naive and parallel execution times\n",
        "        total_naive_time = sum(self.naive_execution_times.values())\n",
        "        total_parallel_time = sum(self.parallel_execution_times.values())\n",
        "\n",
        "        # Speedup: naive_time / parallel_time\n",
        "        speedup = total_naive_time / total_parallel_time if total_parallel_time > 0 else float('inf')\n",
        "\n",
        "        # Throughput: number of tasks / total time\n",
        "        num_tasks = len(self.taskset.tasks)\n",
        "        throughput_naive = num_tasks / total_naive_time if total_naive_time > 0 else 0.0\n",
        "        throughput_parallel = num_tasks / total_parallel_time if total_parallel_time > 0 else 0.0\n",
        "\n",
        "        print(f\"[Evaluator] Total Naive Execution Time: {total_naive_time:.6f} seconds.\")\n",
        "        print(f\"[Evaluator] Total Parallel Execution Time: {total_parallel_time:.6f} seconds.\")\n",
        "        print(f\"[Evaluator] Speedup: {speedup:.2f}x.\")\n",
        "        print(f\"[Evaluator] Throughput (Naive): {throughput_naive:.2f} tasks/sec.\")\n",
        "        print(f\"[Evaluator] Throughput (Parallel): {throughput_parallel:.2f} tasks/sec.\\n\")\n",
        "\n",
        "    def cleanup_resources(self):\n",
        "        \"\"\"\n",
        "        Cleans up resources after execution by clearing outputs and resetting node states.\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Cleaning up resources.\")\n",
        "\n",
        "        # Clear stored outputs and execution times\n",
        "        self.naive_outputs.clear()\n",
        "        self.parallel_outputs.clear()\n",
        "        self.naive_execution_times.clear()\n",
        "        self.parallel_execution_times.clear()\n",
        "\n",
        "        # Reset node loads and assigned stages\n",
        "        for node in self.scheduler.nodes:\n",
        "            node.current_load = 0.0\n",
        "            node.assigned_stages.clear()\n",
        "\n",
        "        # Reset Scheduler's completed stages\n",
        "        with self.scheduler.lock:\n",
        "            self.scheduler.completed_stages.clear()\n",
        "\n",
        "        print(\"[Evaluator] Resources cleaned up.\\n\")\n",
        "\n",
        "# --- Utility Functions (Modified to use single Taskset and single tensor inputs) ---\n",
        "def init_phase(profiler: 'Profiler',taskset: 'Taskset', nodes: List['Node'], runs: int = 3, slack_percentage: float = 0.1):\n",
        "    \"\"\"\n",
        "    Executes the initialization phase by running the profiler in 'init' mode multiple times\n",
        "    and calculating the observation window based on profiling data.\n",
        "\n",
        "    Args:\n",
        "        profiler (Profiler): The Profiler instance.\n",
        "        taskset (Taskset): The Taskset containing all tasks to be profiled.\n",
        "        nodes (List[Node]): List of Node instances to profile on.\n",
        "        runs (int, optional): Number of profiling runs. Defaults to 3.\n",
        "        slack_percentage (float, optional): Slack to add to the observation time. Defaults to 0.1 (10%).\n",
        "    \"\"\"\n",
        "    print(\"[Utility] Starting Init Phase.\")\n",
        "    for run in range(1, runs + 1):\n",
        "        print(f\"[Utility] Init Phase Run {run}/{runs}\")\n",
        "        for node in nodes:\n",
        "            for task in taskset.tasks:\n",
        "                profiler.profile_model(\n",
        "                    model=copy.deepcopy(task.model),          # Use a copy to prevent state changes\n",
        "                    input_data=copy.deepcopy(task.input_data),# Ensure input data is fresh\n",
        "                    node=node,\n",
        "                    model_name=task.model_name\n",
        "                )\n",
        "    print(f\"[Utility] Completed Init Phase after {runs} runs.\\n\")\n",
        "\n",
        "    # Calculate Observation Window\n",
        "    profiler.print_profile_db()\n",
        "    total_forward_time = profiler.profile_db['Total Execution Time (us)'].sum() / 1_000_000  # Convert to seconds\n",
        "    observation_window = total_forward_time * (1 + slack_percentage)\n",
        "    profiler.observation_window = observation_window  # Update profiler's observation window\n",
        "\n",
        "    print(f\"[Utility] Observation window set to {observation_window:.6f} seconds (Total Forward Time: {total_forward_time:.6f} + {slack_percentage*100}% slack).\\n\")\n",
        "\n",
        "    taskset.schedule_all_tasks()\n",
        "    print(\"[Taskset/Scheduler] Scheduling all tasks onto the compute\")\n",
        "\n",
        "\n",
        "    return observation_window\n",
        "\n",
        "def eval_phase(evaluator: 'Evaluator', taskset: 'Taskset'):\n",
        "    \"\"\"\n",
        "    Executes the evaluation phase by running naive and parallel executions,\n",
        "    comparing their outputs, and analyzing speedup and throughput.\n",
        "\n",
        "    Args:\n",
        "        evaluator (Evaluator): The Evaluator instance.\n",
        "        taskset (Taskset): The Taskset containing all tasks to be evaluated.\n",
        "    \"\"\"\n",
        "    print(\"[Utility] Starting Evaluation Phase.\")\n",
        "\n",
        "    # Run Naive Execution\n",
        "    evaluator.run_naive_execution()\n",
        "\n",
        "    # Run Parallel Execution\n",
        "    evaluator.run_parallel_execution()\n",
        "\n",
        "    # Compare Outputs\n",
        "    evaluator.compare_outputs()\n",
        "\n",
        "    # Analyze Speedup and Throughput\n",
        "    evaluator.analyze_speedup_throughput()\n",
        "\n",
        "    print(\"[Utility] Evaluation Phase Completed.\\n\")\n",
        "\n",
        "# --- Test Script (Modified to have single Taskset with single tensor inputs) ---\n",
        "# --- Define a Simple Model for Demonstration ---\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.conv1(x))\n",
        "        out = self.relu2(self.conv2(out))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.relu3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# --- Create Synthetic DataLoader ---\n",
        "def create_synthetic_dataloader(batch_size: int = 1, num_samples: int = 1):\n",
        "    inputs = torch.randn(num_samples, 3, 8, 8)  # Example input size\n",
        "    targets = torch.randint(0, 10, (num_samples,))\n",
        "    dataset = TensorDataset(inputs, targets)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "# --- Modified Task Initialization ---\n",
        "def initialize_components():\n",
        "    # Discover Nodes\n",
        "    nodes = Node.discover_nodes()\n",
        "    print(f\"[Main] Discovered Nodes: {nodes}\\n\")\n",
        "\n",
        "    # Initialize Profiler\n",
        "    profiler = Profiler(mode='init')\n",
        "    print(\"[Main] Initialized Profiler.\\n\")\n",
        "\n",
        "    # Initialize Scheduler\n",
        "    scheduler = Scheduler(\n",
        "        nodes=nodes,\n",
        "        profiler=profiler,\n",
        "        observation_window=1000.0  # Initial observation window (will be recalculated)\n",
        "    )\n",
        "    print(\"[Main] Initialized Scheduler.\\n\")\n",
        "\n",
        "    # Create Tasks with Single Tensors for both profiling and evaluation\n",
        "    num_tasks = 5  # Example number of tasks\n",
        "    tasks = []\n",
        "    for i in range(num_tasks):\n",
        "        model = SimpleCNN()\n",
        "        # Create a single input tensor\n",
        "        dataloader = create_synthetic_dataloader(batch_size=1, num_samples=1)\n",
        "        single_input, single_target = next(iter(dataloader))\n",
        "        task = Task(\n",
        "            task_id=f\"task{i+1}\",\n",
        "            model=model,\n",
        "            input_data=single_input,  # input_data is a single Tensor\n",
        "            model_name=model.__class__.__name__,\n",
        "            scheduler=scheduler\n",
        "        )\n",
        "        tasks.append(task)\n",
        "    print(f\"[Main] Created {num_tasks} Tasks.\\n\")\n",
        "\n",
        "    # Initialize Taskset with all tasks\n",
        "    taskset = Taskset(tasks=tasks, scheduler=scheduler)\n",
        "    print(\"[Main] Initialized Taskset.\\n\")\n",
        "\n",
        "    # Initialize Evaluator with the single Taskset\n",
        "    evaluator = Evaluator(\n",
        "        scheduler=scheduler,\n",
        "        taskset=taskset,\n",
        "        profiler=profiler\n",
        "    )\n",
        "    print(\"[Main] Initialized Evaluator.\\n\")\n",
        "\n",
        "    return evaluator, taskset, profiler, scheduler, nodes\n",
        "\n",
        "# --- Run Evaluation ---\n",
        "def run_evaluation():\n",
        "    evaluator, taskset, profiler, scheduler, nodes = initialize_components()\n",
        "\n",
        "    # Run Init Phase with Taskset\n",
        "    init_observation_window = init_phase(profiler, taskset, nodes, runs=3, slack_percentage=0.1)\n",
        "    # for task in taskset.tasks:\n",
        "    #   scheduler.visualize_execution_graph(task.task_id)\n",
        "\n",
        "    # Run Evaluation Phase with Taskset\n",
        "    eval_phase(evaluator, taskset)\n",
        "\n",
        "    # Print Performance Metrics from Taskset\n",
        "    print(\"=== Performance Metrics ===\")\n",
        "    print(taskset)\n",
        "    print(\"============================\\n\")\n",
        "\n",
        "    # Shutdown Scheduler\n",
        "    scheduler.shutdown()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_evaluation()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Unified_Taskset_Evaluation.ipynb\n",
        "\n",
        "This script implements a single Taskset approach, utilizing single tensor inputs for both profiling and evaluation phases.\n",
        "\"\"\"\n",
        "\n",
        "import networkx as nx\n",
        "import os\n",
        "import torch\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.profiler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from typing import Callable, Any, List, Dict, Optional\n",
        "import copy\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# --- Node Class ---\n",
        "class Node:\n",
        "    \"\"\"\n",
        "    Represents a computational resource: either a CPU-only node (1 CPU core)\n",
        "    or a GPU+CPU pair. Each Node has:\n",
        "      - node_id (e.g., 'CPU-0', 'GPU-0-CPU-1')\n",
        "      - A worker thread + queue to run tasks\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, node_id: str, cpus=None, gpu=None):\n",
        "        self._node_id = node_id\n",
        "        self._cpus = tuple(cpus or [])\n",
        "        self._gpu = gpu\n",
        "\n",
        "        self._original_affinity = os.sched_getaffinity(0)\n",
        "        self._task_queue = queue.Queue()\n",
        "        self._stop_signal = False\n",
        "\n",
        "        self._worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n",
        "        self._worker_thread.start()\n",
        "\n",
        "        self.current_load = 0.0  # Initialize current load\n",
        "        self.assigned_stages = []  # List to track assigned stages\n",
        "\n",
        "    @property\n",
        "    def node_id(self):\n",
        "        return self._node_id\n",
        "\n",
        "    @property\n",
        "    def cpus(self):\n",
        "        return self._cpus\n",
        "\n",
        "    @property\n",
        "    def gpu(self):\n",
        "        return self._gpu\n",
        "\n",
        "    def assign_task(self, func: Callable, *args, **kwargs) -> queue.Queue:\n",
        "        \"\"\"\n",
        "        Enqueue a function to this node. Returns a queue from which\n",
        "        the caller can retrieve the result (blocking).\n",
        "        \"\"\"\n",
        "        result_queue = queue.Queue(maxsize=1)\n",
        "        self._task_queue.put((func, args, kwargs, result_queue))\n",
        "        return result_queue\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"\n",
        "        Signal the node to stop after processing queued tasks.\n",
        "        \"\"\"\n",
        "        self._stop_signal = True\n",
        "        self._task_queue.put(None)\n",
        "        self._worker_thread.join()\n",
        "\n",
        "    def _worker_loop(self):\n",
        "        while not self._stop_signal:\n",
        "            item = self._task_queue.get()\n",
        "            if item is None:\n",
        "                break\n",
        "            func, args, kwargs, result_queue = item\n",
        "            try:\n",
        "                self._set_context()\n",
        "                result = func(*args, **kwargs)\n",
        "            except Exception as e:\n",
        "                result = e\n",
        "            finally:\n",
        "                self._reset_context()\n",
        "\n",
        "            result_queue.put(result)\n",
        "\n",
        "    def _set_context(self):\n",
        "        if self._cpus:\n",
        "            os.sched_setaffinity(0, self._cpus)\n",
        "        if self._gpu is not None and torch.cuda.is_available():\n",
        "            torch.cuda.set_device(self._gpu)\n",
        "\n",
        "    def _reset_context(self):\n",
        "        os.sched_setaffinity(0, self._original_affinity)\n",
        "        # Optionally reset GPU device if needed\n",
        "\n",
        "    @staticmethod\n",
        "    def discover_nodes() -> List['Node']:\n",
        "        \"\"\"\n",
        "        Create a Node for each CPU core, and for each GPU+CPU pair.\n",
        "        \"\"\"\n",
        "        nodes = []\n",
        "        num_cpus = os.cpu_count() or 1\n",
        "        ngpus = torch.cuda.device_count()\n",
        "\n",
        "        # CPU-only nodes\n",
        "        for core_id in range(num_cpus):\n",
        "            node = Node(node_id=f\"CPU-{core_id}\", cpus=[core_id])\n",
        "            nodes.append(node)\n",
        "\n",
        "        # GPU+CPU nodes\n",
        "        for g in range(ngpus):\n",
        "            for core_id in range(num_cpus):\n",
        "                node = Node(node_id=f\"GPU-{g}-CPU-{core_id}\", cpus=[core_id], gpu=g)\n",
        "                nodes.append(node)\n",
        "\n",
        "        return nodes\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Node({self._node_id}, cpus={self._cpus}, gpu={self._gpu})\"\n",
        "\n",
        "\n",
        "# --- Profiler Class ---\n",
        "class Profiler:\n",
        "    \"\"\"\n",
        "    In 'init' mode: Gather detailed profiling info for each leaf layer on each Node,\n",
        "    storing results in a CSV-based ProfileDB.\n",
        "    In 'runtime' mode: Potentially gather minimal logs (optional).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode: str, profile_db_path='profiling_results.csv', log_dir='logs'):\n",
        "        assert mode in ['init', 'runtime']\n",
        "        self.mode = mode\n",
        "        self.profile_db_path = profile_db_path\n",
        "        self.log_dir = log_dir\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "\n",
        "        columns = [\n",
        "            'Model', 'Layer', 'Compute',\n",
        "            'Self CPU (us)', 'CPU Total (us)', 'CUDA Total (us)',\n",
        "            'Self CPU Mem (bytes)', 'Self CUDA Mem (bytes)',\n",
        "            'Total Execution Time (us)', 'Total Memory Used (bytes)'\n",
        "        ]\n",
        "        if os.path.exists(self.profile_db_path):\n",
        "            self.profile_db = pd.read_csv(self.profile_db_path)\n",
        "        else:\n",
        "            self.profile_db = pd.DataFrame(columns=columns)\n",
        "\n",
        "        self.runtime_csv = os.path.join(self.log_dir, 'runtime_results.csv')\n",
        "        if not os.path.exists(self.runtime_csv):\n",
        "            rt_cols = ['Model', 'Layer', 'Compute', 'Execution Time (us)']\n",
        "            pd.DataFrame(columns=rt_cols).to_csv(self.runtime_csv, index=False)\n",
        "\n",
        "        # We'll store an 'observation_window' if needed\n",
        "        self.observation_window = 0.0\n",
        "\n",
        "    def _register_hooks(self, model: nn.Module):\n",
        "        def hook_wrapper(layer_name):\n",
        "            def hook(mod, inp, out):\n",
        "                with torch.profiler.record_function(layer_name):\n",
        "                    pass\n",
        "            return hook\n",
        "\n",
        "        for idx, (name, layer) in enumerate(model.named_modules()):\n",
        "            if not isinstance(layer, nn.Sequential) and not isinstance(layer, nn.ModuleList) and layer != model:\n",
        "                layer.register_forward_hook(hook_wrapper(f\"{name}_{idx}\"))\n",
        "\n",
        "    def profile_model(self, model: nn.Module, input_data: Any, node, model_name: str, warmup_iters=3):\n",
        "        \"\"\"\n",
        "        Schedule a profiling task on 'node'. In 'init' mode, we gather\n",
        "        full per-layer times.\n",
        "        \"\"\"\n",
        "        def profiling_task():\n",
        "            device = torch.device(f\"cuda:{node.gpu}\" if node.gpu is not None and torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "\n",
        "            if self.mode == 'init':\n",
        "                # Warmup\n",
        "                with torch.no_grad():\n",
        "                    for _ in range(warmup_iters):\n",
        "                        model(input_data.to(device))\n",
        "                self._profile_init(model, input_data, node, model_name, device)\n",
        "            else:\n",
        "                self._profile_runtime(model, input_data, node, model_name, device)\n",
        "\n",
        "        rq = node.assign_task(profiling_task)\n",
        "        rq.get()  # block until done\n",
        "\n",
        "    def _profile_init(self, model, input_data, node, model_name, device):\n",
        "        self._register_hooks(model)\n",
        "        with torch.profiler.profile(\n",
        "            activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
        "            profile_memory=True\n",
        "        ) as prof:\n",
        "            with torch.no_grad():\n",
        "                model(input_data.to(device))\n",
        "                prof.step()\n",
        "\n",
        "        stats = self._process_events(prof, model, node, runtime=False)\n",
        "        self._update_profile_db(stats, model_name, node, runtime=False)\n",
        "\n",
        "    def _profile_runtime(self, model, input_data, node, model_name, device):\n",
        "        self._register_hooks(model)\n",
        "        with torch.no_grad():\n",
        "            with torch.profiler.profile(\n",
        "                activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA]\n",
        "            ) as prof:\n",
        "                model(input_data.to(device))\n",
        "                prof.step()\n",
        "            stats = self._process_events(prof, model, node, runtime=True)\n",
        "            self._append_runtime_csv(stats, model_name, node)\n",
        "\n",
        "    def _process_events(self, profiler, model, node, runtime=False):\n",
        "        recognized = set()\n",
        "        for n, m in model.named_modules():\n",
        "            if n:\n",
        "                recognized.add(n)\n",
        "\n",
        "        aggregated = {\n",
        "            'forward_pass': dict(self_cpu_time_total=0, cpu_time_total=0, cuda_time_total=0,\n",
        "                                 self_cpu_memory_usage=0, self_cuda_memory_usage=0, compute=node.node_id),\n",
        "            'misc': dict(self_cpu_time_total=0, cpu_time_total=0, cuda_time_total=0,\n",
        "                         self_cpu_memory_usage=0, self_cuda_memory_usage=0, compute=node.node_id)\n",
        "        }\n",
        "\n",
        "        events = list(profiler.events())\n",
        "        found_root = False\n",
        "\n",
        "        def strip_suffix(s):\n",
        "            return re.sub(r'(\\.|_)\\d+$', '', s)\n",
        "\n",
        "        for e in events:\n",
        "            if e.name == \"\":\n",
        "                # Root event (some profiler versions yield blank top-level)\n",
        "                found_root = True\n",
        "                aggregated['forward_pass']['self_cpu_time_total'] += e.self_cpu_time_total\n",
        "                aggregated['forward_pass']['cpu_time_total'] += e.cpu_time_total\n",
        "                aggregated['forward_pass']['cuda_time_total'] += e.device_time_total\n",
        "                if not runtime:\n",
        "                    aggregated['forward_pass']['self_cpu_memory_usage'] += e.self_cpu_memory_usage\n",
        "                    aggregated['forward_pass']['self_cuda_memory_usage'] += e.self_device_memory_usage\n",
        "            else:\n",
        "                base = strip_suffix(e.name)\n",
        "                if base in recognized:\n",
        "                    if base not in aggregated:\n",
        "                        aggregated[base] = dict(\n",
        "                            self_cpu_time_total=0, cpu_time_total=0, cuda_time_total=0,\n",
        "                            self_cpu_memory_usage=0, self_cuda_memory_usage=0,\n",
        "                            compute=node.node_id\n",
        "                        )\n",
        "                    aggregated[base]['self_cpu_time_total'] += e.self_cpu_time_total\n",
        "                    aggregated[base]['cpu_time_total'] += e.cpu_time_total\n",
        "                    aggregated[base]['cuda_time_total'] += e.device_time_total\n",
        "                    if not runtime:\n",
        "                        aggregated[base]['self_cpu_memory_usage'] += e.self_cpu_memory_usage\n",
        "                        aggregated[base]['self_cuda_memory_usage'] += e.self_device_memory_usage\n",
        "                else:\n",
        "                    aggregated['misc']['self_cpu_time_total'] += e.self_cpu_time_total\n",
        "                    aggregated['misc']['cpu_time_total'] += e.cpu_time_total\n",
        "                    aggregated['misc']['cuda_time_total'] += e.device_time_total\n",
        "                    if not runtime:\n",
        "                        aggregated['misc']['self_cpu_memory_usage'] += e.self_cpu_memory_usage\n",
        "                        aggregated['misc']['self_cuda_memory_usage'] += e.self_device_memory_usage\n",
        "\n",
        "        # If no root event found, sum everything else into forward_pass\n",
        "        if not found_root:\n",
        "            # Merge everything else into 'forward_pass'\n",
        "            for k in list(aggregated.keys()):\n",
        "                if k not in ('forward_pass', 'misc'):\n",
        "                    aggregated['forward_pass']['self_cpu_time_total'] += aggregated[k]['self_cpu_time_total']\n",
        "                    aggregated['forward_pass']['cpu_time_total'] += aggregated[k]['cpu_time_total']\n",
        "                    aggregated['forward_pass']['cuda_time_total'] += aggregated[k]['cuda_time_total']\n",
        "                    if not runtime:\n",
        "                        aggregated['forward_pass']['self_cpu_memory_usage'] += aggregated[k]['self_cpu_memory_usage']\n",
        "                        aggregated['forward_pass']['self_cuda_memory_usage'] += aggregated[k]['self_cuda_memory_usage']\n",
        "\n",
        "            aggregated['forward_pass']['self_cpu_time_total'] += aggregated['misc']['self_cpu_time_total']\n",
        "            aggregated['forward_pass']['cpu_time_total'] += aggregated['misc']['cpu_time_total']\n",
        "            aggregated['forward_pass']['cuda_time_total'] += aggregated['misc']['cuda_time_total']\n",
        "            if not runtime:\n",
        "                aggregated['forward_pass']['self_cpu_memory_usage'] += aggregated['misc']['self_cpu_memory_usage']\n",
        "                aggregated['forward_pass']['self_cuda_memory_usage'] += aggregated['misc']['self_cuda_memory_usage']\n",
        "\n",
        "        return aggregated\n",
        "\n",
        "    def _update_profile_db(self, stats, model_name, node, runtime=False):\n",
        "        if runtime:\n",
        "            return\n",
        "        for layer_name, data in stats.items():\n",
        "            total_t = data['cpu_time_total'] + data['cuda_time_total']\n",
        "            total_m = data['self_cpu_memory_usage'] + data['self_cuda_memory_usage']\n",
        "            row = {\n",
        "                'Model': model_name,\n",
        "                'Layer': layer_name,\n",
        "                'Compute': data['compute'],\n",
        "                'Self CPU (us)': data['self_cpu_time_total'],\n",
        "                'CPU Total (us)': data['cpu_time_total'],\n",
        "                'CUDA Total (us)': data['cuda_time_total'],\n",
        "                'Self CPU Mem (bytes)': data['self_cpu_memory_usage'],\n",
        "                'Self CUDA Mem (bytes)': data['self_cuda_memory_usage'],\n",
        "                'Total Execution Time (us)': total_t * 1_000_000,  # Convert to microseconds\n",
        "                'Total Memory Used (bytes)': total_m\n",
        "            }\n",
        "            self.profile_db = self._upsert(self.profile_db, row)\n",
        "        self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "\n",
        "    def _upsert(self, df, row):\n",
        "        mask = (\n",
        "            (df['Model'] == row['Model']) &\n",
        "            (df['Layer'] == row['Layer']) &\n",
        "            (df['Compute'] == row['Compute'])\n",
        "        )\n",
        "        if not df[mask].empty:\n",
        "            existing_time = df.loc[mask, 'Total Execution Time (us)'].max()\n",
        "            if row['Total Execution Time (us)'] > existing_time:\n",
        "                for k, v in row.items():\n",
        "                    df.loc[mask, k] = v\n",
        "        else:\n",
        "            new_row = pd.DataFrame([row])\n",
        "            if not new_row.dropna().empty:\n",
        "                df = pd.concat([df, new_row], ignore_index=True)\n",
        "        return df\n",
        "\n",
        "    def _append_runtime_csv(self, stats, model_name, node):\n",
        "        rows = []\n",
        "        for layer_name, data in stats.items():\n",
        "            exec_time = data['cpu_time_total'] + data['cuda_time_total']\n",
        "            rows.append({\n",
        "                'Model': model_name,\n",
        "                'Layer': layer_name,\n",
        "                'Compute': data['compute'],\n",
        "                'Execution Time (us)': exec_time * 1_000_000  # microseconds\n",
        "            })\n",
        "        if rows:\n",
        "            rdf = pd.read_csv(self.runtime_csv)\n",
        "            rdf = pd.concat([rdf, pd.DataFrame(rows)], ignore_index=True)\n",
        "            rdf.to_csv(self.runtime_csv, index=False)\n",
        "\n",
        "    def get_profile_db(self):\n",
        "        return self.profile_db\n",
        "\n",
        "    def print_profile_db(self):\n",
        "        if self.profile_db.empty:\n",
        "            print(\"ProfileDB is empty.\")\n",
        "        else:\n",
        "            print(\"ProfileDB:\\n\", self.profile_db.to_string(index=False))\n",
        "\n",
        "\n",
        "# --- Stage Class ---\n",
        "class Stage:\n",
        "    \"\"\"\n",
        "    Represents a partitioned segment of a model, assigned to a specific Node.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stage_id: str, layers: nn.ModuleList, assigned_node: 'Node', task: 'Task'):\n",
        "        self.stage_id = stage_id\n",
        "        self.layers = layers\n",
        "        self.assigned_node = assigned_node\n",
        "\n",
        "        self.dependencies: List[str] = []\n",
        "        self.dependents: List[str] = []\n",
        "\n",
        "        self.execution_time: Optional[float] = None\n",
        "        self.input_data: Optional[torch.Tensor] = None\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "        self.transfer_time: float = 0.0\n",
        "\n",
        "        self.task = task\n",
        "\n",
        "    def add_dependency(self, stage_id: str):\n",
        "        self.dependencies.append(stage_id)\n",
        "\n",
        "    def add_dependent(self, stage_id: str):\n",
        "        self.dependents.append(stage_id)\n",
        "\n",
        "    def run_stage(self):\n",
        "        start_time = time.time()\n",
        "        transfer_start = time.time()\n",
        "        try:\n",
        "            device = torch.device(\n",
        "                f\"cuda:{self.assigned_node.gpu}\" if (self.assigned_node.gpu is not None and torch.cuda.is_available())\n",
        "                else \"cpu\"\n",
        "            )\n",
        "\n",
        "            if self.input_data is None:\n",
        "                print(f\"[Stage] {self.stage_id}: No input data provided. Executing with empty tensor.\")\n",
        "                out = torch.tensor([])\n",
        "                transfer_end = time.time()\n",
        "                self.transfer_time += (transfer_end - transfer_start)\n",
        "            else:\n",
        "                inp = self.input_data.to(device)\n",
        "                transfer_end = time.time()\n",
        "                self.transfer_time += (transfer_end - transfer_start)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    out = inp\n",
        "                    for layer in self.layers:\n",
        "                        out = layer(out)\n",
        "\n",
        "                if device.type == 'cuda':\n",
        "                    transfer_start = time.time()\n",
        "                    out = out.cpu()\n",
        "                    transfer_end = time.time()\n",
        "                    self.transfer_time += (transfer_end - transfer_start)\n",
        "\n",
        "            self.output_data = out\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage] {self.stage_id}: Error during execution: {e}\")\n",
        "            self.output_data = None\n",
        "        finally:\n",
        "            end_time = time.time()\n",
        "            self.execution_time = end_time - start_time\n",
        "            print(f\"[Stage] {self.stage_id}: Executed on {self.assigned_node.node_id} in {self.execution_time:.6f} seconds. Transfer Time: {self.transfer_time:.6f} seconds.\")\n",
        "\n",
        "            # Update Task's busy time with both execution and transfer times\n",
        "            self.task.update_busy_time(self.execution_time, self.transfer_time)\n",
        "\n",
        "            # If this is the final stage, set the Task's output data\n",
        "            if not self.dependents:\n",
        "                self.task.set_output_data(self.output_data)\n",
        "\n",
        "            # Notify Scheduler of stage completion\n",
        "            self.task.scheduler.stage_completed(self.stage_id)\n",
        "\n",
        "        return self.output_data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Stage(stage_id={self.stage_id}, node={self.assigned_node.node_id if self.assigned_node else 'None'}, \"\n",
        "                f\"deps={self.dependencies}, exec_time={self.execution_time}, transfer_time={self.transfer_time}, \"\n",
        "                f\"output_data_present={self.output_data is not None})\")\n",
        "\n",
        "    def __deepcopy__(self, memo):\n",
        "        new_stage = Stage(\n",
        "            stage_id=copy.deepcopy(self.stage_id, memo),\n",
        "            layers=copy.deepcopy(self.layers, memo),\n",
        "            assigned_node=self.assigned_node,  # keep the same Node reference\n",
        "            task=None  # or self.task if you prefer\n",
        "        )\n",
        "        new_stage.dependencies = copy.deepcopy(self.dependencies, memo)\n",
        "        new_stage.dependents = copy.deepcopy(self.dependents, memo)\n",
        "        new_stage.execution_time = self.execution_time\n",
        "        new_stage.transfer_time = self.transfer_time\n",
        "        # Optionally copy input/output\n",
        "        new_stage.input_data = copy.deepcopy(self.input_data, memo)\n",
        "        new_stage.output_data = copy.deepcopy(self.output_data, memo)\n",
        "        return new_stage\n",
        "\n",
        "\n",
        "# --- Task Class ---\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Represents a single DNN inference task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_id: str, model: nn.Module, input_data: torch.Tensor, model_name: str, scheduler: 'Scheduler'):\n",
        "        self.task_id = task_id\n",
        "        self.model = model\n",
        "        self.input_data = input_data\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        self.stages: Dict[str, Stage] = {}\n",
        "\n",
        "        self.start_time: Optional[float] = None\n",
        "        self.finish_time: Optional[float] = None\n",
        "\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "        self.busy_time: float = 0.0\n",
        "        self.computation_time: float = 0.0\n",
        "        self.transfer_time: float = 0.0\n",
        "\n",
        "    def add_stage(self, stage: 'Stage'):\n",
        "        if stage.stage_id in self.stages:\n",
        "            raise ValueError(f\"Stage ID {stage.stage_id} already exists in Task {self.task_id}.\")\n",
        "        self.stages[stage.stage_id] = stage\n",
        "\n",
        "    def get_stage(self, stage_id: str) -> Optional['Stage']:\n",
        "        return self.stages.get(stage_id, None)\n",
        "\n",
        "    def get_total_execution_time(self) -> float:\n",
        "        if self.start_time and self.finish_time:\n",
        "            return self.finish_time - self.start_time\n",
        "        return 0.0\n",
        "\n",
        "    def update_busy_time(self, stage_execution_time: float, stage_transfer_time: float = 0.0):\n",
        "        self.busy_time += stage_execution_time\n",
        "        self.transfer_time += stage_transfer_time\n",
        "        self.computation_time += (stage_execution_time - stage_transfer_time)\n",
        "\n",
        "    def set_output_data(self, output: torch.Tensor):\n",
        "        self.output_data = output\n",
        "        self.finish_time = time.time()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Task(task_id={self.task_id}, model_name={self.model_name}, \"\n",
        "                f\"stages={list(self.stages.keys())}, \"\n",
        "                f\"busy_time={self.busy_time:.6f}, transfer_time={self.transfer_time:.6f}, \"\n",
        "                f\"output_data_present={self.output_data is not None})\")\n",
        "\n",
        "    def __deepcopy__(self, memo):\n",
        "        new_task = Task(\n",
        "            task_id=copy.deepcopy(self.task_id, memo),\n",
        "            model=copy.deepcopy(self.model, memo),\n",
        "            input_data=copy.deepcopy(self.input_data, memo),\n",
        "            model_name=copy.deepcopy(self.model_name, memo),\n",
        "            scheduler=None  # exclude to avoid recursion\n",
        "        )\n",
        "        new_task.stages = copy.deepcopy(self.stages, memo)\n",
        "        new_task.start_time = self.start_time\n",
        "        new_task.finish_time = self.finish_time\n",
        "        new_task.output_data = self.output_data\n",
        "        new_task.busy_time = self.busy_time\n",
        "        new_task.computation_time = self.computation_time\n",
        "        new_task.transfer_time = self.transfer_time\n",
        "        return new_task\n",
        "\n",
        "\n",
        "# --- Taskset Class ---\n",
        "class Taskset:\n",
        "    \"\"\"\n",
        "    Manages a collection of Tasks and orchestrates their execution using the Scheduler.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tasks: List['Task'], scheduler: 'Scheduler'):\n",
        "        self.tasks = tasks\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        # Performance Metrics\n",
        "        self.total_utilization: float = 0.0\n",
        "        self.average_turnaround_time: float = 0.0\n",
        "        self.throughput: float = 0.0\n",
        "        self.makespan: float = 0.0\n",
        "        self.task_completion_rate: float = 0.0\n",
        "        self.average_resource_utilization_per_node: Dict[str, float] = {}\n",
        "\n",
        "    def schedule_all_tasks(self):\n",
        "        for task in self.tasks:\n",
        "            self.scheduler.decompose_and_allocate_task(task)\n",
        "\n",
        "    def execute_all(self):\n",
        "        threads = []\n",
        "        for task in self.tasks:\n",
        "            t = threading.Thread(target=self.scheduler.execute_task, args=(task,))\n",
        "            t.start()\n",
        "            threads.append(t)\n",
        "\n",
        "        for t in threads:\n",
        "            t.join()\n",
        "\n",
        "        self.calculate_metrics()\n",
        "\n",
        "    def calculate_metrics(self):\n",
        "        # 1) total_busy_time = sum of (execution_time) across all tasks\n",
        "        total_busy_time = 0.0\n",
        "        for task in self.tasks:\n",
        "            total_busy_time += task.busy_time\n",
        "\n",
        "        # 2) total_available_time = observation_window * #nodes\n",
        "        total_available_time = self.scheduler.observation_window * len(self.scheduler.nodes)\n",
        "        self.total_utilization = (total_busy_time / total_available_time) if total_available_time > 0 else 0.0\n",
        "\n",
        "        # 3) average turnaround\n",
        "        turnaround_times = [task.get_total_execution_time() for task in self.tasks]\n",
        "        if turnaround_times:\n",
        "            self.average_turnaround_time = sum(turnaround_times) / len(turnaround_times)\n",
        "        else:\n",
        "            self.average_turnaround_time = 0.0\n",
        "\n",
        "        # 4) makespan = difference between earliest start and latest finish\n",
        "        start_times = [task.start_time for task in self.tasks if task.start_time is not None]\n",
        "        finish_times = [task.finish_time for task in self.tasks if task.finish_time is not None]\n",
        "        if start_times and finish_times:\n",
        "            earliest_start = min(start_times)\n",
        "            latest_finish = max(finish_times)\n",
        "            self.makespan = latest_finish - earliest_start\n",
        "        else:\n",
        "            self.makespan = 0.0\n",
        "\n",
        "        # 5) throughput = number_of_tasks / makespan\n",
        "        if self.makespan > 0:\n",
        "            self.throughput = len(self.tasks) / self.makespan\n",
        "        else:\n",
        "            self.throughput = 0.0\n",
        "\n",
        "        # 6) task completion rate\n",
        "        completed_tasks = [t for t in self.tasks if t.output_data is not None]\n",
        "        self.task_completion_rate = len(completed_tasks) / len(self.tasks) if self.tasks else 0.0\n",
        "\n",
        "        # 7) average_resource_utilization_per_node\n",
        "        node_utilization = {node.node_id: 0.0 for node in self.scheduler.nodes}\n",
        "        for task in self.tasks:\n",
        "            for stage in task.stages.values():\n",
        "                if stage.execution_time is not None:\n",
        "                    node_utilization[stage.assigned_node.node_id] += (stage.execution_time + stage.transfer_time)\n",
        "        for node in self.scheduler.nodes:\n",
        "            total_node_time = self.scheduler.observation_window\n",
        "            if total_node_time > 0:\n",
        "                self.average_resource_utilization_per_node[node.node_id] = node_utilization[node.node_id] / total_node_time\n",
        "            else:\n",
        "                self.average_resource_utilization_per_node[node.node_id] = 0.0\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"Taskset(total_tasks={len(self.tasks)}, \"\n",
        "            f\"total_utilization={self.total_utilization:.2%}, \"\n",
        "            f\"average_turnaround_time={self.average_turnaround_time:.6f} sec, \"\n",
        "            f\"throughput={self.throughput:.2f} tasks/sec, \"\n",
        "            f\"makespan={self.makespan:.6f} sec, \"\n",
        "            f\"task_completion_rate={self.task_completion_rate:.2%}, \"\n",
        "            f\"avg_util_per_node={self.average_resource_utilization_per_node})\"\n",
        "        )\n",
        "\n",
        "\n",
        "# --- Scheduler Class ---\n",
        "class Scheduler:\n",
        "    \"\"\"\n",
        "    Scheduler class responsible for decomposing tasks into stages,\n",
        "    allocating stages to nodes using DP, dispatching stages for execution,\n",
        "    and managing dependencies via an execution graph.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nodes: List['Node'],\n",
        "        profiler: 'Profiler',\n",
        "        observation_window: float = 1000.0,\n",
        "        load_metric_func: Optional[Callable[[float, float], float]] = None\n",
        "    ):\n",
        "        self.nodes = nodes\n",
        "        self.profiler = profiler\n",
        "        self.observation_window = observation_window\n",
        "        self.load_metric = load_metric_func if load_metric_func else self.default_load_metric\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "        self.tasks: Dict[str, Task] = {}\n",
        "        self.stage_map: Dict[str, Stage] = {}\n",
        "        self.completed_stages: set = set()\n",
        "\n",
        "        # Execution Graphs: task_id -> nx.DiGraph\n",
        "        self.execution_graphs: Dict[str, nx.DiGraph] = {}\n",
        "\n",
        "    def default_load_metric(self, execution_time: float, observation_window: float) -> float:\n",
        "        return execution_time / observation_window\n",
        "\n",
        "    def build_execution_graph(self, task: Task) -> nx.DiGraph:\n",
        "      \"\"\"\n",
        "      Builds an execution graph for a given Task by adding each stage\n",
        "      as a node and adding edges based on dependencies.\n",
        "      \"\"\"\n",
        "      G = nx.DiGraph()\n",
        "      for stage_id, stage in task.stages.items():\n",
        "          G.add_node(stage_id)\n",
        "          for dep_id in stage.dependencies:\n",
        "              G.add_edge(dep_id, stage_id)\n",
        "      return G\n",
        "\n",
        "\n",
        "    def decompose_and_allocate_task(self, task: Task):\n",
        "        with self.lock:\n",
        "            self.tasks[task.task_id] = task\n",
        "            task.start_time = time.time()\n",
        "\n",
        "            print(f\"[Scheduler] Starting decomposition and allocation for Task '{task.task_id}'.\")\n",
        "\n",
        "            # 1) Decompose\n",
        "            stages = self.decompose_task_into_stages(task)\n",
        "\n",
        "            # 2) Build execution graph\n",
        "            exec_graph = self.build_execution_graph(task)\n",
        "            self.execution_graphs[task.task_id] = exec_graph\n",
        "            print(f\"[Scheduler] Built execution graph for Task '{task.task_id}'. \"\n",
        "                  f\"Nodes: {exec_graph.number_of_nodes()}, Edges: {exec_graph.number_of_edges()}.\")\n",
        "\n",
        "            # 3) DP Allocate\n",
        "            allocation = self.dp_allocate(task, stages)\n",
        "\n",
        "            # 4) Assign stages to nodes\n",
        "            for stage_id, node in allocation.items():\n",
        "                stage = task.get_stage(stage_id)\n",
        "                stage.assigned_node = node\n",
        "                self.stage_map[stage_id] = stage\n",
        "                node.assigned_stages.append(stage_id)\n",
        "                node.current_load += self.load_metric(\n",
        "                    self.get_execution_time(stage, node),\n",
        "                    self.observation_window\n",
        "                )\n",
        "                print(f\"[Scheduler] Allocated Stage '{stage_id}' to Node '{node.node_id}'.\")\n",
        "\n",
        "            # 5) Group allocated stages\n",
        "            self.group_allocated_stages(task, allocation)\n",
        "            print(f\"[Scheduler] Completed allocation and grouping for Task '{task.task_id}'.\")\n",
        "\n",
        "    def decompose_task_into_stages(self, task: Task) -> List[Stage]:\n",
        "        \"\"\"\n",
        "        Decompose the model into stages (one layer per stage).\n",
        "        Also link each stage to the previous stage for a linear chain:\n",
        "          stage0 -> stage1 -> stage2 -> ...\n",
        "        \"\"\"\n",
        "        stages = []\n",
        "        previous_stage_id = None\n",
        "\n",
        "        for idx, (name, layer) in enumerate(task.model.named_children()):\n",
        "            stage_id = f\"{task.task_id}-stage-{idx}_{name}\"\n",
        "            stage = Stage(stage_id=stage_id, layers=nn.ModuleList([layer]), assigned_node=None, task=task)\n",
        "            task.add_stage(stage)\n",
        "            stages.append(stage)\n",
        "            print(f\"[Scheduler] Created Stage '{stage_id}' with Layer '{name}'.\")\n",
        "\n",
        "            # Add a linear dependency from the previous stage\n",
        "            if previous_stage_id is not None:\n",
        "                stage.add_dependency(previous_stage_id)\n",
        "                prev_stage = task.get_stage(previous_stage_id)\n",
        "                prev_stage.add_dependent(stage_id)\n",
        "\n",
        "            previous_stage_id = stage_id\n",
        "\n",
        "        return stages\n",
        "\n",
        "    def dp_allocate(self, task: Task, stages: List[Stage]) -> Dict[str, 'Node']:\n",
        "        num_stages = len(stages)\n",
        "        num_nodes = len(self.nodes)\n",
        "\n",
        "        # Current node loads\n",
        "        w = [node.current_load for node in self.nodes]\n",
        "\n",
        "        # DP table M\n",
        "        M = [[math.inf for _ in range(num_nodes + 1)] for _ in range(num_stages + 1)]\n",
        "        for k in range(num_nodes + 1):\n",
        "            M[0][k] = 0.0\n",
        "\n",
        "        # Fill DP\n",
        "        for n in range(1, num_stages + 1):\n",
        "            for k in range(1, num_nodes + 1):\n",
        "                for x in range(0, n):\n",
        "                    grouped_execution_time = sum(\n",
        "                        self.get_execution_time(stages[y], self.nodes[k - 1]) for y in range(x, n)\n",
        "                    )\n",
        "                    util_sum = self.load_metric(grouped_execution_time, self.observation_window)\n",
        "                    current_max = max(M[x][k - 1], w[k - 1] + util_sum)\n",
        "                    if current_max < M[n][k]:\n",
        "                        M[n][k] = current_max\n",
        "\n",
        "        # Backtrack\n",
        "        allocation = {}\n",
        "        n = num_stages\n",
        "        k = num_nodes\n",
        "        while n > 0 and k > 0:\n",
        "            for x in range(0, n):\n",
        "                grouped_execution_time = sum(\n",
        "                    self.get_execution_time(stages[y], self.nodes[k - 1]) for y in range(x, n)\n",
        "                )\n",
        "                util_sum = self.load_metric(grouped_execution_time, self.observation_window)\n",
        "                current_max = max(M[x][k - 1], w[k - 1] + util_sum)\n",
        "                if math.isclose(current_max, M[n][k], rel_tol=1e-6):\n",
        "                    for y in range(x, n):\n",
        "                        allocation[stages[y].stage_id] = self.nodes[k - 1]\n",
        "                    n = x\n",
        "                    k -= 1\n",
        "                    break\n",
        "\n",
        "        # Print final mapping\n",
        "        if allocation:\n",
        "            print(f\"[Scheduler] Allocation Mapping for Task '{task.task_id}':\")\n",
        "            sorted_allocation = sorted(allocation.items(),\n",
        "                                       key=lambda x: int(x[0].split(\"-stage-\")[1].split(\"_\")[0]))\n",
        "            current_node = None\n",
        "            current_group = []\n",
        "            for stage_id, node in sorted_allocation:\n",
        "                if node != current_node:\n",
        "                    if current_group:\n",
        "                        print(f\"  - Grouped Stages '{', '.join(current_group)}' allocated to Node '{current_node.node_id}'.\")\n",
        "                        current_group = []\n",
        "                    current_node = node\n",
        "                current_group.append(stage_id)\n",
        "            if current_group:\n",
        "                print(f\"  - Grouped Stages '{', '.join(current_group)}' allocated to Node '{current_node.node_id}'.\")\n",
        "        else:\n",
        "            print(f\"[Scheduler] No allocation performed for Task '{task.task_id}'.\")\n",
        "\n",
        "        return allocation\n",
        "\n",
        "    def group_allocated_stages(self, task: Task, allocation: Dict[str, 'Node']) -> Dict[str, 'Node']:\n",
        "        \"\"\"\n",
        "        Merge consecutive stages on the same node into one Stage (optional).\n",
        "        \"\"\"\n",
        "        groups = {}\n",
        "        current_node = None\n",
        "        current_group = []\n",
        "        sorted_allocation = sorted(allocation.items(),\n",
        "                                   key=lambda x: int(x[0].split(\"-stage-\")[1].split(\"_\")[0]))\n",
        "        for stage_id, node in sorted_allocation:\n",
        "            if node != current_node:\n",
        "                if current_group:\n",
        "                    if current_node.node_id not in groups:\n",
        "                        groups[current_node.node_id] = []\n",
        "                    groups[current_node.node_id].append(current_group.copy())\n",
        "                    current_group = []\n",
        "                current_node = node\n",
        "                if current_node.node_id not in groups:\n",
        "                    groups[current_node.node_id] = []\n",
        "            current_group.append(stage_id)\n",
        "        if current_group:\n",
        "            if current_node.node_id not in groups:\n",
        "                groups[current_node.node_id] = []\n",
        "            groups[current_node.node_id].append(current_group.copy())\n",
        "\n",
        "        new_allocation = {}\n",
        "        for node_id, stage_groups in groups.items():\n",
        "            for group in stage_groups:\n",
        "                if len(group) == 1:\n",
        "                    # single stage\n",
        "                    stage_id = group[0]\n",
        "                    new_allocation[stage_id] = self.nodes[self.get_node_index(node_id)]\n",
        "                else:\n",
        "                    # Merge\n",
        "                    new_stage_id = f\"{group[0]}_to_{group[-1]}\"\n",
        "                    merged_layers = nn.ModuleList()\n",
        "                    for sid in group:\n",
        "                        st = task.get_stage(sid)\n",
        "                        merged_layers.extend(st.layers)\n",
        "                    merged_stage = Stage(\n",
        "                        stage_id=new_stage_id,\n",
        "                        layers=merged_layers,\n",
        "                        assigned_node=self.nodes[self.get_node_index(node_id)],\n",
        "                        task=task\n",
        "                    )\n",
        "                    # Fix dependencies\n",
        "                    first_stage = task.get_stage(group[0])\n",
        "                    last_stage = task.get_stage(group[-1])\n",
        "                    merged_stage.dependencies = first_stage.dependencies.copy()\n",
        "                    for dep in merged_stage.dependencies:\n",
        "                        dep_st = task.get_stage(dep)\n",
        "                        dep_st.dependents.remove(group[0])\n",
        "                        dep_st.dependents.append(new_stage_id)\n",
        "                    merged_stage.dependents = last_stage.dependents.copy()\n",
        "                    for dp in merged_stage.dependents:\n",
        "                        dp_st = task.get_stage(dp)\n",
        "                        dp_st.dependencies.remove(group[-1])\n",
        "                        dp_st.dependencies.append(new_stage_id)\n",
        "\n",
        "                    # Add to task, remove old\n",
        "                    task.add_stage(merged_stage)\n",
        "                    for sid in group:\n",
        "                        del task.stages[sid]\n",
        "                        if sid in self.stage_map:\n",
        "                            del self.stage_map[sid]\n",
        "                        if sid in self.execution_graphs[task.task_id]:\n",
        "                            self.execution_graphs[task.task_id].remove_node(sid)\n",
        "                        node_ = self.nodes[self.get_node_index(node_id)]\n",
        "                        if sid in node_.assigned_stages:\n",
        "                            node_.assigned_stages.remove(sid)\n",
        "\n",
        "                    new_allocation[new_stage_id] = self.nodes[self.get_node_index(node_id)]\n",
        "                    self.stage_map[new_stage_id] = merged_stage\n",
        "                    node_ = self.nodes[self.get_node_index(node_id)]\n",
        "                    node_.assigned_stages.append(new_stage_id)\n",
        "                    node_.current_load += self.load_metric(\n",
        "                        self.get_execution_time(merged_stage, node_),\n",
        "                        self.observation_window\n",
        "                    )\n",
        "                    print(f\"[Scheduler] Merged Stages '{', '.join(group)}' into '{new_stage_id}' and allocated to Node '{node_.node_id}'.\")\n",
        "\n",
        "        self.update_execution_graph_after_grouping(task)\n",
        "        return new_allocation\n",
        "\n",
        "    def get_node_index(self, node_id: str) -> int:\n",
        "        for i, node in enumerate(self.nodes):\n",
        "            if node.node_id == node_id:\n",
        "                return i\n",
        "        raise ValueError(f\"Node with ID '{node_id}' not found.\")\n",
        "\n",
        "    def update_execution_graph_after_grouping(self, task: Task):\n",
        "        G = self.execution_graphs.get(task.task_id, None)\n",
        "        if not G:\n",
        "            print(f\"[Scheduler] No execution graph for Task '{task.task_id}' to update.\")\n",
        "            return\n",
        "        G.clear()\n",
        "        for sid, st in task.stages.items():\n",
        "            G.add_node(sid)\n",
        "            for dep in st.dependencies:\n",
        "                G.add_edge(dep, sid)\n",
        "        print(f\"[Scheduler] Updated execution graph for Task '{task.task_id}'. \"\n",
        "              f\"Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}.\")\n",
        "\n",
        "    def visualize_execution_graph(self, task_id: str):\n",
        "        if task_id not in self.execution_graphs:\n",
        "            print(f\"[Scheduler] No execution graph found for Task '{task_id}'.\")\n",
        "            return\n",
        "        G = self.execution_graphs[task_id]\n",
        "        pos = nx.spring_layout(G)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray',\n",
        "                node_size=2000, font_size=10, arrows=True)\n",
        "        plt.title(f\"Execution Graph for Task '{task_id}'\")\n",
        "        plt.show()\n",
        "\n",
        "    def get_execution_time(self, stage: Stage, node: 'Node') -> float:\n",
        "        \"\"\"\n",
        "        Look up the layer(s) in the profiler DB. If not found, return observation_window.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            layer_info = stage.stage_id.split('_', 1)[-1]  # after 'stage-#_'\n",
        "            # If grouped, e.g. \"..._to_...\", split\n",
        "            layer_names = layer_info.split(\"_to_\")\n",
        "        except ValueError:\n",
        "            print(f\"[Scheduler] Warning: Unable to parse layer from '{stage.stage_id}'. Using max time.\")\n",
        "            return self.observation_window\n",
        "\n",
        "        total_exec_time = 0.0\n",
        "        for lname in layer_names:\n",
        "            base_layer_name = re.sub(r'(\\.|_)\\d+$', '', lname)\n",
        "            query = (\n",
        "                (self.profiler.profile_db['Model'] == stage.task.model_name) &\n",
        "                (self.profiler.profile_db['Layer'] == base_layer_name) &\n",
        "                (self.profiler.profile_db['Compute'] == node.node_id)\n",
        "            )\n",
        "            execution_time_us = self.profiler.profile_db.loc[query, 'Total Execution Time (us)']\n",
        "            if not execution_time_us.empty:\n",
        "                val_s = execution_time_us.values[0] / 1_000_000\n",
        "                total_exec_time += val_s\n",
        "                print(f\"[Scheduler] Retrieved execution time for Layer '{base_layer_name}' on Node '{node.node_id}': {val_s:.6f} seconds.\")\n",
        "            else:\n",
        "                print(f\"[Scheduler] Warning: No profiling data for Layer '{base_layer_name}' on Node '{node.node_id}'. \"\n",
        "                      f\"Assigning max execution time ({self.observation_window} seconds).\")\n",
        "                total_exec_time += self.observation_window\n",
        "\n",
        "        return total_exec_time\n",
        "\n",
        "    def dispatch_allocation(self, allocation: Dict[str, 'Node']):\n",
        "        for stage_id, node in allocation.items():\n",
        "            stage = self.stage_map[stage_id]\n",
        "            self.dispatch_stage(stage)\n",
        "\n",
        "    def dispatch_stage(self, stage: Stage):\n",
        "        # Transfer the output from dependencies\n",
        "        if stage.dependencies:\n",
        "            dep_id = stage.dependencies[0]\n",
        "            dep_stage = self.stage_map.get(dep_id)\n",
        "            if dep_stage and dep_stage.output_data is not None:\n",
        "                stage.input_data = dep_stage.output_data\n",
        "            else:\n",
        "                print(f\"[Scheduler] Warning: Dependency '{dep_id}' output is None for Stage '{stage.stage_id}'.\")\n",
        "        else:\n",
        "            stage.input_data = stage.task.input_data\n",
        "\n",
        "        def stage_execution():\n",
        "            try:\n",
        "                stage.run_stage()\n",
        "            finally:\n",
        "                self.stage_completed(stage.stage_id)\n",
        "\n",
        "        node_queue = stage.assigned_node.assign_task(stage_execution)\n",
        "        print(f\"[Scheduler] Dispatched Stage '{stage.stage_id}' to Node '{stage.assigned_node.node_id}'.\")\n",
        "\n",
        "    def execute_task(self, task: Task):\n",
        "        allocation = {sid: st.assigned_node for sid, st in task.stages.items()}\n",
        "        print(f\"[Scheduler] Executing Task '{task.task_id}' with {len(allocation)} stages.\")\n",
        "        self.dispatch_allocation(allocation)\n",
        "\n",
        "    def stage_completed(self, stage_id: str):\n",
        "        with self.lock:\n",
        "            self.completed_stages.add(stage_id)\n",
        "            task_id = self.get_task_id_from_stage(stage_id)\n",
        "            if not task_id:\n",
        "                print(f\"[Scheduler] Warning: No Task ID found for stage '{stage_id}'.\")\n",
        "                return\n",
        "            task = self.tasks.get(task_id)\n",
        "            if not task:\n",
        "                print(f\"[Scheduler] Warning: Task '{task_id}' not found for stage '{stage_id}'.\")\n",
        "                return\n",
        "            stage = task.get_stage(stage_id)\n",
        "            if not stage:\n",
        "                print(f\"[Scheduler] Warning: Stage '{stage_id}' not found in Task '{task_id}'.\")\n",
        "                return\n",
        "            # Trigger dependent stages if all deps are done\n",
        "            for dep_id in stage.dependents:\n",
        "                dep_stage = task.get_stage(dep_id)\n",
        "                if dep_stage and all(d in self.completed_stages for d in dep_stage.dependencies):\n",
        "                    print(f\"[Scheduler] Dependencies met for Stage '{dep_id}'. Dispatching.\")\n",
        "                    self.dispatch_stage(dep_stage)\n",
        "\n",
        "    def get_task_id_from_stage(self, stage_id: str) -> Optional[str]:\n",
        "        try:\n",
        "            tid, _ = stage_id.split(\"-stage-\")\n",
        "            return tid\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "    def shutdown(self):\n",
        "        print(\"[Scheduler] Shutting down all Nodes.\")\n",
        "        for node in self.nodes:\n",
        "            node.stop()\n",
        "        print(\"[Scheduler] All Nodes have been shut down.\")\n",
        "\n",
        "\n",
        "# --- Evaluator Class ---\n",
        "class Evaluator:\n",
        "    \"\"\"\n",
        "    Evaluator runs tasks in naive mode vs. parallel mode and compares outputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scheduler: 'Scheduler', taskset: 'Taskset', profiler: 'Profiler'):\n",
        "        self.scheduler = scheduler\n",
        "        self.taskset = taskset\n",
        "        self.profiler = profiler\n",
        "\n",
        "        self.naive_outputs: Dict[str, torch.Tensor] = {}\n",
        "        self.parallel_outputs: Dict[str, torch.Tensor] = {}\n",
        "        self.naive_execution_times: Dict[str, float] = {}\n",
        "        self.parallel_execution_times: Dict[str, float] = {}\n",
        "\n",
        "    def run_evaluation(self):\n",
        "        print(\"=== Starting Evaluation ===\\n\")\n",
        "        print(\"=== Evaluation Completed ===\\n\")\n",
        "\n",
        "    def run_naive_execution(self):\n",
        "        print(\"[Evaluator] Starting Naive Execution.\")\n",
        "        for task in self.taskset.tasks:\n",
        "            model = task.model\n",
        "            input_tensor = task.input_data\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "            input_tensor = input_tensor.to(device)\n",
        "\n",
        "            t0 = time.time()\n",
        "            with torch.no_grad():\n",
        "                output = model(input_tensor)\n",
        "            t1 = time.time()\n",
        "\n",
        "            exec_time = t1 - t0\n",
        "            print(f\"[Evaluator] Task '{task.task_id}' (Naive) executed in {exec_time:.6f} seconds.\")\n",
        "            self.naive_execution_times[task.task_id] = exec_time\n",
        "            self.naive_outputs[task.task_id] = output\n",
        "\n",
        "        print(\"[Evaluator] Naive Execution Completed.\\n\")\n",
        "        self.cleanup_resources()\n",
        "\n",
        "    def run_parallel_execution(self):\n",
        "        print(\"[Evaluator] Starting Parallel Execution.\")\n",
        "        self.parallel_outputs.clear()\n",
        "        self.parallel_execution_times.clear()\n",
        "\n",
        "        # Deep copy tasks\n",
        "        parallel_tasks = copy.deepcopy(self.taskset.tasks)\n",
        "        for t in parallel_tasks:\n",
        "            t.scheduler = self.scheduler\n",
        "\n",
        "        parallel_taskset = Taskset(tasks=parallel_tasks, scheduler=self.scheduler)\n",
        "        parallel_start = time.time()\n",
        "        parallel_taskset.execute_all()\n",
        "        parallel_end = time.time()\n",
        "        total_parallel_time = parallel_end - parallel_start\n",
        "\n",
        "        for t in parallel_tasks:\n",
        "            self.parallel_outputs[t.task_id] = t.output_data\n",
        "            self.parallel_execution_times[t.task_id] = t.get_total_execution_time()\n",
        "\n",
        "        print(f\"[Evaluator] Parallel Execution Completed in {total_parallel_time:.6f} seconds.\\n\")\n",
        "        self.cleanup_resources()\n",
        "\n",
        "    def compare_outputs(self):\n",
        "        print(\"[Evaluator] Comparing Outputs.\")\n",
        "        all_match = True\n",
        "        for task_id in self.naive_outputs:\n",
        "            naive_out = self.naive_outputs[task_id]\n",
        "            parallel_out = self.parallel_outputs.get(task_id, None)\n",
        "            if naive_out is None or parallel_out is None:\n",
        "                print(f\"[Evaluator] Task '{task_id}' missing output in one execution.\")\n",
        "                all_match = False\n",
        "                continue\n",
        "            if torch.equal(naive_out, parallel_out):\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs match exactly.\")\n",
        "            elif torch.allclose(naive_out, parallel_out, atol=1e-5):\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs are close within tolerance.\")\n",
        "            else:\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs do NOT match.\")\n",
        "                all_match = False\n",
        "        if all_match:\n",
        "            print(\"[Evaluator] All outputs match.\\n\")\n",
        "        else:\n",
        "            print(\"[Evaluator] Some outputs differ.\\n\")\n",
        "\n",
        "    def analyze_speedup_throughput(self):\n",
        "        print(\"[Evaluator] Analyzing Speedup.\")\n",
        "        total_naive = sum(self.naive_execution_times.values())\n",
        "        total_parallel = sum(self.parallel_execution_times.values())\n",
        "        speedup = total_naive / total_parallel if total_parallel > 0 else float('inf')\n",
        "        num_tasks = len(self.taskset.tasks)\n",
        "        naive_thr = num_tasks / total_naive if total_naive > 0 else 0\n",
        "        parallel_thr = num_tasks / total_parallel if total_parallel > 0 else 0\n",
        "        print(f\"[Evaluator] Speedup: {speedup:.2f}x. \"\n",
        "              f\"Naive Throughput: {naive_thr:.2f} tasks/s, Parallel Throughput: {parallel_thr:.2f} tasks/s.\\n\")\n",
        "\n",
        "    def cleanup_resources(self):\n",
        "        print(\"[Evaluator] Cleaning up resources.\")\n",
        "        self.naive_outputs.clear()\n",
        "        self.parallel_outputs.clear()\n",
        "        self.naive_execution_times.clear()\n",
        "        self.parallel_execution_times.clear()\n",
        "\n",
        "        # Reset node loads\n",
        "        for node in self.scheduler.nodes:\n",
        "            node.current_load = 0.0\n",
        "            node.assigned_stages.clear()\n",
        "\n",
        "        # Reset completed stages\n",
        "        with self.scheduler.lock:\n",
        "            self.scheduler.completed_stages.clear()\n",
        "\n",
        "        print(\"[Evaluator] Resources cleaned up.\\n\")\n",
        "\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def init_phase(profiler: 'Profiler', taskset: 'Taskset', nodes: List['Node'], runs: int = 3, slack_percentage: float = 0.1):\n",
        "    print(\"[Utility] Starting Init Phase.\")\n",
        "    for run in range(1, runs + 1):\n",
        "        print(f\"[Utility] Init Phase Run {run}/{runs}\")\n",
        "        for node in nodes:\n",
        "            for task in taskset.tasks:\n",
        "                profiler.profile_model(\n",
        "                    model=copy.deepcopy(task.model),\n",
        "                    input_data=copy.deepcopy(task.input_data),\n",
        "                    node=node,\n",
        "                    model_name=task.model_name\n",
        "                )\n",
        "    print(f\"[Utility] Completed Init Phase after {runs} runs.\\n\")\n",
        "    profiler.print_profile_db()\n",
        "\n",
        "    total_forward_time = profiler.profile_db['Total Execution Time (us)'].sum() / 1_000_000\n",
        "    observation_window = total_forward_time * (1 + slack_percentage)\n",
        "    profiler.observation_window = observation_window\n",
        "\n",
        "    print(f\"[Utility] Observation window set to {observation_window:.6f} seconds \"\n",
        "          f\"(Total Forward Time: {total_forward_time:.6f} + {slack_percentage*100}% slack).\\n\")\n",
        "\n",
        "    taskset.scheduler.observation_window = observation_window\n",
        "    taskset.schedule_all_tasks()\n",
        "    print(\"[Taskset/Scheduler] Scheduling all tasks onto the compute\")\n",
        "\n",
        "    return observation_window\n",
        "\n",
        "\n",
        "def eval_phase(evaluator: 'Evaluator', taskset: 'Taskset'):\n",
        "    print(\"[Utility] Starting Evaluation Phase.\")\n",
        "\n",
        "    # 1) Naive\n",
        "    evaluator.run_naive_execution()\n",
        "\n",
        "    # 2) Parallel\n",
        "    evaluator.run_parallel_execution()\n",
        "\n",
        "    # 3) Compare\n",
        "    evaluator.compare_outputs()\n",
        "\n",
        "    # 4) Speedup\n",
        "    evaluator.analyze_speedup_throughput()\n",
        "\n",
        "    print(\"[Utility] Evaluation Phase Completed.\\n\")\n",
        "\n",
        "\n",
        "# --- Simple CNN Model ---\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.conv1(x))\n",
        "        out = self.relu2(self.conv2(out))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.relu3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def create_synthetic_dataloader(batch_size: int = 1, num_samples: int = 1):\n",
        "    inputs = torch.randn(num_samples, 3, 8, 8)\n",
        "    targets = torch.randint(0, 10, (num_samples,))\n",
        "    dataset = TensorDataset(inputs, targets)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def initialize_components():\n",
        "    nodes = Node.discover_nodes()\n",
        "    print(f\"[Main] Discovered Nodes: {nodes}\\n\")\n",
        "\n",
        "    profiler = Profiler(mode='init')\n",
        "    print(\"[Main] Initialized Profiler.\\n\")\n",
        "\n",
        "    scheduler = Scheduler(\n",
        "        nodes=nodes,\n",
        "        profiler=profiler,\n",
        "        observation_window=1000.0\n",
        "    )\n",
        "    print(\"[Main] Initialized Scheduler.\\n\")\n",
        "\n",
        "    num_tasks = 5\n",
        "    tasks = []\n",
        "    for i in range(num_tasks):\n",
        "        model = SimpleCNN()\n",
        "        dl = create_synthetic_dataloader(batch_size=1, num_samples=1)\n",
        "        single_input, _ = next(iter(dl))\n",
        "        task = Task(\n",
        "            task_id=f\"task{i+1}\",\n",
        "            model=model,\n",
        "            input_data=single_input,\n",
        "            model_name=model.__class__.__name__,\n",
        "            scheduler=scheduler\n",
        "        )\n",
        "        tasks.append(task)\n",
        "    print(f\"[Main] Created {num_tasks} Tasks.\\n\")\n",
        "\n",
        "    taskset = Taskset(tasks=tasks, scheduler=scheduler)\n",
        "    print(\"[Main] Initialized Taskset.\\n\")\n",
        "\n",
        "    evaluator = Evaluator(\n",
        "        scheduler=scheduler,\n",
        "        taskset=taskset,\n",
        "        profiler=profiler\n",
        "    )\n",
        "    print(\"[Main] Initialized Evaluator.\\n\")\n",
        "\n",
        "    return evaluator, taskset, profiler, scheduler, nodes\n",
        "\n",
        "\n",
        "def run_evaluation():\n",
        "    evaluator, taskset, profiler, scheduler, nodes = initialize_components()\n",
        "\n",
        "    # Init Phase\n",
        "    init_observation_window = init_phase(profiler, taskset, nodes, runs=3, slack_percentage=0.1)\n",
        "\n",
        "    # Evaluation Phase\n",
        "    eval_phase(evaluator, taskset)\n",
        "\n",
        "    # Print final metrics\n",
        "    print(\"=== Performance Metrics ===\")\n",
        "    print(taskset)\n",
        "    print(\"===========================\")\n",
        "\n",
        "    # Shutdown\n",
        "    scheduler.shutdown()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_evaluation()\n"
      ],
      "metadata": {
        "id": "ntQMuJNFfDR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c91602-8f24-4775-aef9-5b7db9e1de4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Main] Discovered Nodes: [Node(CPU-0, cpus=(0,), gpu=None), Node(CPU-1, cpus=(1,), gpu=None), Node(GPU-0-CPU-0, cpus=(0,), gpu=0), Node(GPU-0-CPU-1, cpus=(1,), gpu=0)]\n",
            "\n",
            "[Main] Initialized Profiler.\n",
            "\n",
            "[Main] Initialized Scheduler.\n",
            "\n",
            "[Main] Created 5 Tasks.\n",
            "\n",
            "[Main] Initialized Taskset.\n",
            "\n",
            "[Main] Initialized Evaluator.\n",
            "\n",
            "[Utility] Starting Init Phase.\n",
            "[Utility] Init Phase Run 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-cf9bd4ee21c3>:327: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Utility] Init Phase Run 2/3\n",
            "[Utility] Init Phase Run 3/3\n",
            "[Utility] Completed Init Phase after 3 runs.\n",
            "\n",
            "ProfileDB:\n",
            "     Model        Layer     Compute  Self CPU (us)  CPU Total (us) CUDA Total (us) Self CPU Mem (bytes) Self CUDA Mem (bytes)  Total Execution Time (us) Total Memory Used (bytes)\n",
            "SimpleCNN forward_pass       CPU-0     145935.871      161809.978               0                    0                     0               1.618100e+11                         0\n",
            "SimpleCNN         misc       CPU-0     145614.326      161488.433               0                    0                     0               1.614884e+11                         0\n",
            "SimpleCNN        conv1       CPU-0         84.699          84.699               0                    0                     0               8.469900e+07                         0\n",
            "SimpleCNN        relu1       CPU-0         61.206          61.206               0                    0                     0               6.120600e+07                         0\n",
            "SimpleCNN        conv2       CPU-0         47.892          47.892               0                    0                     0               4.789200e+07                         0\n",
            "SimpleCNN        relu2       CPU-0         39.621          39.621               0                    0                     0               3.962100e+07                         0\n",
            "SimpleCNN          fc1       CPU-0         85.957          85.957               0                    0                     0               8.595700e+07                         0\n",
            "SimpleCNN        relu3       CPU-0         44.814          44.814               0                    0                     0               4.481400e+07                         0\n",
            "SimpleCNN          fc2       CPU-0         40.110          40.110               0                    0                     0               4.011000e+07                         0\n",
            "SimpleCNN forward_pass       CPU-1        853.288        2063.086               0                    0                     0               2.063086e+09                         0\n",
            "SimpleCNN         misc       CPU-1        496.931        1706.729               0                    0                     0               1.706729e+09                         0\n",
            "SimpleCNN        conv1       CPU-1         78.503          78.503               0                    0                     0               7.850300e+07                         0\n",
            "SimpleCNN        relu1       CPU-1         73.788          73.788               0                    0                     0               7.378800e+07                         0\n",
            "SimpleCNN        conv2       CPU-1         57.796          57.796               0                    0                     0               5.779600e+07                         0\n",
            "SimpleCNN        relu2       CPU-1         68.112          68.112               0                    0                     0               6.811200e+07                         0\n",
            "SimpleCNN          fc1       CPU-1         56.455          56.455               0                    0                     0               5.645500e+07                         0\n",
            "SimpleCNN        relu3       CPU-1         51.603          51.603               0                    0                     0               5.160300e+07                         0\n",
            "SimpleCNN          fc2       CPU-1         53.109          53.109               0                    0                     0               5.310900e+07                         0\n",
            "SimpleCNN forward_pass GPU-0-CPU-0       6364.225       19160.805         294.784                    0                     0               1.945559e+10                         0\n",
            "SimpleCNN         misc GPU-0-CPU-0       6096.421       18893.001         294.784                    0                     0               1.918778e+10                         0\n",
            "SimpleCNN        conv1 GPU-0-CPU-0         87.288          87.288               0                    0                     0               8.728800e+07                         0\n",
            "SimpleCNN        relu1 GPU-0-CPU-0         48.243          48.243               0                    0                     0               4.824300e+07                         0\n",
            "SimpleCNN        conv2 GPU-0-CPU-0         76.364          76.364               0                    0                     0               7.636400e+07                         0\n",
            "SimpleCNN        relu2 GPU-0-CPU-0         32.158          32.158               0                    0                     0               3.215800e+07                         0\n",
            "SimpleCNN          fc1 GPU-0-CPU-0         50.924          50.924               0                    0                     0               5.092400e+07                         0\n",
            "SimpleCNN        relu3 GPU-0-CPU-0         58.481          58.481               0                    0                     0               5.848100e+07                         0\n",
            "SimpleCNN          fc2 GPU-0-CPU-0         54.420          54.420               0                    0                     0               5.442000e+07                         0\n",
            "SimpleCNN forward_pass GPU-0-CPU-1       4006.728       12160.878         291.872                    0                     0               1.245275e+10                         0\n",
            "SimpleCNN         misc GPU-0-CPU-1       3775.723       11929.873         291.872                    0                     0               1.222174e+10                         0\n",
            "SimpleCNN        conv1 GPU-0-CPU-1         97.773          97.773               0                    0                     0               9.777300e+07                         0\n",
            "SimpleCNN        relu1 GPU-0-CPU-1        103.290         103.290               0                    0                     0               1.032900e+08                         0\n",
            "SimpleCNN        conv2 GPU-0-CPU-1         59.520          59.520               0                    0                     0               5.952000e+07                         0\n",
            "SimpleCNN        relu2 GPU-0-CPU-1         57.010          57.010               0                    0                     0               5.701000e+07                         0\n",
            "SimpleCNN          fc1 GPU-0-CPU-1         72.662          72.662               0                    0                     0               7.266200e+07                         0\n",
            "SimpleCNN        relu3 GPU-0-CPU-1         58.181          58.181               0                    0                     0               5.818100e+07                         0\n",
            "SimpleCNN          fc2 GPU-0-CPU-1         52.273          52.273               0                    0                     0               5.227300e+07                         0\n",
            "[Utility] Observation window set to 431352.181700 seconds (Total Forward Time: 392138.347000 + 10.0% slack).\n",
            "\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task1'.\n",
            "[Scheduler] Created Stage 'task1-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task1-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task1-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task1-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task1-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task1-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task1-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task1'. Nodes: 7, Edges: 6.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task1':\n",
            "  - Grouped Stages 'task1-stage-0_conv1' allocated to Node 'CPU-0'.\n",
            "  - Grouped Stages 'task1-stage-1_relu1, task1-stage-2_conv2' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task1-stage-3_relu2, task1-stage-4_fc1' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task1-stage-5_relu3, task1-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-4_fc1' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-1_relu1' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-2_conv2' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Allocated Stage 'task1-stage-0_conv1' to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task1-stage-2_conv2' on Node 'CPU-1'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task1-stage-1_relu1, task1-stage-2_conv2' into 'task1-stage-1_relu1_to_task1-stage-2_conv2' and allocated to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task1-stage-4_fc1' on Node 'GPU-0-CPU-0'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task1-stage-3_relu2, task1-stage-4_fc1' into 'task1-stage-3_relu2_to_task1-stage-4_fc1' and allocated to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task1-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task1-stage-5_relu3, task1-stage-6_fc2' into 'task1-stage-5_relu3_to_task1-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task1'. Nodes: 4, Edges: 3.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task1'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task2'.\n",
            "[Scheduler] Created Stage 'task2-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task2-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task2-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task2-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task2-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task2-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task2-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task2'. Nodes: 7, Edges: 6.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task2':\n",
            "  - Grouped Stages 'task2-stage-0_conv1, task2-stage-1_relu1, task2-stage-2_conv2, task2-stage-3_relu2' allocated to Node 'CPU-0'.\n",
            "  - Grouped Stages 'task2-stage-4_fc1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task2-stage-5_relu3' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task2-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-5_relu3' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-4_fc1' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-0_conv1' to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-1_relu1' to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-2_conv2' to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Allocated Stage 'task2-stage-3_relu2' to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task2-stage-3_relu2' on Node 'CPU-0'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task2-stage-0_conv1, task2-stage-1_relu1, task2-stage-2_conv2, task2-stage-3_relu2' into 'task2-stage-0_conv1_to_task2-stage-3_relu2' and allocated to Node 'CPU-0'.\n",
            "[Scheduler] Updated execution graph for Task 'task2'. Nodes: 4, Edges: 3.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task2'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task3'.\n",
            "[Scheduler] Created Stage 'task3-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task3-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task3-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task3-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task3-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task3-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task3-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task3'. Nodes: 7, Edges: 6.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task3':\n",
            "  - Grouped Stages 'task3-stage-0_conv1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task3-stage-1_relu1, task3-stage-2_conv2, task3-stage-3_relu2, task3-stage-4_fc1' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task3-stage-5_relu3, task3-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-1_relu1' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-2_conv2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-4_fc1' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Allocated Stage 'task3-stage-0_conv1' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task3-stage-4_fc1' on Node 'GPU-0-CPU-0'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task3-stage-1_relu1, task3-stage-2_conv2, task3-stage-3_relu2, task3-stage-4_fc1' into 'task3-stage-1_relu1_to_task3-stage-4_fc1' and allocated to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task3-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task3-stage-5_relu3, task3-stage-6_fc2' into 'task3-stage-5_relu3_to_task3-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task3'. Nodes: 3, Edges: 2.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task3'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task4'.\n",
            "[Scheduler] Created Stage 'task4-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task4-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task4-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task4-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task4-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task4-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task4-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task4'. Nodes: 7, Edges: 6.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task4':\n",
            "  - Grouped Stages 'task4-stage-0_conv1, task4-stage-1_relu1' allocated to Node 'CPU-0'.\n",
            "  - Grouped Stages 'task4-stage-2_conv2, task4-stage-3_relu2, task4-stage-4_fc1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task4-stage-5_relu3' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task4-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-5_relu3' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-2_conv2' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-3_relu2' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-4_fc1' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-0_conv1' to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Allocated Stage 'task4-stage-1_relu1' to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task4-stage-1_relu1' on Node 'CPU-0'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task4-stage-0_conv1, task4-stage-1_relu1' into 'task4-stage-0_conv1_to_task4-stage-1_relu1' and allocated to Node 'CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task4-stage-4_fc1' on Node 'CPU-1'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task4-stage-2_conv2, task4-stage-3_relu2, task4-stage-4_fc1' into 'task4-stage-2_conv2_to_task4-stage-4_fc1' and allocated to Node 'CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task4'. Nodes: 4, Edges: 3.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task4'.\n",
            "[Scheduler] Starting decomposition and allocation for Task 'task5'.\n",
            "[Scheduler] Created Stage 'task5-stage-0_conv1' with Layer 'conv1'.\n",
            "[Scheduler] Created Stage 'task5-stage-1_relu1' with Layer 'relu1'.\n",
            "[Scheduler] Created Stage 'task5-stage-2_conv2' with Layer 'conv2'.\n",
            "[Scheduler] Created Stage 'task5-stage-3_relu2' with Layer 'relu2'.\n",
            "[Scheduler] Created Stage 'task5-stage-4_fc1' with Layer 'fc1'.\n",
            "[Scheduler] Created Stage 'task5-stage-5_relu3' with Layer 'relu3'.\n",
            "[Scheduler] Created Stage 'task5-stage-6_fc2' with Layer 'fc2'.\n",
            "[Scheduler] Built execution graph for Task 'task5'. Nodes: 7, Edges: 6.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-0': 84.699000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-0': 61.206000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-0': 47.892000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-0': 39.621000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-0': 85.957000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-0': 44.814000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-0': 40.110000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'CPU-1': 73.788000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'CPU-1': 57.796000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'CPU-1': 68.112000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'CPU-1': 56.455000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'CPU-1': 51.603000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'CPU-1': 53.109000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-0': 50.924000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-0': 58.481000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-0': 54.420000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-1': 97.773000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-1': 103.290000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-1': 59.520000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-1': 57.010000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'GPU-0-CPU-0': 87.288000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Allocation Mapping for Task 'task5':\n",
            "  - Grouped Stages 'task5-stage-0_conv1' allocated to Node 'CPU-1'.\n",
            "  - Grouped Stages 'task5-stage-1_relu1, task5-stage-2_conv2, task5-stage-3_relu2' allocated to Node 'GPU-0-CPU-0'.\n",
            "  - Grouped Stages 'task5-stage-4_fc1, task5-stage-5_relu3, task5-stage-6_fc2' allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-4_fc1' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu3' on Node 'GPU-0-CPU-1': 58.181000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-5_relu3' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc2' on Node 'GPU-0-CPU-1': 52.273000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-1_relu1' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv2' on Node 'GPU-0-CPU-0': 76.364000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-2_conv2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu2' on Node 'GPU-0-CPU-0': 32.158000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'conv1' on Node 'CPU-1': 78.503000 seconds.\n",
            "[Scheduler] Allocated Stage 'task5-stage-0_conv1' to Node 'CPU-1'.\n",
            "[Scheduler] Retrieved execution time for Layer 'relu1' on Node 'GPU-0-CPU-0': 48.243000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task5-stage-3_relu2' on Node 'GPU-0-CPU-0'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task5-stage-1_relu1, task5-stage-2_conv2, task5-stage-3_relu2' into 'task5-stage-1_relu1_to_task5-stage-3_relu2' and allocated to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Retrieved execution time for Layer 'fc1' on Node 'GPU-0-CPU-1': 72.662000 seconds.\n",
            "[Scheduler] Warning: No profiling data for Layer 'task5-stage-6_fc2' on Node 'GPU-0-CPU-1'. Assigning max execution time (431352.1817 seconds).\n",
            "[Scheduler] Merged Stages 'task5-stage-4_fc1, task5-stage-5_relu3, task5-stage-6_fc2' into 'task5-stage-4_fc1_to_task5-stage-6_fc2' and allocated to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Updated execution graph for Task 'task5'. Nodes: 3, Edges: 2.\n",
            "[Scheduler] Completed allocation and grouping for Task 'task5'.\n",
            "[Taskset/Scheduler] Scheduling all tasks onto the compute\n",
            "[Utility] Starting Evaluation Phase.\n",
            "[Evaluator] Starting Naive Execution.\n",
            "[Evaluator] Task 'task1' (Naive) executed in 0.006171 seconds.\n",
            "[Evaluator] Task 'task2' (Naive) executed in 0.000447 seconds.\n",
            "[Evaluator] Task 'task3' (Naive) executed in 0.000493 seconds.\n",
            "[Evaluator] Task 'task4' (Naive) executed in 0.000731 seconds.\n",
            "[Evaluator] Task 'task5' (Naive) executed in 0.000512 seconds.\n",
            "[Evaluator] Naive Execution Completed.\n",
            "\n",
            "[Evaluator] Cleaning up resources.\n",
            "[Evaluator] Resources cleaned up.\n",
            "\n",
            "[Evaluator] Starting Parallel Execution.\n",
            "[Scheduler] Executing Task 'task1' with 4 stages.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-0_conv1' to Node 'CPU-0'.\n",
            "[Scheduler] Warning: Dependency 'task1-stage-0_conv1' output is None for Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2'.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2' to Node 'CPU-1'.\n",
            "[Scheduler] Warning: Dependency 'task1-stage-1_relu1_to_task1-stage-2_conv2' output is None for Stage 'task1-stage-3_relu2_to_task1-stage-4_fc1'.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-3_relu2_to_task1-stage-4_fc1' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Executing Task 'task2' with 4 stages.[Scheduler] Warning: Dependency 'task1-stage-3_relu2_to_task1-stage-4_fc1' output is None for Stage 'task1-stage-5_relu3_to_task1-stage-6_fc2'.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-5_relu3_to_task1-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Stage] task1-stage-1_relu1_to_task1-stage-2_conv2: No input data provided. Executing with empty tensor.\n",
            "[Stage] task1-stage-1_relu1_to_task1-stage-2_conv2: Executed on CPU-1 in 0.000349 seconds. Transfer Time: 0.000346 seconds.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task1-stage-1_relu1_to_task1-stage-2_conv2'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task1-stage-1_relu1_to_task1-stage-2_conv2'.\n",
            "[Scheduler] Executing Task 'task3' with 3 stages.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-0_conv1' to Node 'CPU-1'.\n",
            "[Scheduler] Warning: Dependency 'task3-stage-0_conv1' output is None for Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1' to Node 'GPU-0-CPU-0'.\n",
            "[Stage] task1-stage-5_relu3_to_task1-stage-6_fc2: No input data provided. Executing with empty tensor.\n",
            "[Stage] task1-stage-5_relu3_to_task1-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.000205 seconds. Transfer Time: 0.000202 seconds.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task1-stage-5_relu3_to_task1-stage-6_fc2'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task1-stage-5_relu3_to_task1-stage-6_fc2'.\n",
            "[Scheduler] Executing Task 'task4' with 4 stages.\n",
            "\n",
            "[Scheduler] Warning: Dependency 'task2-stage-0_conv1_to_task2-stage-3_relu2' output is None for Stage 'task2-stage-4_fc1'.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-4_fc1' to Node 'CPU-1'.\n",
            "[Scheduler] Warning: Dependency 'task2-stage-4_fc1' output is None for Stage 'task2-stage-5_relu3'.\n",
            "[Scheduler] Warning: Dependency 'task3-stage-1_relu1_to_task3-stage-4_fc1' output is None for Stage 'task3-stage-5_relu3_to_task3-stage-6_fc2'.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-5_relu3' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Warning: Dependency 'task2-stage-5_relu3' output is None for Stage 'task2-stage-6_fc2'.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-0_conv1_to_task2-stage-3_relu2' to Node 'CPU-0'.\n",
            "[Stage] task2-stage-6_fc2: No input data provided. Executing with empty tensor.\n",
            "[Stage] task2-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.000167 seconds. Transfer Time: 0.000164 seconds.\n",
            "[Scheduler] Executing Task 'task5' with 3 stages.\n",
            "[Scheduler] Warning: Dependency 'task4-stage-2_conv2_to_task4-stage-4_fc1' output is None for Stage 'task4-stage-5_relu3'.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-5_relu3' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-5_relu3_to_task3-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Warning: Dependency 'task4-stage-5_relu3' output is None for Stage 'task4-stage-6_fc2'.[Stage] task3-stage-5_relu3_to_task3-stage-6_fc2: No input data provided. Executing with empty tensor.\n",
            "[Stage] task3-stage-5_relu3_to_task3-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.000108 seconds. Transfer Time: 0.000106 seconds.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task3-stage-5_relu3_to_task3-stage-6_fc2'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task3-stage-5_relu3_to_task3-stage-6_fc2'.\n",
            "[Scheduler] Dispatched Stage 'task5-stage-0_conv1' to Node 'CPU-1'.\n",
            "[Scheduler] Warning: Dependency 'task5-stage-0_conv1' output is None for Stage 'task5-stage-1_relu1_to_task5-stage-3_relu2'.\n",
            "[Scheduler] Dispatched Stage 'task5-stage-1_relu1_to_task5-stage-3_relu2' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Warning: Dependency 'task5-stage-1_relu1_to_task5-stage-3_relu2' output is None for Stage 'task5-stage-4_fc1_to_task5-stage-6_fc2'.[Stage] task1-stage-3_relu2_to_task1-stage-4_fc1: No input data provided. Executing with empty tensor.\n",
            "[Stage] task1-stage-3_relu2_to_task1-stage-4_fc1: Executed on GPU-0-CPU-0 in 0.000240 seconds. Transfer Time: 0.000238 seconds.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task1-stage-3_relu2_to_task1-stage-4_fc1'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task1-stage-3_relu2_to_task1-stage-4_fc1'.\n",
            "[Stage] task3-stage-1_relu1_to_task3-stage-4_fc1: No input data provided. Executing with empty tensor.\n",
            "[Stage] task3-stage-1_relu1_to_task3-stage-4_fc1: Executed on GPU-0-CPU-0 in 0.000058 seconds. Transfer Time: 0.000056 seconds.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'.\n",
            "[Stage] task2-stage-5_relu3: No input data provided. Executing with empty tensor.\n",
            "[Stage] task2-stage-5_relu3: Executed on GPU-0-CPU-0 in 0.000069 seconds. Transfer Time: 0.000067 seconds.\n",
            "[Scheduler] Dependencies met for Stage 'task2-stage-6_fc2'. Dispatching.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Dependencies met for Stage 'task2-stage-6_fc2'. Dispatching.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Stage] task4-stage-5_relu3: No input data provided. Executing with empty tensor.\n",
            "[Stage] task4-stage-5_relu3: Executed on GPU-0-CPU-0 in 0.000060 seconds. Transfer Time: 0.000058 seconds.\n",
            "[Scheduler] Dependencies met for Stage 'task4-stage-6_fc2'. Dispatching.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Dependencies met for Stage 'task4-stage-6_fc2'. Dispatching.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Stage] task5-stage-1_relu1_to_task5-stage-3_relu2: No input data provided. Executing with empty tensor.\n",
            "[Stage] task5-stage-1_relu1_to_task5-stage-3_relu2: Executed on GPU-0-CPU-0 in 0.000088 seconds. Transfer Time: 0.000087 seconds.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task5-stage-1_relu1_to_task5-stage-3_relu2'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task5-stage-1_relu1_to_task5-stage-3_relu2'.\n",
            "\n",
            "[Scheduler] Dispatched Stage 'task4-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-0_conv1_to_task4-stage-1_relu1' to Node 'CPU-0'.\n",
            "[Scheduler] Warning: Dependency 'task4-stage-0_conv1_to_task4-stage-1_relu1' output is None for Stage 'task4-stage-2_conv2_to_task4-stage-4_fc1'.\n",
            "[Scheduler] Dispatched Stage 'task4-stage-2_conv2_to_task4-stage-4_fc1' to Node 'CPU-1'.\n",
            "\n",
            "[Scheduler] Dispatched Stage 'task5-stage-4_fc1_to_task5-stage-6_fc2' to Node 'GPU-0-CPU-1'.\n",
            "[Evaluator] Parallel Execution Completed in 0.035579 seconds.\n",
            "\n",
            "[Evaluator] Cleaning up resources.\n",
            "[Evaluator] Resources cleaned up.\n",
            "\n",
            "[Evaluator] Comparing Outputs.\n",
            "[Evaluator] All outputs match.\n",
            "\n",
            "[Evaluator] Analyzing Speedup.\n",
            "[Evaluator] Speedup: infx. Naive Throughput: 0.00 tasks/s, Parallel Throughput: 0.00 tasks/s.\n",
            "\n",
            "[Utility] Evaluation Phase Completed.\n",
            "\n",
            "=== Performance Metrics ===\n",
            "Taskset(total_tasks=5, total_utilization=0.00%, average_turnaround_time=0.000000 sec, throughput=0.00 tasks/sec, makespan=0.000000 sec, task_completion_rate=0.00%, avg_util_per_node={})\n",
            "===========================\n",
            "[Scheduler] Shutting down all Nodes.\n",
            "[Stage] task2-stage-6_fc2: Error during execution: mat1 and mat2 shapes cannot be multiplied (1x0 and 64x10)\n",
            "[Stage] task2-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.084463 seconds. Transfer Time: 0.000221 seconds.\n",
            "[Stage] task1-stage-0_conv1: Error during execution: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)\n",
            "[Stage] task1-stage-0_conv1: Executed on CPU-0 in 0.104104 seconds. Transfer Time: 0.000017 seconds.[Stage] task3-stage-0_conv1: Error during execution: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)\n",
            "[Stage] task3-stage-0_conv1: Executed on CPU-1 in 0.104088 seconds. Transfer Time: 0.000028 seconds.\n",
            "[Scheduler] Dependencies met for Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2'. Dispatching.\n",
            "\n",
            "[Scheduler] Warning: Dependency 'task1-stage-0_conv1' output is None for Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2'.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2' to Node 'CPU-1'.\n",
            "[Scheduler] Dependencies met for Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2'. Dispatching.\n",
            "[Scheduler] Warning: Dependency 'task1-stage-0_conv1' output is None for Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2'.\n",
            "[Scheduler] Dispatched Stage 'task1-stage-1_relu1_to_task1-stage-2_conv2' to Node 'CPU-1'.\n",
            "[Stage] task2-stage-6_fc2: Error during execution: mat1 and mat2 shapes cannot be multiplied (1x0 and 64x10)\n",
            "[Stage] task2-stage-6_fc2: Executed on GPU-0-CPU-1 in 0.001266 seconds. Transfer Time: 0.000799 seconds.\n",
            "[Scheduler] Dependencies met for Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'. Dispatching.\n",
            "[Scheduler] Warning: Dependency 'task3-stage-0_conv1' output is None for Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Dependencies met for Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'. Dispatching.\n",
            "[Scheduler] Warning: Dependency 'task3-stage-0_conv1' output is None for Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'.\n",
            "[Scheduler] Dispatched Stage 'task3-stage-1_relu1_to_task3-stage-4_fc1' to Node 'GPU-0-CPU-0'.\n",
            "[Stage] task2-stage-4_fc1: No input data provided. Executing with empty tensor.\n",
            "[Stage] task2-stage-4_fc1: Executed on CPU-1 in 0.000080 seconds. Transfer Time: 0.000079 seconds.\n",
            "[Scheduler] Dependencies met for Stage 'task2-stage-5_relu3'. Dispatching.\n",
            "[Scheduler] Dispatched Stage 'task2-stage-5_relu3' to Node 'GPU-0-CPU-0'.[Stage] task3-stage-1_relu1_to_task3-stage-4_fc1: No input data provided. Executing with empty tensor.\n",
            "\n",
            "[Scheduler] Dependencies met for Stage 'task2-stage-5_relu3'. Dispatching.[Stage] task3-stage-1_relu1_to_task3-stage-4_fc1: Executed on GPU-0-CPU-0 in 0.000377 seconds. Transfer Time: 0.000148 seconds.\n",
            "\n",
            "[Scheduler] Dispatched Stage 'task2-stage-5_relu3' to Node 'GPU-0-CPU-0'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'.\n",
            "[Scheduler] Warning: No Task ID found for stage 'task3-stage-1_relu1_to_task3-stage-4_fc1'.\n",
            "[Scheduler] All Nodes have been shut down.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import time\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Use your existing Node, Profiler, Task, Taskset classes\n",
        "#    We'll show simplified versions or placeholders below.\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, node_id, cpus=None, gpu=None):\n",
        "        self.node_id = node_id\n",
        "        self.cpus = cpus or []\n",
        "        self.gpu = gpu\n",
        "        self.current_load = 0.0\n",
        "        self.assigned_stages = []\n",
        "\n",
        "        import queue\n",
        "        import threading\n",
        "        self._task_queue = queue.Queue()\n",
        "        self._stop_signal = False\n",
        "\n",
        "        self._worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n",
        "        self._worker_thread.start()\n",
        "\n",
        "    def assign_task(self, func):\n",
        "        \"\"\"Enqueue a function. Return a queue so we can optionally .get() the result.\"\"\"\n",
        "        import queue\n",
        "        result_queue = queue.Queue(maxsize=1)\n",
        "        self._task_queue.put((func, result_queue))\n",
        "        return result_queue\n",
        "\n",
        "    def _worker_loop(self):\n",
        "        while not self._stop_signal:\n",
        "            item = self._task_queue.get()\n",
        "            if item is None:\n",
        "                break\n",
        "            func, result_q = item\n",
        "            result = None\n",
        "            try:\n",
        "                result = func()\n",
        "            except Exception as e:\n",
        "                result = e\n",
        "            result_q.put(result)\n",
        "\n",
        "    def stop(self):\n",
        "        self._stop_signal = True\n",
        "        self._task_queue.put(None)\n",
        "        self._worker_thread.join()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Node({self.node_id}, gpu={self.gpu})\"\n",
        "\n",
        "\n",
        "class Profiler:\n",
        "    \"\"\"\n",
        "    Minimal placeholder. We'll assume we have a DataFrame with\n",
        "    columns: ['Model','Layer','Compute','Total Execution Time (us)'].\n",
        "    \"\"\"\n",
        "    def __init__(self, mode='init'):\n",
        "        import pandas as pd\n",
        "        self.mode = mode\n",
        "        # Hardcode a small DataFrame for demonstration:\n",
        "        data = {\n",
        "            'Model':   ['SimpleCNN','SimpleCNN','SimpleCNN','SimpleCNN'],\n",
        "            'Layer':   ['Conv2d','ReLU','Linear','ReLU'],  # placeholders\n",
        "            'Compute': ['CPU-0','CPU-1','CPU-0','GPU-0-CPU-1'],  # placeholders\n",
        "            'Total Execution Time (us)': [5_000, 2_000, 4_000, 2_500]\n",
        "        }\n",
        "        self.profile_db = pd.DataFrame(data)\n",
        "\n",
        "    def get_profile_db(self):\n",
        "        return self.profile_db\n",
        "\n",
        "\n",
        "class Task:\n",
        "    def __init__(self, task_id, model, input_data, model_name, scheduler=None):\n",
        "        self.task_id = task_id\n",
        "        self.model = model\n",
        "        self.input_data = input_data\n",
        "        self.model_name = model_name\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        self.stages = {}\n",
        "        self.start_time = None\n",
        "        self.finish_time = None\n",
        "        self.output_data = None\n",
        "        self.busy_time = 0.0\n",
        "        self.computation_time = 0.0\n",
        "        self.transfer_time = 0.0\n",
        "\n",
        "    def add_stage(self, stage):\n",
        "        if stage.stage_id in self.stages:\n",
        "            raise ValueError(f\"Stage ID {stage.stage_id} already exists.\")\n",
        "        self.stages[stage.stage_id] = stage\n",
        "\n",
        "    def set_output_data(self, output):\n",
        "        self.output_data = output\n",
        "        self.finish_time = time.time()\n",
        "\n",
        "    def update_busy_time(self, exec_time, transfer_time=0.0):\n",
        "        self.busy_time += exec_time\n",
        "        self.transfer_time += transfer_time\n",
        "        self.computation_time += (exec_time - transfer_time)\n",
        "\n",
        "\n",
        "class Taskset:\n",
        "    \"\"\"\n",
        "    For demonstration, we just store tasks and can schedule/execute them.\n",
        "    \"\"\"\n",
        "    def __init__(self, tasks, scheduler):\n",
        "        self.tasks = tasks\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def schedule_all_tasks(self):\n",
        "        for t in self.tasks:\n",
        "            self.scheduler.decompose_and_allocate_task(t)\n",
        "\n",
        "    def execute_all(self):\n",
        "        # For demonstration, we just do:\n",
        "        for t in self.tasks:\n",
        "            # each stage is dispatched in the scheduler\n",
        "            # or we can do a simple synchronous approach\n",
        "            self.scheduler.execute_task(t)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Taskset with {len(self.tasks)} tasks.\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) We use your \"recreated\" Scheduler and Stage classes from the\n",
        "#    previous conversation snippet. We'll define them here in short form.\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "import networkx as nx\n",
        "import re\n",
        "import math\n",
        "from typing import List\n",
        "\n",
        "# -- We'll import the new Stage from your updated snippet:\n",
        "# from your_code import Stage\n",
        "\n",
        "class Stage:\n",
        "    \"\"\"From updated snippet: now supports add_layer().\"\"\"\n",
        "    def __init__(self, stage_id, assigned_node=None, task=None):\n",
        "        self.stage_id = stage_id\n",
        "        self.assigned_node = assigned_node\n",
        "        self.task = task\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dependencies = []\n",
        "        self.dependents = []\n",
        "\n",
        "        self.input_data = None\n",
        "        self.output_data = None\n",
        "\n",
        "        self.execution_time = None\n",
        "        self.transfer_time = 0.0\n",
        "\n",
        "    def add_layer(self, layer: nn.Module):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    @property\n",
        "    def num_layers(self):\n",
        "        return len(self.layers)\n",
        "\n",
        "    def add_dependency(self, stage_id: str):\n",
        "        self.dependencies.append(stage_id)\n",
        "\n",
        "    def add_dependent(self, stage_id: str):\n",
        "        self.dependents.append(stage_id)\n",
        "\n",
        "    def run_stage(self):\n",
        "        # print(self.input_data)\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "        try:\n",
        "            node = self.assigned_node\n",
        "            device_str = \"cpu\"\n",
        "            if (node is not None) and (node.gpu is not None) and torch.cuda.is_available():\n",
        "                device_str = f\"cuda:{node.gpu}\"\n",
        "            device = torch.device(device_str)\n",
        "\n",
        "            # Move layers to device\n",
        "            for layer in self.layers:\n",
        "                layer.to(device)\n",
        "\n",
        "            if self.input_data is None:\n",
        "                self.output_data = torch.tensor([])\n",
        "            else:\n",
        "                inp = self.input_data.to(device)\n",
        "                with torch.no_grad():\n",
        "                    out = inp\n",
        "                    for lyr in self.layers:\n",
        "                        out = lyr(out)\n",
        "                if device.type == 'cuda':\n",
        "                    self.output_data = out.cpu()\n",
        "                else:\n",
        "                    self.output_data = out\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage] {self.stage_id}: Error: {e}\")\n",
        "            self.output_data = None\n",
        "\n",
        "        end_time = time.time()\n",
        "        self.execution_time = end_time - start_time\n",
        "        if self.task:\n",
        "            self.task.update_busy_time(self.execution_time, self.transfer_time)\n",
        "\n",
        "        if self.task and not self.dependents:\n",
        "            self.task.set_output_data(self.output_data)\n",
        "\n",
        "        if self.task and self.task.scheduler:\n",
        "            self.task.scheduler.stage_completed(self.stage_id)\n",
        "\n",
        "        # print(self.output_data)\n",
        "        return self.output_data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Stage(stage_id={self.stage_id}, #layers={self.num_layers}, \"\n",
        "                f\"deps={self.dependencies}, node={self.assigned_node.node_id if self.assigned_node else None})\")\n",
        "\n",
        "\n",
        "class Scheduler:\n",
        "    \"\"\"\n",
        "    Simplified version from the prior snippet.\n",
        "    \"\"\"\n",
        "    def __init__(self, nodes:List[Node], profiler:Profiler, observation_window=1000.0):\n",
        "        self.nodes = nodes\n",
        "        self.profiler = profiler\n",
        "        self.observation_window = observation_window\n",
        "\n",
        "        self.tasks = {}\n",
        "        self.stage_map = {}\n",
        "        self.completed_stages = set()\n",
        "        self.execution_graphs = {}\n",
        "\n",
        "        import threading\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def decompose_and_allocate_task(self, task):\n",
        "        with self.lock:\n",
        "            self.tasks[task.task_id] = task\n",
        "            task.start_time = time.time()\n",
        "\n",
        "        # Step 1: Build initial stages (1-liner per top-level layer)\n",
        "        initial_stages = self.build_initial_stages(task)\n",
        "\n",
        "        # Step 2: Build graph\n",
        "        G = self.build_execution_graph(initial_stages)\n",
        "        self.execution_graphs[task.task_id] = G\n",
        "\n",
        "        # Step 3: Topo sort\n",
        "        topo_order = list(nx.topological_sort(G))\n",
        "\n",
        "        # Step 4: DP allocate + merge\n",
        "        merged_stages = self.dp_allocate(task, topo_order, initial_stages)\n",
        "\n",
        "        # Step 5: Register final merged stages\n",
        "        for stg in merged_stages:\n",
        "            task.add_stage(stg)\n",
        "            self.stage_map[stg.stage_id] = stg\n",
        "\n",
        "        # Optionally print the final allocation\n",
        "        print(f\"[Scheduler] Task '{task.task_id}' final stages:\")\n",
        "        for ms in merged_stages:\n",
        "            print(\"   \", ms)\n",
        "\n",
        "    def build_initial_stages(self, task):\n",
        "        stages = []\n",
        "        idx = 0\n",
        "        for name, layer in task.model.named_children():\n",
        "            stage_id = f\"{task.task_id}-stage-{idx}_{name}\"\n",
        "            stg = Stage(stage_id, assigned_node=None, task=task)\n",
        "            stg.add_layer(layer)\n",
        "            stages.append(stg)\n",
        "            idx += 1\n",
        "        return stages\n",
        "\n",
        "    def build_execution_graph(self, stages):\n",
        "        G = nx.DiGraph()\n",
        "        for i, st in enumerate(stages):\n",
        "            G.add_node(st.stage_id)\n",
        "            if i > 0:\n",
        "                # linear for simplicity\n",
        "                st.add_dependency(stages[i-1].stage_id)\n",
        "                stages[i-1].add_dependent(st.stage_id)\n",
        "                G.add_edge(stages[i-1].stage_id, st.stage_id)\n",
        "        return G\n",
        "\n",
        "    def dp_allocate(self, task, topo_order, stages):\n",
        "        # 1) re-order\n",
        "        ordered_stages = [s for s in stages if s.stage_id in topo_order]\n",
        "        ordered_stages.sort(key=lambda s: topo_order.index(s.stage_id))\n",
        "\n",
        "        N = len(ordered_stages)\n",
        "        K = len(self.nodes)\n",
        "        w = [node.current_load for node in self.nodes]\n",
        "\n",
        "        # DP table\n",
        "        M = [[math.inf]*(K+1) for _ in range(N+1)]\n",
        "        choice = [[0]*(K+1) for _ in range(N+1)]\n",
        "\n",
        "        for k in range(K+1):\n",
        "            M[0][k] = 0\n",
        "\n",
        "        for n in range(1, N+1):\n",
        "            for k in range(1, K+1):\n",
        "                for x in range(0, n):\n",
        "                    grouped_time = self.sum_exec_times(ordered_stages[x:n], self.nodes[k-1], task)\n",
        "                    load_sum = grouped_time / self.observation_window\n",
        "                    curr_max = max(M[x][k-1], w[k-1] + load_sum)\n",
        "                    if curr_max < M[n][k]:\n",
        "                        M[n][k] = curr_max\n",
        "                        choice[n][k] = x\n",
        "\n",
        "        merged_stages = []\n",
        "        n = N\n",
        "        k = K\n",
        "        while n>0 and k>0:\n",
        "            x = choice[n][k]\n",
        "            node = self.nodes[k-1]\n",
        "            # merge stages x..n-1\n",
        "            new_stage = self.merge_stages(ordered_stages[x:n], node, task)\n",
        "            merged_stages.insert(0, new_stage)\n",
        "\n",
        "            n = x\n",
        "            k -= 1\n",
        "\n",
        "        return merged_stages\n",
        "\n",
        "    def merge_stages(self, stage_list, node, task):\n",
        "        if not stage_list:\n",
        "            return None\n",
        "        if len(stage_list)==1:\n",
        "            st = stage_list[0]\n",
        "            st.assigned_node = node\n",
        "            node.assigned_stages.append(st.stage_id)\n",
        "            return st\n",
        "\n",
        "        first_id = stage_list[0].stage_id\n",
        "        last_id  = stage_list[-1].stage_id\n",
        "        new_id   = f\"{first_id}_to_{last_id}\"\n",
        "        new_stage = Stage(new_id, node, task)\n",
        "\n",
        "        # gather layers\n",
        "        for s in stage_list:\n",
        "            for lyr in s.layers:\n",
        "                new_stage.add_layer(lyr)\n",
        "        # dependencies / dependents\n",
        "        new_stage.dependencies = stage_list[0].dependencies.copy()\n",
        "        new_stage.dependents   = stage_list[-1].dependents.copy()\n",
        "\n",
        "        node.assigned_stages.append(new_id)\n",
        "        return new_stage\n",
        "\n",
        "    def sum_exec_times(self, stage_list, node, task):\n",
        "        \"\"\"\n",
        "        For testing, we just sum up times from the Profiler for each layer.\n",
        "        We'll do naive matching by layer.__class__.__name__ -> 'Layer' column in the DB\n",
        "        and 'Compute' == node.node_id if it exists. Otherwise fallback.\n",
        "        \"\"\"\n",
        "        total_time = 0.0\n",
        "        for st in stage_list:\n",
        "            for lyr in st.layers:\n",
        "                layer_class_name = lyr.__class__.__name__\n",
        "                # Just do a naive match:\n",
        "                # e.g. Conv2d -> 'Conv2d', ReLU -> 'ReLU', ...\n",
        "                df = self.profiler.get_profile_db()\n",
        "                query = (\n",
        "                    (df['Model']==task.model_name) &\n",
        "                    (df['Layer']==layer_class_name) &\n",
        "                    (df['Compute']==node.node_id)\n",
        "                )\n",
        "                rows = df.loc[query, 'Total Execution Time (us)']\n",
        "                if not rows.empty:\n",
        "                    val_us = rows.values[0]\n",
        "                    total_time += (val_us / 1e6)\n",
        "                else:\n",
        "                    total_time += self.observation_window\n",
        "\n",
        "        return total_time\n",
        "\n",
        "    def stage_completed(self, stage_id:str):\n",
        "        with self.lock:\n",
        "            self.completed_stages.add(stage_id)\n",
        "\n",
        "    def execute_task(self, task):\n",
        "        \"\"\"\n",
        "        Dispatch all final stages that have no dependencies or have\n",
        "        dependencies already completed.\n",
        "        For a linear chain, we just dispatch the first stage (the rest\n",
        "        will get triggered in stage_completed).\n",
        "        \"\"\"\n",
        "        # find stages that have no dependencies in task\n",
        "        for sid, stg in task.stages.items():\n",
        "            if not stg.dependencies:\n",
        "                self.dispatch_stage(stg)\n",
        "\n",
        "    def dispatch_stage(self, stage):\n",
        "        # print(stage.)\n",
        "        if stage.dependencies:\n",
        "            # single dependency if linear\n",
        "            dep_id = stage.dependencies[0]\n",
        "            dep_stage = stage.task.stages.get(dep_id)\n",
        "            print(\"******************\")\n",
        "            print(dep_stage.output_data)\n",
        "            print(\"******************\")\n",
        "            stage.input_data = dep_stage.output_data\n",
        "        else:\n",
        "            print(\"******************\")\n",
        "            print(stage.task.input_data)\n",
        "            print(\"******************\")\n",
        "            stage.input_data = stage.task.input_data\n",
        "\n",
        "        result_q = stage.assigned_node.assign_task(stage.run_stage)\n",
        "        # optionally .get() if you want synchronous. We'll do async.\n",
        "\n",
        "    def shutdown(self):\n",
        "        print(\"[Scheduler] Shutting down all Nodes.\")\n",
        "        for node in self.nodes:\n",
        "            node.stop()\n",
        "        print(\"[Scheduler] All Nodes have been shut down.\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Define a simple CNN for demonstration\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc1   = nn.Linear(16*8*8, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Demonstration of the test run\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # (1) Create 2 \"Node\" objects for CPU\n",
        "    node_cpu0 = Node(node_id=\"CPU-0\")\n",
        "    node_cpu1 = Node(node_id=\"CPU-1\")\n",
        "    nodes = [node_cpu0, node_cpu1]\n",
        "\n",
        "    # (2) Create a Profiler placeholder\n",
        "    profiler = Profiler(mode='init')\n",
        "\n",
        "    # (3) Create a Scheduler\n",
        "    scheduler = Scheduler(nodes=nodes, profiler=profiler, observation_window=100.0)\n",
        "\n",
        "    # (4) Build a simple CNN\n",
        "    model = SimpleCNN()\n",
        "    input_tensor = torch.randn(1, 3, 8, 8)  # example input\n",
        "\n",
        "    # (5) Create a single Task\n",
        "    task = Task(\n",
        "        task_id=\"task1\",\n",
        "        model=model,\n",
        "        input_data=input_tensor,\n",
        "        model_name=\"SimpleCNN\",\n",
        "        scheduler=scheduler\n",
        "    )\n",
        "\n",
        "    # (6) Put it in a Taskset, schedule and execute\n",
        "    tset = Taskset([task], scheduler=scheduler)\n",
        "    tset.schedule_all_tasks()\n",
        "    tset.execute_all()\n",
        "\n",
        "    # (7) Wait a bit for all stages to complete (since we used threads)\n",
        "    import time\n",
        "    time.sleep(2)\n",
        "\n",
        "    # (8) Compare pipeline output with naive\n",
        "    with torch.no_grad():\n",
        "        naive_out = model(input_tensor)\n",
        "    pipeline_out = task.output_data\n",
        "\n",
        "    print(\"\\n=== Comparison ===\")\n",
        "    print(\"Naive Output:\", naive_out)\n",
        "    print(\"Pipeline Output:\", pipeline_out)\n",
        "\n",
        "    if pipeline_out is None:\n",
        "        print(\"Pipeline did not produce any output!\")\n",
        "    else:\n",
        "        # check closeness\n",
        "        if torch.allclose(naive_out, pipeline_out, atol=1e-5):\n",
        "            print(\"[Test] SUCCESS: Outputs match (within tolerance).\")\n",
        "        else:\n",
        "            print(\"[Test] WARNING: Outputs differ!\")\n",
        "\n",
        "    # (9) Print final stage info\n",
        "    print(\"\\n=== Stages Info ===\")\n",
        "    for sid, stg in task.stages.items():\n",
        "        print(stg)\n",
        "\n",
        "    # (10) Cleanup\n",
        "    scheduler.shutdown()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhOte8-TpQW1",
        "outputId": "fdfd57a0-7c81-422c-eebe-479753b6c3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Scheduler] Task 'task1' final stages:\n",
            "    Stage(stage_id=task1-stage-0_conv1_to_task1-stage-2_conv2, #layers=3, deps=[], node=CPU-0)\n",
            "    Stage(stage_id=task1-stage-3_relu2_to_task1-stage-4_fc1, #layers=2, deps=['task1-stage-2_conv2'], node=CPU-1)\n",
            "******************\n",
            "tensor([[[[ 0.9599, -0.4344,  0.9591,  0.0693, -0.4149, -0.0587, -1.4252,\n",
            "           -0.5186],\n",
            "          [-0.0158,  0.1946,  1.0743,  0.2321,  0.4702, -0.5130,  0.4202,\n",
            "            0.5887],\n",
            "          [-2.1693, -1.9995, -0.4183,  0.5400, -1.9718, -0.6927,  0.1251,\n",
            "            0.0414],\n",
            "          [-0.0327, -0.0607, -1.1242, -1.8818,  0.8721,  1.5568, -0.9984,\n",
            "           -1.4274],\n",
            "          [ 1.9087, -0.4064, -3.2843, -2.2190, -0.5669,  1.3269,  1.1347,\n",
            "           -0.9561],\n",
            "          [ 0.3090,  0.6564,  1.0238,  0.6457,  0.3690,  0.6289,  2.0433,\n",
            "            0.8297],\n",
            "          [ 0.7926, -0.6222, -1.8273, -0.6226,  0.3800, -1.1853, -1.2737,\n",
            "           -0.4199],\n",
            "          [ 0.2040, -1.4604, -0.2295,  0.7866, -1.5409,  1.5228, -0.3346,\n",
            "           -0.5133]],\n",
            "\n",
            "         [[ 0.2362, -0.7727, -1.3536, -0.3183,  1.5833,  2.4762,  2.5220,\n",
            "            0.2695],\n",
            "          [-0.8497,  2.1395, -0.5674, -0.1319, -0.4720,  0.2679,  2.3641,\n",
            "            0.8803],\n",
            "          [ 1.0114,  0.0791,  1.8582,  2.2556, -0.7303, -0.2896,  0.4864,\n",
            "            2.0214],\n",
            "          [-0.1094,  0.5038, -0.8993, -0.7428,  0.8949, -1.6557,  0.7319,\n",
            "           -1.8985],\n",
            "          [-0.4043, -0.1691,  0.4880, -1.2924, -0.6960,  0.1308, -0.6076,\n",
            "           -0.0844],\n",
            "          [-0.5346,  0.6300,  0.5927,  1.9278,  1.5075, -0.2079, -0.0810,\n",
            "           -1.1743],\n",
            "          [-1.4717, -1.5095,  0.7440, -1.2887,  0.1249,  1.8606,  1.4388,\n",
            "           -0.1761],\n",
            "          [ 0.1332,  0.5936, -0.1226,  0.0165,  0.4559,  2.0348,  2.5198,\n",
            "            0.6845]],\n",
            "\n",
            "         [[-0.3200,  0.4387,  0.3804,  0.6854,  0.5714, -0.7905,  1.8361,\n",
            "           -0.7816],\n",
            "          [ 1.6829,  1.7122, -1.1420, -0.8462,  0.5868,  0.6479, -0.2935,\n",
            "            0.7040],\n",
            "          [ 0.7497, -0.7872,  0.9808, -0.7477,  1.2435, -2.1798, -0.6345,\n",
            "            0.4552],\n",
            "          [-1.5688,  0.8378,  0.1035, -0.1209, -1.5527,  0.7262,  0.1874,\n",
            "            0.8873],\n",
            "          [-1.6319, -0.1895,  1.2422, -0.8098,  0.5199,  0.8239,  0.6194,\n",
            "           -2.0500],\n",
            "          [-0.0892, -0.1928, -0.8200,  1.7508, -1.0769, -0.2320,  1.6319,\n",
            "           -0.5377],\n",
            "          [-3.2415,  0.2227,  0.5356, -0.7825,  1.0041, -0.2740, -0.3412,\n",
            "            0.9309],\n",
            "          [-2.6929, -0.5046,  0.0164,  2.0152, -0.1797,  0.0832, -0.1797,\n",
            "           -1.3638]]]])\n",
            "******************\n",
            "\n",
            "=== Comparison ===\n",
            "Naive Output: tensor([[ 0.0744, -0.0451, -0.0232, -0.0444, -0.0837,  0.0046,  0.0064,  0.0051,\n",
            "          0.0517, -0.0775]])\n",
            "Pipeline Output: None\n",
            "Pipeline did not produce any output!\n",
            "\n",
            "=== Stages Info ===\n",
            "Stage(stage_id=task1-stage-0_conv1_to_task1-stage-2_conv2, #layers=3, deps=[], node=CPU-0)\n",
            "Stage(stage_id=task1-stage-3_relu2_to_task1-stage-4_fc1, #layers=2, deps=['task1-stage-2_conv2'], node=CPU-1)\n",
            "[Scheduler] Shutting down all Nodes.\n",
            "[Scheduler] All Nodes have been shut down.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import networkx as nx\n",
        "import time\n",
        "import math\n",
        "import re\n",
        "from typing import List, Optional\n",
        "import queue  # Added import for handling queue.Empty\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Reuse your existing Node, Profiler, Task, Taskset, Stage\n",
        "#    classes with necessary modifications.\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, node_id, cpus=None, gpu=None):\n",
        "        self.node_id = node_id\n",
        "        self.cpus = cpus or []\n",
        "        self.gpu = gpu\n",
        "        self.current_load = 0.0\n",
        "        self.assigned_stages = []\n",
        "\n",
        "        self._task_queue = queue.Queue()\n",
        "        self._stop_signal = False\n",
        "\n",
        "        self._worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n",
        "        self._worker_thread.start()\n",
        "\n",
        "    def assign_task(self, func):\n",
        "        \"\"\"Enqueue a function. Return a queue so we can optionally .get() the result.\"\"\"\n",
        "        result_queue = queue.Queue(maxsize=1)\n",
        "        self._task_queue.put((func, result_queue))\n",
        "        return result_queue\n",
        "\n",
        "    def _worker_loop(self):\n",
        "        while not self._stop_signal:\n",
        "            item = self._task_queue.get()\n",
        "            if item is None:\n",
        "                break\n",
        "            func, result_q = item\n",
        "            result = None\n",
        "            try:\n",
        "                result = func()\n",
        "            except Exception as e:\n",
        "                result = e\n",
        "            result_q.put(result)\n",
        "\n",
        "    def stop(self):\n",
        "        self._stop_signal = True\n",
        "        self._task_queue.put(None)\n",
        "        self._worker_thread.join()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Node({self.node_id}, gpu={self.gpu})\"\n",
        "\n",
        "\n",
        "class Profiler:\n",
        "    \"\"\"Minimal example with a small profile_db DataFrame.\"\"\"\n",
        "    def __init__(self, mode='init'):\n",
        "        import pandas as pd\n",
        "        self.mode = mode\n",
        "        data = {\n",
        "            'Model':   ['SimpleCNN','SimpleCNN','SimpleCNN','SimpleCNN'],\n",
        "            'Layer':   ['Conv2d','ReLU','Linear','ReLU'],  # placeholders\n",
        "            'Compute': ['CPU-0','CPU-1','CPU-0','CPU-1'],  # Updated to match node IDs\n",
        "            'Total Execution Time (us)': [5_000,2_000,4_000,2_500]\n",
        "        }\n",
        "        self.profile_db = pd.DataFrame(data)\n",
        "\n",
        "    def get_profile_db(self):\n",
        "        return self.profile_db\n",
        "\n",
        "\n",
        "class Task:\n",
        "    def __init__(self, task_id, model, input_data, model_name, scheduler=None):\n",
        "        self.task_id = task_id\n",
        "        self.model = model\n",
        "        self.input_data = input_data\n",
        "        self.model_name = model_name\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        self.stages = {}\n",
        "        self.start_time = None\n",
        "        self.finish_time = None\n",
        "        self.output_data = None\n",
        "        self.busy_time = 0.0\n",
        "        self.computation_time = 0.0\n",
        "        self.transfer_time = 0.0\n",
        "\n",
        "    def add_stage(self, stage):\n",
        "        if stage.stage_id in self.stages:\n",
        "            raise ValueError(f\"Stage ID {stage.stage_id} already exists.\")\n",
        "        self.stages[stage.stage_id] = stage\n",
        "\n",
        "    def set_output_data(self, output):\n",
        "        self.output_data = output\n",
        "        self.finish_time = time.time()\n",
        "\n",
        "    def update_busy_time(self, exec_time, transfer_time=0.0):\n",
        "        self.busy_time += exec_time\n",
        "        self.transfer_time += transfer_time\n",
        "        self.computation_time += (exec_time - transfer_time)\n",
        "\n",
        "\n",
        "class Taskset:\n",
        "    def __init__(self, tasks, scheduler):\n",
        "        self.tasks = tasks\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def schedule_all_tasks(self):\n",
        "        for t in self.tasks:\n",
        "            self.scheduler.decompose_and_allocate_task(t)\n",
        "\n",
        "    def execute_all(self):\n",
        "        for t in self.tasks:\n",
        "            self.scheduler.execute_task(t)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Taskset with {len(self.tasks)} tasks.\"\n",
        "\n",
        "\n",
        "class Stage:\n",
        "    def __init__(self, stage_id, assigned_node=None, task=None):\n",
        "        self.stage_id = stage_id\n",
        "        self.assigned_node = assigned_node\n",
        "        self.task = task\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dependencies = []\n",
        "        self.dependents = []\n",
        "\n",
        "        self.input_data = None\n",
        "        self.output_data = None\n",
        "        self.execution_time = None\n",
        "        self.transfer_time = 0.0\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    @property\n",
        "    def num_layers(self):\n",
        "        return len(self.layers)\n",
        "\n",
        "    def add_dependency(self, stage_id):\n",
        "        self.dependencies.append(stage_id)\n",
        "\n",
        "    def add_dependent(self, stage_id):\n",
        "        self.dependents.append(stage_id)\n",
        "\n",
        "    def run_stage(self):\n",
        "        start_time = time.time()\n",
        "        try:\n",
        "            node = self.assigned_node\n",
        "            device_str = \"cpu\"\n",
        "            if node and node.gpu is not None and torch.cuda.is_available():\n",
        "                device_str = f\"cuda:{node.gpu}\"\n",
        "            device = torch.device(device_str)\n",
        "\n",
        "            # Move each layer to the assigned device\n",
        "            for layer in self.layers:\n",
        "                layer.to(device)\n",
        "\n",
        "            if self.input_data is None:\n",
        "                # No input => produce empty tensor\n",
        "                self.output_data = torch.tensor([])\n",
        "            else:\n",
        "                inp = self.input_data.to(device)\n",
        "                with torch.no_grad():\n",
        "                    out = inp\n",
        "                    for lyr in self.layers:\n",
        "                        out = lyr(out)\n",
        "                if device.type == 'cuda':\n",
        "                    self.output_data = out.cpu()\n",
        "                else:\n",
        "                    self.output_data = out\n",
        "\n",
        "            # Debug: Print output_data for verification\n",
        "            print(f\"[Stage] {self.stage_id} executed on {node.node_id}. Output shape: {self.output_data.shape}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage] {self.stage_id}: Error: {e}\")\n",
        "            self.output_data = None\n",
        "\n",
        "        end_time = time.time()\n",
        "        self.execution_time = end_time - start_time\n",
        "\n",
        "        if self.task:\n",
        "            self.task.update_busy_time(self.execution_time, self.transfer_time)\n",
        "        if self.task and not self.dependents:\n",
        "            self.task.set_output_data(self.output_data)\n",
        "\n",
        "        # Mark stage completed\n",
        "        if self.task and self.task.scheduler:\n",
        "            self.task.scheduler.stage_completed(self.stage_id)\n",
        "\n",
        "        return self.output_data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Stage(stage_id={self.stage_id}, #layers={self.num_layers}, \"\n",
        "                f\"deps={self.dependencies}, node={self.assigned_node.node_id if self.assigned_node else None})\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Updated 'SchedulerNoMerge' that dispatches dependent stages\n",
        "# ---------------------------------------------------------------------\n",
        "class SchedulerNoMerge:\n",
        "    \"\"\"Scheduler that topologically sorts the layers, assigns each as a separate stage, no merging.\"\"\"\n",
        "    def __init__(self, nodes:List[Node], profiler:Profiler, observation_window=1000.0):\n",
        "        self.nodes = nodes\n",
        "        self.profiler = profiler\n",
        "        self.observation_window = observation_window\n",
        "\n",
        "        self.tasks = {}\n",
        "        self.stage_map = {}\n",
        "        self.completed_stages = set()\n",
        "        self.execution_graphs = {}\n",
        "\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def decompose_and_allocate_task(self, task:Task):\n",
        "        with self.lock:\n",
        "            self.tasks[task.task_id] = task\n",
        "            task.start_time = time.time()\n",
        "\n",
        "        # 1) Build an initial stage per layer (linear chain)\n",
        "        stages = []\n",
        "        idx = 0\n",
        "        for name, layer in task.model.named_children():\n",
        "            st_id = f\"{task.task_id}-stage-{idx}_{name}\"\n",
        "            stg = Stage(st_id, assigned_node=None, task=task)\n",
        "            stg.add_layer(layer)\n",
        "            stages.append(stg)\n",
        "            idx += 1\n",
        "\n",
        "        # 2) Build a linear execution graph:\n",
        "        G = nx.DiGraph()\n",
        "        for i in range(len(stages)):\n",
        "            s = stages[i]\n",
        "            G.add_node(s.stage_id)\n",
        "            if i > 0:\n",
        "                # linear for simplicity\n",
        "                s.add_dependency(stages[i-1].stage_id)\n",
        "                stages[i-1].add_dependent(s.stage_id)\n",
        "                G.add_edge(stages[i-1].stage_id, s.stage_id)\n",
        "        self.execution_graphs[task.task_id] = G\n",
        "\n",
        "        # 3) Do a topological sort\n",
        "        topo_order = list(nx.topological_sort(G))\n",
        "\n",
        "        # 4) Allocate each stage individually (no merges)\n",
        "        #    Use a minimal load approach\n",
        "        for i, stg in enumerate(stages):\n",
        "            assigned_node = self.choose_node_for_stage(stg, task)\n",
        "            stg.assigned_node = assigned_node\n",
        "            assigned_node.assigned_stages.append(stg.stage_id)\n",
        "            task.add_stage(stg)\n",
        "            self.stage_map[stg.stage_id] = stg\n",
        "\n",
        "        # Debug print\n",
        "        print(f\"[SchedulerNoMerge] Task '{task.task_id}' final stages:\")\n",
        "        for s in stages:\n",
        "            print(\"   \", s)\n",
        "\n",
        "    def choose_node_for_stage(self, stage:Stage, task:Task) -> Node:\n",
        "        \"\"\"\n",
        "        Pick the node with the least projected load.\n",
        "        \"\"\"\n",
        "        best_node = None\n",
        "        best_load = math.inf\n",
        "        best_exec_time = 0.0\n",
        "        for nd in self.nodes:\n",
        "            stage_time = self.sum_exec_times(stage, task, nd)\n",
        "            projected_load = nd.current_load + stage_time / self.observation_window\n",
        "            if projected_load < best_load:\n",
        "                best_load = projected_load\n",
        "                best_node = nd\n",
        "                best_exec_time = stage_time\n",
        "        # Update the node's load\n",
        "        best_node.current_load += best_exec_time / self.observation_window\n",
        "        return best_node\n",
        "\n",
        "    def sum_exec_times(self, stage:Stage, task:Task, node:Node) -> float:\n",
        "        \"\"\"\n",
        "        Sum up times from the Profiler for each layer on the given node.\n",
        "        \"\"\"\n",
        "        df = self.profiler.get_profile_db()\n",
        "        total_time = 0.0\n",
        "        for lyr in stage.layers:\n",
        "            layer_class = lyr.__class__.__name__\n",
        "            query = (\n",
        "                (df['Model'] == task.model_name) &\n",
        "                (df['Layer'] == layer_class) &\n",
        "                (df['Compute'] == node.node_id)  # Match node ID\n",
        "            )\n",
        "            row = df.loc[query, 'Total Execution Time (us)']\n",
        "            if not row.empty:\n",
        "                val_us = row.values[0]\n",
        "                total_time += (val_us / 1e6)\n",
        "            else:\n",
        "                total_time += self.observation_window  # Fallback\n",
        "        return total_time\n",
        "\n",
        "    def stage_completed(self, stage_id:str):\n",
        "        with self.lock:\n",
        "            self.completed_stages.add(stage_id)\n",
        "            task_id = self.get_task_id_from_stage(stage_id)\n",
        "            if not task_id:\n",
        "                return\n",
        "            task = self.tasks.get(task_id)\n",
        "            if not task:\n",
        "                return\n",
        "            stg = task.stages.get(stage_id)\n",
        "            if not stg:\n",
        "                return\n",
        "            # Dispatch dependents if all dependencies are met\n",
        "            for dep_stg_id in stg.dependents:\n",
        "                dep_stg = task.stages.get(dep_stg_id)\n",
        "                if dep_stg:\n",
        "                    if all(d in self.completed_stages for d in dep_stg.dependencies):\n",
        "                        self.dispatch_stage(dep_stg)\n",
        "\n",
        "    def get_task_id_from_stage(self, stage_id: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Extracts the task_id from a stage_id.\n",
        "        \"\"\"\n",
        "        parts = stage_id.split(\"-stage-\", maxsplit=1)\n",
        "        if len(parts) < 2:\n",
        "            return None\n",
        "        return parts[0]\n",
        "\n",
        "    def execute_task(self, task:Task):\n",
        "        # Dispatch all stages with no dependencies\n",
        "        for st_id, stg in task.stages.items():\n",
        "            if not stg.dependencies:\n",
        "                self.dispatch_stage(stg)\n",
        "\n",
        "    def dispatch_stage(self, stage:Stage):\n",
        "        # Set input data\n",
        "        if stage.dependencies:\n",
        "            # assume single dependency for linear chain\n",
        "            dep_id = stage.dependencies[0]\n",
        "            dep_stage = stage.task.stages.get(dep_id)\n",
        "            stage.input_data = dep_stage.output_data\n",
        "        else:\n",
        "            stage.input_data = stage.task.input_data\n",
        "\n",
        "        print(f\"[SchedulerNoMerge] Dispatching Stage '{stage.stage_id}' to Node '{stage.assigned_node.node_id}'\")\n",
        "        result_q = stage.assigned_node.assign_task(stage.run_stage)\n",
        "\n",
        "        # Optionally, wait for the stage to complete and handle errors\n",
        "        try:\n",
        "            result = result_q.get(timeout=5)  # Wait up to 5 seconds\n",
        "            if isinstance(result, Exception):\n",
        "                print(f\"[SchedulerNoMerge] Stage '{stage.stage_id}' encountered an error: {result}\")\n",
        "        except queue.Empty:\n",
        "            print(f\"[SchedulerNoMerge] Stage '{stage.stage_id}' timed out.\")\n",
        "\n",
        "    def shutdown(self):\n",
        "        print(\"[SchedulerNoMerge] Shutting down all Nodes...\")\n",
        "        for nd in self.nodes:\n",
        "            nd.stop()\n",
        "        print(\"[SchedulerNoMerge] All Nodes stopped.\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Define a simple CNN for demonstration\n",
        "# ---------------------------------------------------------------------\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc1   = nn.Linear(16*8*8, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Demonstration of the test run\n",
        "# ---------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    import threading  # Ensure threading is imported\n",
        "    import pandas as pd  # Ensure pandas is available\n",
        "\n",
        "    # 1) Create two Nodes for CPU\n",
        "    node_cpu0 = Node(node_id=\"CPU-0\")\n",
        "    node_cpu1 = Node(node_id=\"CPU-1\")\n",
        "    nodes = [node_cpu0, node_cpu1]\n",
        "\n",
        "    # 2) Create a Profiler placeholder\n",
        "    profiler = Profiler(mode='init')\n",
        "\n",
        "    # 3) Create a SchedulerNoMerge\n",
        "    scheduler = SchedulerNoMerge(nodes=nodes, profiler=profiler, observation_window=100.0)\n",
        "\n",
        "    # 4) Build a simple CNN\n",
        "    model = SimpleCNN()\n",
        "    input_tensor = torch.randn(1, 3, 8, 8)  # example input\n",
        "\n",
        "    # 5) Create a single Task\n",
        "    task = Task(\n",
        "        task_id=\"task1\",\n",
        "        model=model,\n",
        "        input_data=input_tensor,\n",
        "        model_name=\"SimpleCNN\",\n",
        "        scheduler=scheduler\n",
        "    )\n",
        "\n",
        "    # 6) Put it in a Taskset, schedule and execute\n",
        "    tset = Taskset([task], scheduler=scheduler)\n",
        "    tset.schedule_all_tasks()\n",
        "    tset.execute_all()\n",
        "\n",
        "    # 7) Wait a bit for all stages to complete (since we used threads)\n",
        "    time.sleep(5)  # Increased to 5 seconds to ensure all stages complete\n",
        "\n",
        "    # 8) Compare pipeline output with naive\n",
        "    with torch.no_grad():\n",
        "        naive_out = model(input_tensor)\n",
        "    pipeline_out = task.output_data\n",
        "\n",
        "    print(\"\\n=== Comparison ===\")\n",
        "    print(\"Naive Output:\", naive_out)\n",
        "    print(\"Pipeline Output:\", pipeline_out)\n",
        "\n",
        "    if pipeline_out is None:\n",
        "        print(\"[Test] Pipeline produced no output!\")\n",
        "    else:\n",
        "        # Check closeness\n",
        "        if torch.allclose(naive_out, pipeline_out, atol=1e-5):\n",
        "            print(\"[Test] SUCCESS: Outputs match (within tolerance).\")\n",
        "        else:\n",
        "            print(\"[Test] WARNING: Outputs differ!\\n\"\n",
        "                  f\"Naive: {naive_out}\\nPipe:  {pipeline_out}\")\n",
        "\n",
        "    # 9) Print final stage info\n",
        "    print(\"\\n=== Stages Info ===\")\n",
        "    for sid, stg in task.stages.items():\n",
        "        print(stg)\n",
        "\n",
        "    # 10) Cleanup\n",
        "    scheduler.shutdown()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK7n5_cWGpDW",
        "outputId": "4aa0ac64-335a-43c9-8415-a743a1f226fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SchedulerNoMerge] Task 'task1' final stages:\n",
            "    Stage(stage_id=task1-stage-0_conv1, #layers=1, deps=[], node=CPU-0)\n",
            "    Stage(stage_id=task1-stage-1_relu1, #layers=1, deps=['task1-stage-0_conv1'], node=CPU-1)\n",
            "    Stage(stage_id=task1-stage-2_conv2, #layers=1, deps=['task1-stage-1_relu1'], node=CPU-0)\n",
            "    Stage(stage_id=task1-stage-3_relu2, #layers=1, deps=['task1-stage-2_conv2'], node=CPU-1)\n",
            "    Stage(stage_id=task1-stage-4_fc1, #layers=1, deps=['task1-stage-3_relu2'], node=CPU-0)\n",
            "[SchedulerNoMerge] Dispatching Stage 'task1-stage-0_conv1' to Node 'CPU-0'\n",
            "[Stage] task1-stage-0_conv1 executed on CPU-0. Output shape: torch.Size([1, 8, 8, 8])\n",
            "[SchedulerNoMerge] Dispatching Stage 'task1-stage-1_relu1' to Node 'CPU-1'\n",
            "[Stage] task1-stage-1_relu1 executed on CPU-1. Output shape: torch.Size([1, 8, 8, 8])\n",
            "[SchedulerNoMerge] Stage 'task1-stage-0_conv1' timed out.\n",
            "[SchedulerNoMerge] Stage 'task1-stage-1_relu1' timed out.\n",
            "[SchedulerNoMerge] Dispatching Stage 'task1-stage-2_conv2' to Node 'CPU-0'\n",
            "[Stage] task1-stage-2_conv2 executed on CPU-0. Output shape: torch.Size([1, 16, 8, 8])\n",
            "[SchedulerNoMerge] Stage 'task1-stage-2_conv2' timed out.\n",
            "[SchedulerNoMerge] Dispatching Stage 'task1-stage-3_relu2' to Node 'CPU-1'\n",
            "[Stage] task1-stage-3_relu2 executed on CPU-1. Output shape: torch.Size([1, 16, 8, 8])\n",
            "\n",
            "=== Comparison ===\n",
            "Naive Output: tensor([[-0.0056, -0.0418, -0.1280,  0.0372,  0.1835,  0.0255,  0.0807,  0.0472,\n",
            "          0.0744, -0.0060]])\n",
            "Pipeline Output: None\n",
            "[Test] Pipeline produced no output!\n",
            "\n",
            "=== Stages Info ===\n",
            "Stage(stage_id=task1-stage-0_conv1, #layers=1, deps=[], node=CPU-0)\n",
            "Stage(stage_id=task1-stage-1_relu1, #layers=1, deps=['task1-stage-0_conv1'], node=CPU-1)\n",
            "Stage(stage_id=task1-stage-2_conv2, #layers=1, deps=['task1-stage-1_relu1'], node=CPU-0)\n",
            "Stage(stage_id=task1-stage-3_relu2, #layers=1, deps=['task1-stage-2_conv2'], node=CPU-1)\n",
            "Stage(stage_id=task1-stage-4_fc1, #layers=1, deps=['task1-stage-3_relu2'], node=CPU-0)\n",
            "[SchedulerNoMerge] Shutting down all Nodes...\n",
            "[SchedulerNoMerge] Stage 'task1-stage-3_relu2' timed out.\n",
            "[SchedulerNoMerge] Dispatching Stage 'task1-stage-4_fc1' to Node 'CPU-0'\n",
            "[SchedulerNoMerge] Stage 'task1-stage-4_fc1' timed out.\n",
            "[SchedulerNoMerge] All Nodes stopped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZGLob1-vK8fn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}