{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyDart Library â€“ Post Round-Robin Implementation\n",
        "\n",
        "## Overview\n",
        "\n",
        "This iteration marks the first implementation of a complete PyDart library following the Round-Robin scheduling scheme. In this version, **Utilization** was introduced as a key metric, particularly for **HPC and batch-based workloads**.\n",
        "\n",
        "## Main Contributions\n",
        "\n",
        "1. **Implementing Utilization as a Metric**  \n",
        "   - Defined utilization as:  \n",
        "     \\[\n",
        "     \\text{Utilization} = \\frac{\\text{Busy Time}}{\\text{Observation Window}}\n",
        "     \\]\n",
        "   - The observation window includes:  \n",
        "     - All forward pass execution timings.  \n",
        "     - Associated data processing.  \n",
        "     - A slack percentage for scheduling flexibility.  \n",
        "\n",
        "2. **Targeting HPC and Batch Workloads**  \n",
        "   - Designed to assess performance in **high-performance computing (HPC) environments**.  \n",
        "   - Evaluated the impact on batch-processing scenarios.  \n",
        "\n",
        "3. **Performance Evaluation and Key Insights**  \n",
        "   - Observed **little to no improvement** in performance with this metric.  \n",
        "   - Although ineffective in batch processing, the approach **may hold value in real-time applications**.  \n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Further refine utilization-based scheduling to assess its impact on **dynamic and real-time inference workloads**.  \n",
        "- Explore **adaptive scheduling mechanisms** to improve efficiency beyond static allocation.  \n",
        "\n",
        "---\n",
        "\n",
        "**Note**: This iteration represents a key step toward refining execution strategies. While initial results were inconclusive, this metric might be more beneficial in real-time applications.\n"
      ],
      "metadata": {
        "id": "dg8q9l9Tpj7P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkdvDanT8cll"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Simplified_Taskset_Evaluation.ipynb\n",
        "\n",
        "This script implements a simplified Taskset approach, utilizing manual stage assignments.\n",
        "\"\"\"\n",
        "\n",
        "import networkx as nx\n",
        "import os\n",
        "import torch\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.profiler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from typing import Callable, Any, List, Dict, Optional\n",
        "import copy\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "\n",
        "import torch\n",
        "from torch.fx import Node as FxNode  # Alias torch.fx.Node to FxNode\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "\n",
        "def resolve_arg(arg: Any, node_outputs: Dict[str, torch.Tensor]) -> Any:\n",
        "    \"\"\"\n",
        "    Recursively replaces FxNode references in args and kwargs with their actual outputs.\n",
        "\n",
        "    Args:\n",
        "        arg (Any): The argument to resolve.\n",
        "        node_outputs (Dict[str, torch.Tensor]): A dictionary mapping node names to their output tensors.\n",
        "\n",
        "    Returns:\n",
        "        Any: The resolved argument with FxNode references replaced by tensors.\n",
        "    \"\"\"\n",
        "    if isinstance(arg, FxNode):\n",
        "        return node_outputs[arg.name]\n",
        "    elif isinstance(arg, (list, tuple)):\n",
        "        return type(arg)(resolve_arg(a, node_outputs) for a in arg)\n",
        "    elif isinstance(arg, dict):\n",
        "        return {k: resolve_arg(v, node_outputs) for k, v in arg.items()}\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "\n",
        "def group_topological_order(topological_order: List[str], group_size: int = 2) -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Groups the topological order list into fixed-size groups.\n",
        "    Each group is named as 'stage-1', 'stage-2', etc.\n",
        "\n",
        "    Args:\n",
        "        topological_order (List[str]): List of operation names in topological order.\n",
        "        group_size (int): Number of operations per group.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, List[str]]: Mapping from stage names to lists of operation names.\n",
        "    \"\"\"\n",
        "    groups = {}\n",
        "    num_groups = (len(topological_order) + group_size - 1) // group_size  # Ceiling division\n",
        "\n",
        "    for i in range(num_groups):\n",
        "        start_idx = i * group_size\n",
        "        end_idx = start_idx + group_size\n",
        "        group_nodes = topological_order[start_idx:end_idx]\n",
        "        stage_name = f\"stage-{i+1}\"\n",
        "        groups[stage_name] = group_nodes\n",
        "\n",
        "    return groups"
      ],
      "metadata": {
        "id": "lq8Qhy7Gry8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import threading\n",
        "import queue\n",
        "from typing import Callable, List\n",
        "\n",
        "class Node:\n",
        "    \"\"\"\n",
        "    Represents a computational resource: either a CPU-only node (1 CPU core)\n",
        "    or a GPU+CPU pair. Each Node has:\n",
        "      - node_id (e.g., 'CPU-0', 'GPU-0-CPU-1')\n",
        "      - A worker thread + queue to run tasks\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, node_id: str, cpus=None, gpu=None):\n",
        "        self._node_id = node_id\n",
        "        self._cpus = tuple(cpus or [])\n",
        "        self._gpu = gpu\n",
        "\n",
        "        self._original_affinity = os.sched_getaffinity(0)\n",
        "        self._task_queue = queue.Queue()\n",
        "        self._stop_signal = False\n",
        "\n",
        "        self._worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n",
        "        self._worker_thread.start()\n",
        "\n",
        "        self.current_load = 0.0  # Initialize current load\n",
        "        self.assigned_stages = []  # List to track assigned stages\n",
        "\n",
        "    @property\n",
        "    def node_id(self):\n",
        "        return self._node_id\n",
        "\n",
        "    @property\n",
        "    def cpus(self):\n",
        "        return self._cpus\n",
        "\n",
        "    @property\n",
        "    def gpu(self):\n",
        "        return self._gpu\n",
        "\n",
        "    def assign_task(self, func: Callable, *args, **kwargs) -> queue.Queue:\n",
        "        \"\"\"\n",
        "        Enqueue a function to this node. Returns a queue from which\n",
        "        the caller can retrieve the result (blocking).\n",
        "        \"\"\"\n",
        "        result_queue = queue.Queue(maxsize=1)\n",
        "        self._task_queue.put((func, args, kwargs, result_queue))\n",
        "        return result_queue\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"\n",
        "        Signal the node to stop after processing queued tasks.\n",
        "        \"\"\"\n",
        "        self._stop_signal = True\n",
        "        self._task_queue.put(None)\n",
        "        self._worker_thread.join()\n",
        "\n",
        "    def _worker_loop(self):\n",
        "        while not self._stop_signal:\n",
        "            item = self._task_queue.get()\n",
        "            if item is None:\n",
        "                break\n",
        "            func, args, kwargs, result_queue = item\n",
        "            try:\n",
        "                self._set_context()\n",
        "                result = func(*args, **kwargs)\n",
        "            except Exception as e:\n",
        "                result = e\n",
        "            finally:\n",
        "                self._reset_context()\n",
        "\n",
        "            result_queue.put(result)\n",
        "\n",
        "    def _set_context(self):\n",
        "        if self._cpus:\n",
        "            os.sched_setaffinity(0, self._cpus)\n",
        "        if self._gpu is not None and torch.cuda.is_available():\n",
        "            torch.cuda.set_device(self._gpu)\n",
        "\n",
        "    def _reset_context(self):\n",
        "        os.sched_setaffinity(0, self._original_affinity)\n",
        "        # Optionally reset GPU device if needed\n",
        "\n",
        "    @staticmethod\n",
        "    def discover_nodes(disjoint: bool = True) -> List['Node']:\n",
        "        \"\"\"\n",
        "        Create a list of Node objects.\n",
        "\n",
        "        If disjoint=False (default):\n",
        "          - For each CPU core, create a CPU-only node.\n",
        "          - For each GPU device and each CPU core, create a GPU+CPU node.\n",
        "\n",
        "        If disjoint=True:\n",
        "          - Create one Node per CPU core (CPU-only) in a temporary list.\n",
        "          - For each GPU device, pop exactly one CPU core from the CPU list\n",
        "            and create a GPU+CPU node with that single core.\n",
        "          - If there are more GPUs than CPU cores, leftover GPUs get a Node with no CPU.\n",
        "        \"\"\"\n",
        "        nodes = []\n",
        "        num_cpus = os.cpu_count() or 1\n",
        "        ngpus = torch.cuda.device_count()\n",
        "\n",
        "        if not disjoint:\n",
        "            # --- Original Behavior (overlapping) ---\n",
        "            # CPU-only nodes\n",
        "            for core_id in range(num_cpus):\n",
        "                node = Node(node_id=f\"CPU-{core_id}\", cpus=[core_id])\n",
        "                nodes.append(node)\n",
        "\n",
        "            # GPU+CPU nodes (one for each GPU and CPU pair)\n",
        "            for g in range(ngpus):\n",
        "                for core_id in range(num_cpus):\n",
        "                    node = Node(node_id=f\"GPU-{g}-CPU-{core_id}\", cpus=[core_id], gpu=g)\n",
        "                    nodes.append(node)\n",
        "\n",
        "            print(\"[discover_nodes] Generated ALL possible nodes (CPU-only + GPU+CPU).\")\n",
        "\n",
        "        else:\n",
        "            # --- Disjoint Behavior (no CPU overlap) ---\n",
        "            # 1) Build a CPU-only node for every CPU core\n",
        "            cpu_nodes = []\n",
        "            for core_id in range(num_cpus):\n",
        "                node = Node(node_id=f\"CPU-{core_id}\", cpus=[core_id], gpu=None)\n",
        "                cpu_nodes.append(node)\n",
        "\n",
        "            # 2) For each GPU, pop exactly one CPU node (if available)\n",
        "            #    to pair with that GPU. Otherwise, create a GPU node with no CPU.\n",
        "            gpu_nodes = []\n",
        "            for g in range(ngpus):\n",
        "                if cpu_nodes:\n",
        "                    # Pop a CPU node from the list\n",
        "                    removed_node = cpu_nodes.pop()\n",
        "                    claim_core = removed_node.cpus[0]  # The one CPU from that node\n",
        "\n",
        "                    # Create a GPU+CPU node\n",
        "                    node = Node(node_id=f\"GPU-{g}-CPU-{claim_core}\",\n",
        "                                cpus=[claim_core],\n",
        "                                gpu=g)\n",
        "                    gpu_nodes.append(node)\n",
        "                    print(f\"[discover_nodes] Created GPU node '{node.node_id}' claiming CPU core {claim_core}.\")\n",
        "                else:\n",
        "                    # If no CPU cores left, create a GPU node with no CPU\n",
        "                    node = Node(node_id=f\"GPU-{g}\", cpus=[], gpu=g)\n",
        "                    gpu_nodes.append(node)\n",
        "                    print(f\"[discover_nodes] Created GPU node '{node.node_id}' with no CPU assigned.\")\n",
        "\n",
        "            # Combine the leftover CPU-only nodes + GPU nodes\n",
        "            nodes = cpu_nodes + gpu_nodes\n",
        "\n",
        "            print(\"[discover_nodes] Generated DISJOINT nodes: leftover CPU-only plus GPU+CPU with unique cores.\")\n",
        "\n",
        "        return nodes\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Node({self._node_id}, cpus={self._cpus}, gpu={self._gpu})\"\n"
      ],
      "metadata": {
        "id": "7OQgcv4N5gZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import re\n",
        "# import torch\n",
        "# from torch import nn\n",
        "# from torch.profiler import profile, ProfilerActivity, record_function\n",
        "# import torch.fx\n",
        "# import pandas as pd\n",
        "# from typing import Any, Dict, Callable, Optional\n",
        "# import torchvision.models as models\n",
        "\n",
        "# class Profiler:\n",
        "#     \"\"\"\n",
        "#     Profiler class that uses torch.fx to trace and instrument a PyTorch model,\n",
        "#     wrapping each operation with torch.profiler.record_function to collect detailed profiling data.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, mode: str, profile_db_path='profiling_results.csv', log_dir='logs'):\n",
        "#         \"\"\"\n",
        "#         Initializes the Profiler.\n",
        "\n",
        "#         Args:\n",
        "#             mode (str): 'init' or 'runtime'.\n",
        "#             profile_db_path (str): Path to the ProfileDB CSV file.\n",
        "#             log_dir (str): Directory to store logs.\n",
        "#         \"\"\"\n",
        "#         assert mode in ['init', 'runtime'], \"Profiler mode must be either 'init' or 'runtime'.\"\n",
        "#         self.mode = mode\n",
        "#         self.profile_db_path = profile_db_path\n",
        "#         self.log_dir = log_dir\n",
        "#         os.makedirs(self.log_dir, exist_ok=True)\n",
        "\n",
        "#         # Define columns for ProfileDB\n",
        "#         self.columns = [\n",
        "#             'Task_ID', 'Model', 'Layer', 'Compute',\n",
        "#             'Self CPU (us)', 'CPU Total (us)', 'CUDA Total (us)',\n",
        "#             'Self CPU Mem (bytes)', 'Self CUDA Mem (bytes)',\n",
        "#             'Total Execution Time (us)', 'Total Memory Used (bytes)'\n",
        "#         ]\n",
        "\n",
        "#         # Initialize or load ProfileDB\n",
        "#         if os.path.exists(self.profile_db_path):\n",
        "#             self.profile_db = pd.read_csv(self.profile_db_path)\n",
        "#         else:\n",
        "#             self.profile_db = pd.DataFrame(columns=self.columns)\n",
        "\n",
        "#         self.runtime_csv = os.path.join(self.log_dir, 'runtime_results.csv')\n",
        "#         if not os.path.exists(self.runtime_csv):\n",
        "#             rt_cols = ['Task_ID', 'Model', 'Layer', 'Compute', 'Execution Time (us)']\n",
        "#             pd.DataFrame(columns=rt_cols).to_csv(self.runtime_csv, index=False)\n",
        "\n",
        "#         # We'll store an 'observation_window' if needed\n",
        "#         self.observation_window = 0.0\n",
        "\n",
        "#     def _trace_and_instrument_model(self, model: nn.Module) -> torch.fx.GraphModule:\n",
        "#         \"\"\"\n",
        "#         Traces the model using torch.fx, instruments every node by wrapping its operation\n",
        "#         with torch.profiler.record_function, and returns the modified GraphModule.\n",
        "\n",
        "#         Args:\n",
        "#             model (nn.Module): The PyTorch model to profile.\n",
        "\n",
        "#         Returns:\n",
        "#             torch.fx.GraphModule: The instrumented GraphModule.\n",
        "#         \"\"\"\n",
        "#         # Trace the model\n",
        "#         tracer = torch.fx.Tracer()\n",
        "#         graph = tracer.trace(model)\n",
        "#         graph_module = torch.fx.GraphModule(model, graph)\n",
        "#         graph = graph_module.graph\n",
        "\n",
        "#         # Define a unique attribute name prefix to avoid conflicts\n",
        "#         profiler_attr_prefix = \"_profiler_wrapped_\"\n",
        "\n",
        "#         # Iterate through the nodes and wrap functions\n",
        "#         for node in list(graph.nodes):\n",
        "#             if node.op == 'call_function':\n",
        "#                 func = node.target\n",
        "#                 func_name = func.__name__\n",
        "#                 # Define a unique name for the wrapped function\n",
        "#                 wrapped_func_name = f\"{profiler_attr_prefix}{func_name}_{id(func)}\"\n",
        "\n",
        "#                 # Define the wrapped function with record_function\n",
        "#                 def make_wrapped_func(original_func, name):\n",
        "#                     def wrapped(*args, **kwargs):\n",
        "#                         with record_function(name):\n",
        "#                             return original_func(*args, **kwargs)\n",
        "#                     return wrapped\n",
        "\n",
        "#                 wrapped_func = make_wrapped_func(func, func_name)\n",
        "\n",
        "#                 # Assign the wrapped function as an attribute to the model\n",
        "#                 setattr(model, wrapped_func_name, wrapped_func)\n",
        "\n",
        "#                 # Replace the node's target with the wrapped function\n",
        "#                 node.target = getattr(model, wrapped_func_name)\n",
        "\n",
        "#             elif node.op == 'call_module':\n",
        "#                 submodule = dict(model.named_modules())[node.target]\n",
        "#                 func = submodule.forward\n",
        "#                 func_name = f\"{node.target}.forward\"\n",
        "\n",
        "#                 # Define a unique name for the wrapped function\n",
        "#                 wrapped_func_name = f\"{profiler_attr_prefix}{node.target}_forward_{id(func)}\"\n",
        "\n",
        "#                 # Define the wrapped function with record_function\n",
        "#                 def make_wrapped_forward(original_forward, name):\n",
        "#                     def wrapped_forward(*args, **kwargs):\n",
        "#                         with record_function(name):\n",
        "#                             return original_forward(*args, **kwargs)\n",
        "#                     return wrapped_forward\n",
        "\n",
        "#                 wrapped_forward = make_wrapped_forward(func, func_name)\n",
        "\n",
        "#                 # Assign the wrapped forward as an attribute to the submodule\n",
        "#                 setattr(submodule, wrapped_func_name, wrapped_forward)\n",
        "\n",
        "#                 # Replace the submodule's forward with the wrapped version\n",
        "#                 submodule.forward = getattr(submodule, wrapped_func_name)\n",
        "\n",
        "#             elif node.op == 'call_method':\n",
        "#                 method_name = node.target\n",
        "#                 obj = node.args[0]\n",
        "#                 # Retrieve the method from the object\n",
        "#                 original_method = getattr(obj, method_name)\n",
        "#                 func_name = f\"{obj.name}.{method_name}\" if hasattr(obj, 'name') else method_name\n",
        "\n",
        "#                 # Define a unique name for the wrapped method\n",
        "#                 wrapped_method_name = f\"{profiler_attr_prefix}{method_name}_{id(original_method)}\"\n",
        "\n",
        "#                 # Define the wrapped method with record_function\n",
        "#                 def make_wrapped_method(original_method, name):\n",
        "#                     def wrapped_method(*args, **kwargs):\n",
        "#                         with record_function(name):\n",
        "#                             return original_method(*args, **kwargs)\n",
        "#                     return wrapped_method\n",
        "\n",
        "#                 wrapped_method = make_wrapped_method(original_method, func_name)\n",
        "\n",
        "#                 # Assign the wrapped method back to the object\n",
        "#                 setattr(obj, wrapped_method_name, wrapped_method)\n",
        "\n",
        "#                 # Replace the method call with the wrapped method\n",
        "#                 # Since it's a method, ensure the GraphModule accesses the wrapped method\n",
        "#                 # In torch.fx, method calls are kept as 'call_method', so no need to change node.op\n",
        "#                 # Just ensure that the method is wrapped in the object\n",
        "\n",
        "#             elif node.op == 'placeholder':\n",
        "#                 # For placeholders, optionally wrap with a pass-through function\n",
        "#                 # Currently, no profiling needed for input placeholders\n",
        "#                 pass\n",
        "\n",
        "#         # Recompile the GraphModule after instrumentation\n",
        "#         graph_module.recompile()\n",
        "\n",
        "#         return graph_module\n",
        "\n",
        "#     def profile_model(self, model: nn.Module, input_data: Any, node_id: str, task_id: str, warmup_iters=3, profile_iters=5):\n",
        "#         \"\"\"\n",
        "#         Profiles the given model on the specified node.\n",
        "\n",
        "#         Args:\n",
        "#             model (nn.Module): The PyTorch model to profile.\n",
        "#             input_data (Any): The input data for the model.\n",
        "#             node_id (str): Identifier for the compute node (e.g., 'CPU-0', 'GPU-0').\n",
        "#             task_id (str): Identifier for the profiling task.\n",
        "#             warmup_iters (int): Number of warmup iterations.\n",
        "#             profile_iters (int): Number of profiling iterations.\n",
        "#         \"\"\"\n",
        "#         # Trace and instrument the model\n",
        "#         instrumented_model = self._trace_and_instrument_model(model)\n",
        "\n",
        "#         # Move to device\n",
        "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#         instrumented_model.to(device)\n",
        "#         instrumented_model.eval()\n",
        "\n",
        "#         # Warmup runs\n",
        "#         with torch.no_grad():\n",
        "#             for _ in range(warmup_iters):\n",
        "#                 _ = instrumented_model(input_data.to(device))\n",
        "\n",
        "#         print(\"Starting profiling...\")\n",
        "#         # Start profiler\n",
        "#         with profile(\n",
        "#             activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "#             schedule=torch.profiler.schedule(wait=1, warmup=1, active=profile_iters),\n",
        "#             on_trace_ready=lambda prof: self._trace_handler(prof, task_id, model.__class__.__name__, node_id),\n",
        "#             record_shapes=True,\n",
        "#             profile_memory=True,\n",
        "#             with_stack=True\n",
        "#         ) as prof:\n",
        "#             for _ in range(profile_iters):\n",
        "#                 with torch.no_grad():\n",
        "#                     _ = instrumented_model(input_data.to(device))\n",
        "#                 prof.step()\n",
        "\n",
        "#         # Save profiling data\n",
        "#         self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "#         print(f\"Profiling complete. Data saved to {self.profile_db_path}\")\n",
        "\n",
        "#     def _trace_handler(self, prof, task_id: str, model_name: str, node_id: str):\n",
        "#         \"\"\"\n",
        "#         Handles the trace data and processes events.\n",
        "\n",
        "#         Args:\n",
        "#             prof: The profiler instance.\n",
        "#             task_id (str): Identifier for the profiling task.\n",
        "#             model_name (str): Name of the model.\n",
        "#             node_id (str): Compute node identifier.\n",
        "#         \"\"\"\n",
        "#         self._process_profiler_data(prof, task_id, model_name, node_id)\n",
        "\n",
        "#     def _process_profiler_data(self, profiler, task_id: str, model_name: str, node_id: str):\n",
        "#         \"\"\"\n",
        "#         Processes raw profiler data and aggregates it per node, including a forward_pass record.\n",
        "\n",
        "#         Args:\n",
        "#             profiler: The profiler instance.\n",
        "#             task_id (str): Identifier for the profiling task.\n",
        "#             model_name (str): Name of the model.\n",
        "#             node_id (str): Compute node identifier.\n",
        "#         \"\"\"\n",
        "#         aggregated = {}\n",
        "#         forward_pass = {\n",
        "#             'Task_ID': task_id,\n",
        "#             'Model': model_name,\n",
        "#             'Layer': 'forward_pass',\n",
        "#             'Compute': node_id,\n",
        "#             'Self CPU (us)': 0.0,\n",
        "#             'CPU Total (us)': 0.0,\n",
        "#             'CUDA Total (us)': 0.0,\n",
        "#             'Self CPU Mem (bytes)': 0,\n",
        "#             'Self CUDA Mem (bytes)': 0,\n",
        "#             'Total Execution Time (us)': 0.0,\n",
        "#             'Total Memory Used (bytes)': 0\n",
        "#         }\n",
        "\n",
        "#         events = profiler.key_averages()\n",
        "\n",
        "#         for evt in events:\n",
        "#             layer_name = evt.key\n",
        "#             if layer_name.startswith(\"aten::\"):\n",
        "#                 continue  # Skip aten operations\n",
        "\n",
        "#             # Aggregate forward_pass\n",
        "#             forward_pass['Self CPU (us)'] += evt.self_cpu_time_total\n",
        "#             forward_pass['CPU Total (us)'] += evt.cpu_time_total\n",
        "#             forward_pass['CUDA Total (us)'] += evt.cuda_time_total if hasattr(evt, 'cuda_time_total') else 0.0\n",
        "#             forward_pass['Self CPU Mem (bytes)'] += evt.self_cpu_memory_usage if hasattr(evt, 'self_cpu_memory_usage') else 0\n",
        "#             forward_pass['Self CUDA Mem (bytes)'] += evt.self_cuda_memory_usage if hasattr(evt, 'self_cuda_memory_usage') else 0\n",
        "#             forward_pass['Total Execution Time (us)'] += (evt.cpu_time_total + evt.cuda_time_total)  if hasattr(evt, 'cuda_time_total') else evt.cpu_time_total\n",
        "#             forward_pass['Total Memory Used (bytes)'] += (evt.self_cpu_memory_usage + evt.self_cuda_memory_usage) if hasattr(evt, 'self_cpu_memory_usage') and hasattr(evt, 'self_cuda_memory_usage') else 0\n",
        "\n",
        "#             # Aggregate per node\n",
        "#             if layer_name not in aggregated:\n",
        "#                 aggregated[layer_name] = {\n",
        "#                     'Task_ID': task_id,\n",
        "#                     'Model': model_name,\n",
        "#                     'Layer': layer_name,\n",
        "#                     'Compute': node_id,\n",
        "#                     'Self CPU (us)': 0.0,\n",
        "#                     'CPU Total (us)': 0.0,\n",
        "#                     'CUDA Total (us)': 0.0,\n",
        "#                     'Self CPU Mem (bytes)': 0,\n",
        "#                     'Self CUDA Mem (bytes)': 0,\n",
        "#                     'Total Execution Time (us)': 0.0,\n",
        "#                     'Total Memory Used (bytes)': 0\n",
        "#                 }\n",
        "\n",
        "#             aggregated[layer_name]['Self CPU (us)'] += evt.self_cpu_time_total\n",
        "#             aggregated[layer_name]['CPU Total (us)'] += evt.cpu_time_total\n",
        "#             aggregated[layer_name]['CUDA Total (us)'] += evt.cuda_time_total  if hasattr(evt, 'cuda_time_total') else 0.0\n",
        "#             aggregated[layer_name]['Self CPU Mem (bytes)'] += evt.self_cpu_memory_usage if hasattr(evt, 'self_cpu_memory_usage') else 0\n",
        "#             aggregated[layer_name]['Self CUDA Mem (bytes)'] += evt.self_cuda_memory_usage if hasattr(evt, 'self_cuda_memory_usage') else 0\n",
        "#             aggregated[layer_name]['Total Execution Time (us)'] += (evt.cpu_time_total + evt.cuda_time_total)  if hasattr(evt, 'cuda_time_total') else evt.cpu_time_total\n",
        "#             aggregated[layer_name]['Total Memory Used (bytes)'] += (evt.self_cpu_memory_usage + evt.self_cuda_memory_usage) if hasattr(evt, 'self_cpu_memory_usage') and hasattr(evt, 'self_cuda_memory_usage') else 0\n",
        "\n",
        "#         # Insert forward_pass\n",
        "#         self.profile_db = self._upsert(self.profile_db, forward_pass)\n",
        "\n",
        "#         # Insert per-node data\n",
        "#         for layer_name, data in aggregated.items():\n",
        "#             self.profile_db = self._upsert(self.profile_db, data)\n",
        "\n",
        "#         # Save to CSV\n",
        "#         self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "\n",
        "#     def _upsert(self, df: pd.DataFrame, row: Dict[str, Any]) -> pd.DataFrame:\n",
        "#         \"\"\"\n",
        "#         Inserts or updates a row in the DataFrame based on Task_ID, Model, Layer, and Compute.\n",
        "#         Only updates if 'Total Execution Time (us)' is greater than existing.\n",
        "\n",
        "#         Args:\n",
        "#             df (pd.DataFrame): The ProfileDB DataFrame.\n",
        "#             row (Dict[str, Any]): The row data to upsert.\n",
        "\n",
        "#         Returns:\n",
        "#             pd.DataFrame: The updated DataFrame.\n",
        "#         \"\"\"\n",
        "#         mask = (\n",
        "#             (df['Task_ID'] == row['Task_ID']) &\n",
        "#             (df['Model'] == row['Model']) &\n",
        "#             (df['Layer'] == row['Layer']) &\n",
        "#             (df['Compute'] == row['Compute'])\n",
        "#         )\n",
        "#         if mask.any():\n",
        "#             existing_time = df.loc[mask, 'Total Execution Time (us)'].max()\n",
        "#             if row['Total Execution Time (us)'] > existing_time:\n",
        "#                 for key in self.columns:\n",
        "#                     df.loc[mask, key] = row[key]\n",
        "#         else:\n",
        "#             new_row = pd.DataFrame([row])\n",
        "#             df = pd.concat([df, new_row], ignore_index=True)\n",
        "#         return df\n",
        "\n",
        "#     def get_profile_db(self) -> pd.DataFrame:\n",
        "#         \"\"\"\n",
        "#         Returns the ProfileDB DataFrame.\n",
        "\n",
        "#         Returns:\n",
        "#             pd.DataFrame: The ProfileDB DataFrame.\n",
        "#         \"\"\"\n",
        "#         return self.profile_db\n",
        "\n",
        "#     def print_profile_db(self):\n",
        "#         \"\"\"\n",
        "#         Prints the ProfileDB DataFrame.\n",
        "#         \"\"\"\n",
        "#         if self.profile_db.empty:\n",
        "#             print(\"ProfileDB is empty.\")\n",
        "#         else:\n",
        "#             print(\"ProfileDB:\")\n",
        "#             print(self.profile_db.to_string(index=False))"
      ],
      "metadata": {
        "id": "l8zZqryo8iGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import copy\n",
        "import torch\n",
        "import torch.fx\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.profiler import profile, ProfilerActivity, record_function\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "class Profiler:\n",
        "    \"\"\"\n",
        "    Profiler class that uses torch.fx to trace and instrument a PyTorch model,\n",
        "    wrapping each operation with torch.profiler.record_function to collect detailed profiling data.\n",
        "\n",
        "    Now includes a \"safe clone\" inside profile_model:\n",
        "      - Tries copy.deepcopy first\n",
        "      - Falls back to torch.save / torch.load if deepcopy fails\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode: str, profile_db_path='profiling_results.csv', log_dir='logs'):\n",
        "        \"\"\"\n",
        "        Initializes the Profiler.\n",
        "\n",
        "        Args:\n",
        "            mode (str): 'init' or 'runtime'.\n",
        "            profile_db_path (str): Path to the ProfileDB CSV file.\n",
        "            log_dir (str): Directory to store logs.\n",
        "        \"\"\"\n",
        "        assert mode in ['init', 'runtime'], \"Profiler mode must be either 'init' or 'runtime'.\"\n",
        "        self.mode = mode\n",
        "        self.profile_db_path = profile_db_path\n",
        "        self.log_dir = log_dir\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "\n",
        "        # Define columns for ProfileDB\n",
        "        self.columns = [\n",
        "            'Task_ID', 'Model', 'Layer', 'Compute',\n",
        "            'Self CPU (us)', 'CPU Total (us)', 'CUDA Total (us)',\n",
        "            'Self CPU Mem (bytes)', 'Self CUDA Mem (bytes)',\n",
        "            'Total Execution Time (us)', 'Total Memory Used (bytes)'\n",
        "        ]\n",
        "\n",
        "        # Initialize or load ProfileDB\n",
        "        if os.path.exists(self.profile_db_path):\n",
        "            self.profile_db = pd.read_csv(self.profile_db_path)\n",
        "        else:\n",
        "            self.profile_db = pd.DataFrame(columns=self.columns)\n",
        "\n",
        "        # (Optional) Example location for runtime CSV logs\n",
        "        self.runtime_csv = os.path.join(self.log_dir, 'runtime_results.csv')\n",
        "        if not os.path.exists(self.runtime_csv):\n",
        "            rt_cols = ['Task_ID', 'Model', 'Layer', 'Compute', 'Execution Time (us)']\n",
        "            pd.DataFrame(columns=rt_cols).to_csv(self.runtime_csv, index=False)\n",
        "\n",
        "        self.observation_window = 0.0\n",
        "\n",
        "    def profile_model(self,\n",
        "                      model: nn.Module,\n",
        "                      input_data: Any,\n",
        "                      node_id: str,\n",
        "                      task_id: str,\n",
        "                      warmup_iters=3,\n",
        "                      profile_iters=5):\n",
        "        \"\"\"\n",
        "        Profiles the given model on the specified node. Automatically:\n",
        "          1) Clones the model (to avoid double-instrumentation).\n",
        "          2) Traces and instruments the clone with torch.fx and record_function.\n",
        "          3) Collects and saves profiling data.\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): The PyTorch model to profile.\n",
        "            input_data (Any): The input data for the model.\n",
        "            node_id (str): Identifier for the compute node (e.g., 'CPU-0', 'GPU-0').\n",
        "            task_id (str): Identifier for the profiling task.\n",
        "            warmup_iters (int): Number of warmup iterations.\n",
        "            profile_iters (int): Number of profiling iterations.\n",
        "        \"\"\"\n",
        "        # 1) Create a fresh, uninstrumented model copy\n",
        "        model_copy = self._clone_model_safely(model)\n",
        "\n",
        "        # 2) Trace & instrument the fresh copy\n",
        "        instrumented_model = self._trace_and_instrument_model(model_copy)\n",
        "\n",
        "        # 3) Move to device (CPU or CUDA)\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        instrumented_model.to(device)\n",
        "        instrumented_model.eval()\n",
        "\n",
        "        # 4) Warmup runs\n",
        "        with torch.no_grad():\n",
        "            for _ in range(warmup_iters):\n",
        "                _ = instrumented_model(input_data.to(device))\n",
        "\n",
        "        print(\"Starting profiling...\")\n",
        "        # 5) Actual profiling with the fresh, instrumented model\n",
        "        with profile(\n",
        "            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "            schedule=torch.profiler.schedule(wait=1, warmup=1, active=profile_iters),\n",
        "            on_trace_ready=lambda prof: self._trace_handler(prof, task_id, model_copy.__class__.__name__, node_id),\n",
        "            record_shapes=True,\n",
        "            profile_memory=True,\n",
        "            with_stack=True\n",
        "        ) as prof:\n",
        "            for _ in range(profile_iters):\n",
        "                with torch.no_grad():\n",
        "                    _ = instrumented_model(input_data.to(device))\n",
        "                prof.step()\n",
        "\n",
        "        # 6) Save profiling data\n",
        "        self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "        print(f\"Profiling complete. Data saved to {self.profile_db_path}\")\n",
        "\n",
        "    def _clone_model_safely(self, model: nn.Module) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Tries to clone the given model via copy.deepcopy.\n",
        "        If that fails for any reason, falls back to torch.save/torch.load.\n",
        "\n",
        "        Returns:\n",
        "            A fresh, uninstrumented model instance.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return copy.deepcopy(model)\n",
        "        except Exception as e:\n",
        "            print(f\"[Profiler] deepcopy failed with error: {e}\")\n",
        "            print(\"[Profiler] Falling back to torch.save / torch.load approach.\")\n",
        "            buffer = io.BytesIO()\n",
        "            torch.save(model, buffer)\n",
        "            buffer.seek(0)\n",
        "            return torch.load(buffer)\n",
        "\n",
        "    def _trace_and_instrument_model(self, model: nn.Module) -> torch.fx.GraphModule:\n",
        "        \"\"\"\n",
        "        Traces the model using torch.fx, instruments every node by wrapping its operation\n",
        "        with torch.profiler.record_function, and returns the modified GraphModule.\n",
        "        \"\"\"\n",
        "        # 1) FX tracing\n",
        "        tracer = torch.fx.Tracer()\n",
        "        graph = tracer.trace(model)\n",
        "        graph_module = torch.fx.GraphModule(model, graph)\n",
        "        graph = graph_module.graph\n",
        "\n",
        "        profiler_attr_prefix = \"_profiler_wrapped_\"\n",
        "\n",
        "        # 2) Iterate over nodes and wrap calls\n",
        "        for node in list(graph.nodes):\n",
        "            node_name = node.name\n",
        "\n",
        "            if node.op == 'call_function':\n",
        "                func = node.target  # e.g., torch.add\n",
        "                wrapped_func_name = f\"{profiler_attr_prefix}{node_name}_{id(func)}\"\n",
        "\n",
        "                def make_wrapped_func(original_func, profile_name):\n",
        "                    def wrapped(*args, **kwargs):\n",
        "                        with record_function(profile_name):\n",
        "                            return original_func(*args, **kwargs)\n",
        "                    return wrapped\n",
        "\n",
        "                wrapped_func = make_wrapped_func(func, node_name)\n",
        "                setattr(model, wrapped_func_name, wrapped_func)\n",
        "                node.target = getattr(model, wrapped_func_name)\n",
        "\n",
        "            elif node.op == 'call_module':\n",
        "                submodule = dict(model.named_modules())[node.target]\n",
        "                func = submodule.forward\n",
        "                wrapped_func_name = f\"{profiler_attr_prefix}{node_name}_{id(func)}\"\n",
        "\n",
        "                def make_wrapped_forward(original_forward, profile_name):\n",
        "                    def wrapped_forward(*args, **kwargs):\n",
        "                        with record_function(profile_name):\n",
        "                            return original_forward(*args, **kwargs)\n",
        "                    return wrapped_forward\n",
        "\n",
        "                wrapped_forward = make_wrapped_forward(func, node_name)\n",
        "                setattr(submodule, wrapped_func_name, wrapped_forward)\n",
        "                submodule.forward = getattr(submodule, wrapped_func_name)\n",
        "\n",
        "            elif node.op == 'call_method':\n",
        "                method_name = node.target\n",
        "                obj = node.args[0]\n",
        "                original_method = getattr(obj, method_name, None)\n",
        "                if original_method is None:\n",
        "                    continue\n",
        "\n",
        "                wrapped_method_name = f\"{profiler_attr_prefix}{node_name}_{id(original_method)}\"\n",
        "\n",
        "                def make_wrapped_method(orig_meth, profile_name):\n",
        "                    def wrapped_method(*args, **kwargs):\n",
        "                        with record_function(profile_name):\n",
        "                            return orig_meth(*args, **kwargs)\n",
        "                    return wrapped_method\n",
        "\n",
        "                wrapped_method = make_wrapped_method(original_method, node_name)\n",
        "                setattr(obj, wrapped_method_name, wrapped_method)\n",
        "                # In many cases, no further replacement is needed for call_method,\n",
        "                # but it depends on how your FX graph references the method.\n",
        "\n",
        "            elif node.op == 'placeholder':\n",
        "                # Usually no instrumentation needed for placeholders\n",
        "                pass\n",
        "\n",
        "        # 3) Recompile the GraphModule after instrumentation\n",
        "        graph_module.recompile()\n",
        "        return graph_module\n",
        "\n",
        "    def _trace_handler(self, prof, task_id: str, model_name: str, node_id: str):\n",
        "        \"\"\"\n",
        "        Handles the trace data once the profiling schedule triggers it.\n",
        "        \"\"\"\n",
        "        self._process_profiler_data(prof, task_id, model_name, node_id)\n",
        "\n",
        "    def _process_profiler_data(self, profiler, task_id: str, model_name: str, node_id: str):\n",
        "        \"\"\"\n",
        "        Processes raw profiler data and aggregates it into self.profile_db.\n",
        "        Also adds a forward_pass record combining all ops.\n",
        "\n",
        "        Args:\n",
        "            profiler: The profiler instance.\n",
        "            task_id (str): Identifier for the profiling task.\n",
        "            model_name (str): Model name (class).\n",
        "            node_id (str): Compute node identifier (e.g., 'CPU-0').\n",
        "        \"\"\"\n",
        "        aggregated = {}\n",
        "        forward_pass = {\n",
        "            'Task_ID': task_id,\n",
        "            'Model': model_name,\n",
        "            'Layer': 'forward_pass',\n",
        "            'Compute': node_id,\n",
        "            'Self CPU (us)': 0.0,\n",
        "            'CPU Total (us)': 0.0,\n",
        "            'CUDA Total (us)': 0.0,\n",
        "            'Self CPU Mem (bytes)': 0,\n",
        "            'Self CUDA Mem (bytes)': 0,\n",
        "            'Total Execution Time (us)': 0.0,\n",
        "            'Total Memory Used (bytes)': 0\n",
        "        }\n",
        "\n",
        "        events = profiler.key_averages()\n",
        "\n",
        "        for evt in events:\n",
        "            layer_name = evt.key\n",
        "\n",
        "            # Skip low-level PyTorch ops if desired\n",
        "            if layer_name.startswith(\"aten::\"):\n",
        "                continue\n",
        "\n",
        "            # Accumulate a \"forward_pass\" total\n",
        "            forward_pass['Self CPU (us)'] += evt.self_cpu_time_total\n",
        "            forward_pass['CPU Total (us)'] += evt.cpu_time_total\n",
        "            forward_pass['CUDA Total (us)'] += getattr(evt, 'cuda_time_total', 0.0)\n",
        "            forward_pass['Self CPU Mem (bytes)'] += getattr(evt, 'self_cpu_memory_usage', 0)\n",
        "            forward_pass['Self CUDA Mem (bytes)'] += getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "            forward_pass['Total Execution Time (us)'] += (\n",
        "                evt.cpu_time_total + getattr(evt, 'cuda_time_total', 0.0)\n",
        "            )\n",
        "            forward_pass['Total Memory Used (bytes)'] += (\n",
        "                getattr(evt, 'self_cpu_memory_usage', 0) +\n",
        "                getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "            )\n",
        "\n",
        "            if layer_name not in aggregated:\n",
        "                aggregated[layer_name] = {\n",
        "                    'Task_ID': task_id,\n",
        "                    'Model': model_name,\n",
        "                    'Layer': layer_name,\n",
        "                    'Compute': node_id,\n",
        "                    'Self CPU (us)': 0.0,\n",
        "                    'CPU Total (us)': 0.0,\n",
        "                    'CUDA Total (us)': 0.0,\n",
        "                    'Self CPU Mem (bytes)': 0,\n",
        "                    'Self CUDA Mem (bytes)': 0,\n",
        "                    'Total Execution Time (us)': 0.0,\n",
        "                    'Total Memory Used (bytes)': 0\n",
        "                }\n",
        "\n",
        "            # Per-layer accumulation\n",
        "            aggregated[layer_name]['Self CPU (us)'] += evt.self_cpu_time_total\n",
        "            aggregated[layer_name]['CPU Total (us)'] += evt.cpu_time_total\n",
        "            aggregated[layer_name]['CUDA Total (us)'] += getattr(evt, 'cuda_time_total', 0.0)\n",
        "            aggregated[layer_name]['Self CPU Mem (bytes)'] += getattr(evt, 'self_cpu_memory_usage', 0)\n",
        "            aggregated[layer_name]['Self CUDA Mem (bytes)'] += getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "            aggregated[layer_name]['Total Execution Time (us)'] += (\n",
        "                evt.cpu_time_total + getattr(evt, 'cuda_time_total', 0.0)\n",
        "            )\n",
        "            aggregated[layer_name]['Total Memory Used (bytes)'] += (\n",
        "                getattr(evt, 'self_cpu_memory_usage', 0) +\n",
        "                getattr(evt, 'self_cuda_memory_usage', 0)\n",
        "            )\n",
        "\n",
        "        # Insert forward_pass row\n",
        "        self.profile_db = self._upsert(self.profile_db, forward_pass)\n",
        "\n",
        "        # Insert each layer's data\n",
        "        for layer_name, data in aggregated.items():\n",
        "            self.profile_db = self._upsert(self.profile_db, data)\n",
        "\n",
        "        # Save to CSV\n",
        "        self.profile_db.to_csv(self.profile_db_path, index=False)\n",
        "\n",
        "    def _upsert(self, df: pd.DataFrame, row: Dict[str, Any]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Inserts or updates a row in the DataFrame based on Task_ID, Model, Layer, and Compute.\n",
        "        Only updates if 'Total Execution Time (us)' is greater than existing.\n",
        "        \"\"\"\n",
        "        mask = (\n",
        "            (df['Task_ID'] == row['Task_ID']) &\n",
        "            (df['Model'] == row['Model']) &\n",
        "            (df['Layer'] == row['Layer']) &\n",
        "            (df['Compute'] == row['Compute'])\n",
        "        )\n",
        "        if mask.any():\n",
        "            existing_time = df.loc[mask, 'Total Execution Time (us)'].max()\n",
        "            if row['Total Execution Time (us)'] > existing_time:\n",
        "                for key in self.columns:\n",
        "                    df.loc[mask, key] = row[key]\n",
        "        else:\n",
        "            new_row = pd.DataFrame([row])\n",
        "            df = pd.concat([df, new_row], ignore_index=True)\n",
        "        return df\n",
        "\n",
        "    def get_profile_db(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Returns the ProfileDB DataFrame.\n",
        "        \"\"\"\n",
        "        return self.profile_db\n",
        "\n",
        "    def print_profile_db(self):\n",
        "        \"\"\"\n",
        "        Prints the ProfileDB DataFrame.\n",
        "        \"\"\"\n",
        "        if self.profile_db.empty:\n",
        "            print(\"ProfileDB is empty.\")\n",
        "        else:\n",
        "            print(\"ProfileDB:\")\n",
        "            print(self.profile_db.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "6rb6NUGh548-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stage.py\n",
        "\n",
        "import torch\n",
        "import time\n",
        "from typing import Dict, Optional, List\n",
        "from torch.fx import Node as FxNode\n",
        "\n",
        "# from utils import resolve_arg  # Ensure this import path is correct\n",
        "# from node import Node            # Ensure this import path is correct\n",
        "\n",
        "def move_tensor_to_device(obj, device):\n",
        "    \"\"\"\n",
        "    Recursively move all Tensors in `obj` to `device`.\n",
        "    If `obj` is just a Tensor, call .to(device) on it.\n",
        "    If `obj` is a (list, tuple, dict), recurse.\n",
        "    Otherwise, return `obj` as-is.\n",
        "    \"\"\"\n",
        "    if isinstance(obj, torch.Tensor):\n",
        "        return obj.to(device)\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return type(obj)(move_tensor_to_device(elem, device) for elem in obj)\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: move_tensor_to_device(v, device) for k, v in obj.items()}\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "class Stage:\n",
        "    \"\"\"\n",
        "    Represents a group of operations (FxNodes) assigned to a particular Node.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stage_id: str, nodes: List[FxNode], assigned_node: Node, task: 'Task'):\n",
        "        self.stage_id = stage_id\n",
        "        self.nodes = nodes\n",
        "        self.assigned_node = assigned_node\n",
        "\n",
        "        self.dependencies: List[str] = []\n",
        "        self.dependents: List[str] = []\n",
        "\n",
        "        self.execution_time: Optional[float] = None\n",
        "        self.transfer_time: float = 0.0\n",
        "\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "        self.input_data: Optional[Dict[str, torch.Tensor]] = None\n",
        "\n",
        "        self.task = task\n",
        "\n",
        "        # We'll store the device as a string if needed:\n",
        "        self.stage_device: str = \"cpu\"\n",
        "\n",
        "    def add_dependency(self, stage_id: str):\n",
        "        self.dependencies.append(stage_id)\n",
        "\n",
        "    def add_dependent(self, stage_id: str):\n",
        "        self.dependents.append(stage_id)\n",
        "\n",
        "    def run_stage(self, node_outputs: Dict[str, torch.Tensor]):\n",
        "        \"\"\"\n",
        "        Executes the stage's operations, updates execution metrics, and handles output data.\n",
        "        This method is intended to be enqueued to the Node's worker thread.\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        transfer_time = 0.0\n",
        "\n",
        "        # Decide device from assigned node\n",
        "        if (self.assigned_node is not None) and (self.assigned_node.gpu is not None) and torch.cuda.is_available():\n",
        "            device = torch.device(f\"cuda:{self.assigned_node.gpu}\")\n",
        "            self.stage_device = str(device)\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            self.stage_device = \"cpu\"\n",
        "\n",
        "        # Synchronize before starting (for accurate timing)\n",
        "        # if device.type == 'cuda':\n",
        "        #     torch.cuda.synchronize(device.index)\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                for fx_node in self.nodes:\n",
        "                    # Resolve all fx_node inputs from node_outputs\n",
        "                    resolved_args = resolve_arg(fx_node.args, node_outputs)\n",
        "                    resolved_kwargs = resolve_arg(fx_node.kwargs, node_outputs)\n",
        "\n",
        "                    # Transfer input Tensors to 'device'\n",
        "                    transfer_start = time.time()\n",
        "                    resolved_args = move_tensor_to_device(resolved_args, device)\n",
        "                    resolved_kwargs = move_tensor_to_device(resolved_kwargs, device)\n",
        "                    transfer_end = time.time()\n",
        "                    transfer_time += (transfer_end - transfer_start)\n",
        "\n",
        "                    # Actually run the operation\n",
        "                    if fx_node.op == 'placeholder':\n",
        "                        # Typically means the main input to the entire model\n",
        "                        out = self.task.input_data.to(device)\n",
        "                        node_outputs[fx_node.name] = out\n",
        "\n",
        "                    elif fx_node.op == 'call_module':\n",
        "                        submodule = self.task.model.get_submodule(fx_node.target)\n",
        "                        submodule.to(device)  # ensure submodule is on the same device\n",
        "                        out = submodule(*resolved_args, **resolved_kwargs)\n",
        "\n",
        "                    elif fx_node.op == 'call_function':\n",
        "                        func = fx_node.target\n",
        "                        out = func(*resolved_args, **resolved_kwargs)\n",
        "\n",
        "                    elif fx_node.op == 'call_method':\n",
        "                        method = getattr(resolved_args[0], fx_node.target)\n",
        "                        out = method(*resolved_args[1:], **resolved_kwargs)\n",
        "\n",
        "                    elif fx_node.op == 'output':\n",
        "                        # The final output node for this stage\n",
        "                        out = resolved_args[0]\n",
        "\n",
        "                    else:\n",
        "                        raise NotImplementedError(f\"Operation '{fx_node.op}' not supported in run_stage().\")\n",
        "\n",
        "                    # Save the result into node_outputs\n",
        "                    node_outputs[fx_node.name] = out\n",
        "\n",
        "        except AttributeError as e:\n",
        "            print(f\"[Stage] {self.stage_id}: AttributeError during execution: {e}\")\n",
        "            self.execution_time = float('inf')\n",
        "            self.transfer_time = float('inf')\n",
        "            node_outputs[self.stage_id] = None\n",
        "            return  # Early exit on failure\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage] {self.stage_id}: Error during execution: {e}\")\n",
        "            self.execution_time = float('inf')\n",
        "            self.transfer_time = float('inf')\n",
        "            node_outputs[self.stage_id] = None\n",
        "            return  # Early exit on failure\n",
        "\n",
        "        finally:\n",
        "            # After execution, synchronize again if on GPU\n",
        "            # if device.type == 'cuda':\n",
        "            #     torch.cuda.synchronize(device.index)\n",
        "\n",
        "            end_time = time.time()\n",
        "            self.execution_time = end_time - start_time\n",
        "            self.transfer_time = transfer_time\n",
        "\n",
        "        # Update the Task's busy_time\n",
        "        self.task.update_busy_time(self.execution_time, self.transfer_time)\n",
        "\n",
        "        # If no dependents, set Task's output_data\n",
        "        if not self.dependents:\n",
        "            final_output_node = next((n for n in self.nodes if n.op == 'output'), None)\n",
        "            if final_output_node:\n",
        "                # Assuming the first argument is the tensor\n",
        "                arg = final_output_node.args[0]\n",
        "                if isinstance(arg, torch.Tensor):\n",
        "                    final_res = arg.cpu()\n",
        "                elif isinstance(arg, FxNode):\n",
        "                    final_res = node_outputs.get(arg.name, None)\n",
        "                else:\n",
        "                    final_res = None\n",
        "                self.task.set_output_data(final_res)\n",
        "            else:\n",
        "                self.task.set_output_data(None)\n",
        "\n",
        "        # Print Stage execution info\n",
        "        print(f\"[Stage] {self.stage_id}: Executed on {self.assigned_node.node_id if self.assigned_node else 'None'} \"\n",
        "              f\"in {self.execution_time:.6f} seconds. Transfer Time: {self.transfer_time:.6f} seconds.\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Stage(stage_id={self.stage_id}, device={self.stage_device}, \"\n",
        "                f\"node={self.assigned_node.node_id if self.assigned_node else 'None'}, \"\n",
        "                f\"deps={self.dependencies}, exec_time={self.execution_time}, \"\n",
        "                f\"transfer_time={self.transfer_time})\")\n"
      ],
      "metadata": {
        "id": "s-mO7WsuBTZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.fx as fx\n",
        "import time\n",
        "from typing import List, Dict, Optional, Any\n",
        "\n",
        "# from stage import Stage\n",
        "# from utils import group_topological_order\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any, Optional, Set\n",
        "\n",
        "def retrieve_layer_profile_records(\n",
        "    profile_db: pd.DataFrame,\n",
        "    task_id: str,\n",
        "    model_name: str,\n",
        "    compute: Optional[str],  # e.g., 'CPU-0'\n",
        "    layer_names: List[str],\n",
        "    placeholder_names: Optional[Set[str]] = None\n",
        ") -> Dict[str, Optional[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Retrieves profiler records for each layer in layer_names, filtered by:\n",
        "      - Task_ID == task_id\n",
        "      - Model == model_name\n",
        "      - (optional) Compute == compute\n",
        "      - Layer == each layer_name in layer_names.\n",
        "\n",
        "    If a layer is in 'placeholder_names' (or is named 'x'), we override with a zero-cost record\n",
        "    that mirrors the usual keys but has all 0 for times and memory.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Optional[Dict[str, Any]]]:\n",
        "            layer_name -> row dict or None if not found\n",
        "    \"\"\"\n",
        "    # If no placeholder set is given, default to empty\n",
        "    placeholder_names = placeholder_names or set()\n",
        "\n",
        "    layer_records = {}\n",
        "\n",
        "    # Helper function to build a zero-cost record\n",
        "    def build_zero_record(layer_name: str, compute_str: str) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"Task_ID\": task_id,\n",
        "            \"Model\": model_name,\n",
        "            \"Layer\": layer_name,\n",
        "            \"Compute\": compute_str if compute_str else \"N/A\",\n",
        "            \"Self CPU (us)\": 0.0,\n",
        "            \"CPU Total (us)\": 0.0,\n",
        "            \"CUDA Total (us)\": 0.0,\n",
        "            \"Self CPU Mem (bytes)\": 0,\n",
        "            \"Self CUDA Mem (bytes)\": 0,\n",
        "            \"Total Execution Time (us)\": 0.0,\n",
        "            \"Total Memory Used (bytes)\": 0\n",
        "        }\n",
        "\n",
        "    for layer in layer_names:\n",
        "        # 1) If it's in placeholder_names or specifically called \"x\", produce a zero-cost record\n",
        "        if layer in placeholder_names or layer == \"x\":\n",
        "            layer_records[layer] = build_zero_record(layer, compute or \"\")\n",
        "            continue\n",
        "\n",
        "        # 2) Otherwise, do normal DataFrame filter\n",
        "        mask = (\n",
        "            (profile_db['Task_ID'] == task_id)\n",
        "            & (profile_db['Model'] == model_name)\n",
        "            & (profile_db['Layer'] == layer)\n",
        "        )\n",
        "        if compute is not None:\n",
        "            mask = mask & (profile_db['Compute'] == compute)\n",
        "\n",
        "        matched = profile_db.loc[mask]\n",
        "\n",
        "        if not matched.empty:\n",
        "            row_dict = matched.iloc[0].to_dict()  # First match\n",
        "            layer_records[layer] = row_dict\n",
        "        else:\n",
        "            # If no match found, store None\n",
        "            layer_records[layer] = None\n",
        "\n",
        "    return layer_records\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Represents a single DNN inference task with DAG-based stage allocation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_id: str, model: nn.Module, input_data: torch.Tensor, model_name: str, profiler: 'Profiler'):\n",
        "        self.task_id = task_id\n",
        "        self.model = model\n",
        "        self.input_data = input_data\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.stages: Dict[str, 'Stage'] = {}\n",
        "        self.graph = nx.DiGraph()\n",
        "\n",
        "        self.start_time: Optional[float] = None\n",
        "        self.finish_time: Optional[float] = None\n",
        "\n",
        "        self.output_data: Optional[torch.Tensor] = None\n",
        "        self.busy_time: float = 0.0\n",
        "        self.computation_time: float = 0.0\n",
        "        self.transfer_time: float = 0.0\n",
        "\n",
        "        self.profiler = profiler\n",
        "        self.model.eval()\n",
        "        self.init_traced_graph = None\n",
        "        self.placeholder_names = set()\n",
        "\n",
        "        self.prof_records: Dict[tuple, Optional[Dict[str, Any]]] = {}\n",
        "\n",
        "        # Build the DAG of stages\n",
        "        self._initialize_dag(group_size=4)\n",
        "\n",
        "    def _initialize_dag(self, group_size: int = 2):\n",
        "        # 1) Symbolically trace\n",
        "        tracer = fx.symbolic_trace(self.model)\n",
        "        traced_graph = tracer.graph\n",
        "\n",
        "        topological_order = [node for node in traced_graph.nodes]\n",
        "        # print(topological_order)\n",
        "        self.init_traced_graph = [n.name for n in topological_order]\n",
        "        # print(self.init_traced_graph)\n",
        "\n",
        "        self.placeholder_names = set(node.name for node in topological_order if node.op == \"placeholder\")\n",
        "\n",
        "        # from utils import group_topological_order  # or your local import\n",
        "        grouped_stages = group_topological_order([n.name for n in topological_order],\n",
        "                                                 group_size=group_size)\n",
        "\n",
        "        # 2) Create Stage objects\n",
        "        # from stage import Stage  # or local\n",
        "        for stage_name, node_names in grouped_stages.items():\n",
        "            stage_id = f\"{self.task_id}-{stage_name}\"\n",
        "            nodes = [n for n in traced_graph.nodes if n.name in node_names]\n",
        "\n",
        "\n",
        "            stage = Stage(\n",
        "                stage_id=stage_id,\n",
        "                nodes=nodes,\n",
        "                assigned_node=None,\n",
        "                task=self\n",
        "            )\n",
        "            self.add_stage(stage)\n",
        "\n",
        "        # 3) Add dependencies\n",
        "        for stage_name, node_names in grouped_stages.items():\n",
        "            stage_id = f\"{self.task_id}-{stage_name}\"\n",
        "            if stage_name != \"stage-1\":\n",
        "                prev_idx = int(stage_name.split('-')[1]) - 1\n",
        "                prev_stage_id = f\"{self.task_id}-stage-{prev_idx}\"\n",
        "                self.add_dependency(prev_stage_id, stage_id)\n",
        "\n",
        "        # 4) Retrieve & store profiler records if profiler is available\n",
        "        if self.profiler is not None:\n",
        "            # Get the entire profiler DataFrame\n",
        "            db = self.profiler.get_profile_db()\n",
        "\n",
        "            # Filter to relevant rows for this Task + Model\n",
        "            mask = (\n",
        "                (db['Task_ID'] == self.task_id) &\n",
        "                (db['Model'] == self.model_name)\n",
        "            )\n",
        "            relevant_df = db.loc[mask]\n",
        "\n",
        "            # Find all Compute strings present in the DB for this task & model\n",
        "            all_computes = relevant_df['Compute'].unique().tolist()\n",
        "\n",
        "            # For each compute, retrieve layer records and store them in self.prof_records\n",
        "            for compute_str in all_computes:\n",
        "                records_for_compute = retrieve_layer_profile_records(\n",
        "                    profile_db=db,\n",
        "                    task_id=self.task_id,\n",
        "                    model_name=self.model_name,\n",
        "                    compute=compute_str,\n",
        "                    layer_names=self.init_traced_graph,\n",
        "                    placeholder_names=self.placeholder_names\n",
        "\n",
        "                )\n",
        "                for layer_name, row_dict in records_for_compute.items():\n",
        "                    # Key is (compute, layer_name)\n",
        "                    self.prof_records[(compute_str, layer_name)] = row_dict\n",
        "\n",
        "\n",
        "    def get_forward_pass_time(self, sum_across_compute: bool = False) -> float:\n",
        "        \"\"\"\n",
        "        Retrieves the 'forward_pass' time by querying the Profiler's DataFrame directly,\n",
        "        filtering on this Task's ID + Model + 'forward_pass'.\n",
        "\n",
        "        Args:\n",
        "            sum_across_compute (bool):\n",
        "                If True, sums the forward pass times across all devices (CPU-0, CPU-1, etc.).\n",
        "                If False, returns the max across devices.\n",
        "\n",
        "        Returns:\n",
        "            float: Total forward-pass time in microseconds (or 0.0 if none found).\n",
        "        \"\"\"\n",
        "        if not self.profiler:\n",
        "            # If for some reason there's no Profiler, return 0.\n",
        "            return 0.0\n",
        "\n",
        "        # 1) Get the global profile DataFrame\n",
        "        profile_df = self.profiler.get_profile_db()\n",
        "\n",
        "        # 2) Filter rows for (Task_ID == self.task_id) & (Model == self.model_name) & (Layer == 'forward_pass')\n",
        "        mask = (\n",
        "            (profile_df['Task_ID'] == self.task_id) &\n",
        "            (profile_df['Model'] == self.model_name) &\n",
        "            (profile_df['Layer'] == 'forward_pass')\n",
        "        )\n",
        "        matched = profile_df.loc[mask]\n",
        "\n",
        "        if matched.empty:\n",
        "            return 0.0\n",
        "\n",
        "        # 3) Extract the 'Total Execution Time (us)' for each device\n",
        "        times = matched['Total Execution Time (us)']\n",
        "\n",
        "        # 4) Depending on your strategy, sum across all devices or take max\n",
        "        if sum_across_compute:\n",
        "            return times.sum()\n",
        "        else:\n",
        "            return times.max()\n",
        "\n",
        "\n",
        "    def add_stage(self, stage: 'Stage'):\n",
        "        if stage.stage_id in self.stages:\n",
        "            raise ValueError(f\"Stage ID {stage.stage_id} already exists in Task {self.task_id}.\")\n",
        "        self.stages[stage.stage_id] = stage\n",
        "        self.graph.add_node(stage.stage_id, stage=stage)\n",
        "\n",
        "    def add_dependency(self, from_stage_id: str, to_stage_id: str):\n",
        "        if from_stage_id not in self.stages or to_stage_id not in self.stages:\n",
        "            raise ValueError(\"Stages must exist before adding a dependency.\")\n",
        "        self.graph.add_edge(from_stage_id, to_stage_id)\n",
        "        self.stages[to_stage_id].add_dependency(from_stage_id)\n",
        "        self.stages[from_stage_id].add_dependent(to_stage_id)\n",
        "\n",
        "    def get_execution_order(self) -> List[str]:\n",
        "        try:\n",
        "            return list(nx.topological_sort(self.graph))\n",
        "        except nx.NetworkXUnfeasible:\n",
        "            raise ValueError(\"Stage dependencies contain a cycle.\")\n",
        "\n",
        "    def assign_nodes_to_stages(self, available_nodes: List['Node']):\n",
        "        \"\"\"\n",
        "        Round-robin node assignment. Also moves submodules to the correct device\n",
        "        so that the submodule weights will be on CPU or GPU prior to execution.\n",
        "        \"\"\"\n",
        "        node_count = len(available_nodes)\n",
        "        sorted_stage_ids = sorted(self.stages.keys())  # ensure stable ordering\n",
        "\n",
        "        for idx, stage_id in enumerate(sorted_stage_ids):\n",
        "            stage = self.stages[stage_id]\n",
        "            # node = available_nodes[idx % node_count]\n",
        "            node = available_nodes[idx % node_count]\n",
        "            stage.assigned_node = node\n",
        "\n",
        "    def get_stage(self, stage_id: str) -> Optional['Stage']:\n",
        "        return self.stages.get(stage_id, None)\n",
        "\n",
        "    def get_total_execution_time(self) -> float:\n",
        "        if self.start_time and self.finish_time:\n",
        "            return self.finish_time - self.start_time\n",
        "        return 0.0\n",
        "\n",
        "    def update_busy_time(self, stage_execution_time: float, stage_transfer_time: float = 0.0):\n",
        "        self.busy_time += stage_execution_time\n",
        "        self.transfer_time += stage_transfer_time\n",
        "        self.computation_time += (stage_execution_time - stage_transfer_time)\n",
        "\n",
        "    def set_output_data(self, output: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Typically we want final output on CPU for correctness checks.\n",
        "        \"\"\"\n",
        "        if output is not None:\n",
        "            self.output_data = output.cpu()\n",
        "        else:\n",
        "            self.output_data = None\n",
        "        self.finish_time = time.time()\n",
        "\n",
        "    def print_stage_allocations(self):\n",
        "        print(f\"=== Stage Allocations for Task '{self.task_id}' ===\")\n",
        "        for stage_id, stage in self.stages.items():\n",
        "            layer_names = []\n",
        "            for fx_node in stage.nodes:\n",
        "                # print(fx_node.name,\"****\")\n",
        "                if isinstance(fx_node.target, str):\n",
        "                    layer_names.append(fx_node.target)\n",
        "                else:\n",
        "                    layer_names.append(str(fx_node.target))\n",
        "            node_id = stage.assigned_node.node_id if stage.assigned_node else \"Unassigned\"\n",
        "            print(f\"Stage ID: {stage_id}\")\n",
        "            print(f\"  Assigned Node: {node_id}\")\n",
        "            print(f\"  Layers: {', '.join(layer_names)}\" if layer_names else \"  Layers: None\")\n",
        "            print(f\"  Dependencies: {stage.dependencies}\")\n",
        "            print(f\"  Dependents: {stage.dependents}\\n\")\n"
      ],
      "metadata": {
        "id": "wJChxVTaAL5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import networkx as nx\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.fx as fx\n",
        "# import time\n",
        "# from typing import List, Dict, Optional, Any\n",
        "\n",
        "# # from stage import Stage\n",
        "# # from utils import group_topological_order\n",
        "\n",
        "# class Task:\n",
        "#     \"\"\"\n",
        "#     Represents a single DNN inference task with DAG-based stage allocation,\n",
        "#     enhanced to store/organize its own profiling data in a model-agnostic way.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self,\n",
        "#                  task_id: str,\n",
        "#                  model: nn.Module,\n",
        "#                  input_data: torch.Tensor,\n",
        "#                  model_name: str,\n",
        "#                  profiler: 'Profiler'):\n",
        "#         self.task_id = task_id\n",
        "#         self.model = model\n",
        "#         self.input_data = input_data\n",
        "#         self.model_name = model_name\n",
        "\n",
        "#         # Stage-based DAG\n",
        "#         self.stages: Dict[str, 'Stage'] = {}\n",
        "#         self.graph = nx.DiGraph()\n",
        "\n",
        "#         # Execution timers\n",
        "#         self.start_time: Optional[float] = None\n",
        "#         self.finish_time: Optional[float] = None\n",
        "#         self.output_data: Optional[torch.Tensor] = None\n",
        "\n",
        "#         # Busy time metrics\n",
        "#         self.busy_time: float = 0.0\n",
        "#         self.computation_time: float = 0.0\n",
        "#         self.transfer_time: float = 0.0\n",
        "\n",
        "#         self.profiler = profiler\n",
        "#         self.model.eval()\n",
        "\n",
        "#         # NEW: Profiling data fields\n",
        "#         self.raw_profiling_data: List[Dict[str, Any]] = []          # All raw rows for this task\n",
        "#         self.parsed_layer_data: Dict[str, Dict[str, Any]] = {}      # Mapped layer/operator -> {device: metrics}\n",
        "#         self.traced_graph_order: List[str] = []                     # Node names in topological order\n",
        "#         self.forward_pass_summary: Dict[str, Any] = {}              # Optional aggregated metrics for the entire pass\n",
        "\n",
        "#         # Build the DAG of stages\n",
        "#         self._initialize_dag(group_size=4)\n",
        "\n",
        "#     def _initialize_dag(self, group_size: int = 2):\n",
        "#         \"\"\"\n",
        "#         Symbolically trace the model, generate a topological order of nodes,\n",
        "#         group them into stages, and build a DAG of those stages.\n",
        "#         \"\"\"\n",
        "#         # 1) Symbolic trace\n",
        "#         traced_module = fx.symbolic_trace(self.model)\n",
        "#         traced_graph = traced_module.graph\n",
        "\n",
        "#         # 2) Grab the node list in topological order\n",
        "#         topological_nodes = [node for node in traced_graph.nodes]\n",
        "#         self.traced_graph_order = [node.name for node in topological_nodes]\n",
        "#         print(topological_nodes)  # Debug info, can remove if not needed\n",
        "\n",
        "#         # 3) Group the node names\n",
        "#         # from utils import group_topological_order\n",
        "#         grouped_stages = group_topological_order(self.traced_graph_order, group_size=group_size)\n",
        "\n",
        "#         # 4) Create Stage objects and add them to self.stages + self.graph\n",
        "#         # from stage import Stage\n",
        "#         for stage_name, node_names in grouped_stages.items():\n",
        "#             stage_id = f\"{self.task_id}-{stage_name}\"\n",
        "#             # Filter the actual FxNode objects by name\n",
        "#             nodes_in_stage = [n for n in traced_graph.nodes if n.name in node_names]\n",
        "\n",
        "#             stage = Stage(\n",
        "#                 stage_id=stage_id,\n",
        "#                 nodes=nodes_in_stage,\n",
        "#                 assigned_node=None,\n",
        "#                 task=self\n",
        "#             )\n",
        "#             self.add_stage(stage)\n",
        "\n",
        "#         # 5) Add dependencies for a linear pipeline\n",
        "#         for stage_name, node_names in grouped_stages.items():\n",
        "#             stage_id = f\"{self.task_id}-{stage_name}\"\n",
        "#             if stage_name != \"stage-1\":\n",
        "#                 prev_idx = int(stage_name.split('-')[1]) - 1\n",
        "#                 prev_stage_id = f\"{self.task_id}-stage-{prev_idx}\"\n",
        "#                 self.add_dependency(prev_stage_id, stage_id)\n",
        "\n",
        "#     def add_stage(self, stage: 'Stage'):\n",
        "#         if stage.stage_id in self.stages:\n",
        "#             raise ValueError(f\"Stage ID {stage.stage_id} already exists in Task {self.task_id}.\")\n",
        "#         self.stages[stage.stage_id] = stage\n",
        "#         self.graph.add_node(stage.stage_id, stage=stage)\n",
        "\n",
        "#     def add_dependency(self, from_stage_id: str, to_stage_id: str):\n",
        "#         if from_stage_id not in self.stages or to_stage_id not in self.stages:\n",
        "#             raise ValueError(\"Stages must exist before adding a dependency.\")\n",
        "#         self.graph.add_edge(from_stage_id, to_stage_id)\n",
        "#         self.stages[to_stage_id].add_dependency(from_stage_id)\n",
        "#         self.stages[from_stage_id].add_dependent(to_stage_id)\n",
        "\n",
        "#     def get_execution_order(self) -> List[str]:\n",
        "#         \"\"\"\n",
        "#         Return the stage IDs in a topological sequence.\n",
        "#         \"\"\"\n",
        "#         try:\n",
        "#             return list(nx.topological_sort(self.graph))\n",
        "#         except nx.NetworkXUnfeasible:\n",
        "#             raise ValueError(\"Stage dependencies contain a cycle.\")\n",
        "\n",
        "#     def assign_nodes_to_stages(self, available_nodes: List['Node']):\n",
        "#         \"\"\"\n",
        "#         Round-robin node assignment; also moves submodules to the device\n",
        "#         so submodule weights are on CPU/GPU prior to execution.\n",
        "#         \"\"\"\n",
        "#         node_count = len(available_nodes)\n",
        "#         sorted_stage_ids = sorted(self.stages.keys())\n",
        "\n",
        "#         for idx, stage_id in enumerate(sorted_stage_ids):\n",
        "#             stage = self.stages[stage_id]\n",
        "#             node = available_nodes[idx % node_count]\n",
        "#             stage.assigned_node = node\n",
        "\n",
        "#             # Decide device string\n",
        "#             if node.gpu is not None and torch.cuda.is_available():\n",
        "#                 device_str = f\"cuda:{node.gpu}\"\n",
        "#             else:\n",
        "#                 device_str = \"cpu\"\n",
        "\n",
        "#             # Move submodules used by this stage to device_str\n",
        "#             for fx_node in stage.nodes:\n",
        "#                 if fx_node.op == 'call_module':\n",
        "#                     submodule = self.model.get_submodule(fx_node.target)\n",
        "#                     submodule.to(device_str)\n",
        "\n",
        "#     def get_stage(self, stage_id: str) -> Optional['Stage']:\n",
        "#         return self.stages.get(stage_id, None)\n",
        "\n",
        "#     def get_total_execution_time(self) -> float:\n",
        "#         if self.start_time and self.finish_time:\n",
        "#             return self.finish_time - self.start_time\n",
        "#         return 0.0\n",
        "\n",
        "#     def update_busy_time(self, stage_execution_time: float, stage_transfer_time: float = 0.0):\n",
        "#         self.busy_time += stage_execution_time\n",
        "#         self.transfer_time += stage_transfer_time\n",
        "#         self.computation_time += (stage_execution_time - stage_transfer_time)\n",
        "\n",
        "#     def set_output_data(self, output: torch.Tensor):\n",
        "#         \"\"\"\n",
        "#         Store final output on CPU for correctness checks, mark finish time.\n",
        "#         \"\"\"\n",
        "#         if output is not None:\n",
        "#             self.output_data = output.cpu()\n",
        "#         else:\n",
        "#             self.output_data = None\n",
        "#         self.finish_time = time.time()\n",
        "\n",
        "#     def print_stage_allocations(self):\n",
        "#         print(f\"=== Stage Allocations for Task '{self.task_id}' ===\")\n",
        "#         for stage_id, stage in self.stages.items():\n",
        "#             layer_names = []\n",
        "#             for fx_node in stage.nodes:\n",
        "#                 if isinstance(fx_node.target, str):\n",
        "#                     layer_names.append(fx_node.target)\n",
        "#                 else:\n",
        "#                     layer_names.append(str(fx_node.target))\n",
        "#             node_id = stage.assigned_node.node_id if stage.assigned_node else \"Unassigned\"\n",
        "#             print(f\"Stage ID: {stage_id}\")\n",
        "#             print(f\"  Assigned Node: {node_id}\")\n",
        "#             print(f\"  Layers: {', '.join(layer_names)}\" if layer_names else \"  Layers: None\")\n",
        "#             print(f\"  Dependencies: {stage.dependencies}\")\n",
        "#             print(f\"  Dependents: {stage.dependents}\\n\")\n",
        "\n",
        "#     # ----------------------------------------------------------------------\n",
        "#     # NEW: Store and parse profiling data for this Task\n",
        "#     # ----------------------------------------------------------------------\n",
        "#     def init_profiling_data(self,\n",
        "#                             profiling_records: List[Dict[str, Any]],\n",
        "#                             forward_pass_agg: Optional[Dict[str, Any]] = None) -> None:\n",
        "#         \"\"\"\n",
        "#         Called after profiling is done for this Task. This stores the raw rows,\n",
        "#         aggregates them into self.parsed_layer_data, and optionally stores\n",
        "#         forward-pass summary info.\n",
        "\n",
        "#         Args:\n",
        "#             profiling_records: A list of dictionaries, each with columns from the profiler\n",
        "#                               (Layer, Compute, CPU Total (us), etc.).\n",
        "#             forward_pass_agg: Aggregated metrics for the entire forward pass (optional).\n",
        "#         \"\"\"\n",
        "#         self.raw_profiling_data = profiling_records\n",
        "#         self.forward_pass_summary = forward_pass_agg or {}\n",
        "\n",
        "#         temp_data: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "#         for row in profiling_records:\n",
        "#             raw_layer_name = row.get(\"Layer\", \"\")\n",
        "#             compute_dev = row.get(\"Compute\", \"Unknown\")\n",
        "\n",
        "#             mapped_name, skip_flag = self._map_profiler_layer_to_fx_name(raw_layer_name)\n",
        "#             if skip_flag:\n",
        "#                 continue  # e.g. skip [memory], ProfilerStep*, etc.\n",
        "\n",
        "#             if mapped_name not in temp_data:\n",
        "#                 temp_data[mapped_name] = {}\n",
        "\n",
        "#             cpu_total_us = row.get(\"CPU Total (us)\", 0.0)\n",
        "#             self_cpu_us = row.get(\"Self CPU (us)\", 0.0)\n",
        "#             cuda_total_us = row.get(\"CUDA Total (us)\", 0.0)\n",
        "#             mem_cpu_bytes = row.get(\"Self CPU Mem (bytes)\", 0)\n",
        "#             mem_cuda_bytes = row.get(\"Self CUDA Mem (bytes)\", 0)\n",
        "#             total_exec_us = row.get(\"Total Execution Time (us)\", 0.0)\n",
        "\n",
        "#             temp_data[mapped_name][compute_dev] = {\n",
        "#                 \"cpu_total_us\": cpu_total_us,\n",
        "#                 \"self_cpu_us\": self_cpu_us,\n",
        "#                 \"cuda_total_us\": cuda_total_us,\n",
        "#                 \"mem_cpu_bytes\": mem_cpu_bytes,\n",
        "#                 \"mem_cuda_bytes\": mem_cuda_bytes,\n",
        "#                 \"total_exec_us\": total_exec_us,\n",
        "#             }\n",
        "\n",
        "#         self.parsed_layer_data = temp_data\n",
        "\n",
        "#     def _map_profiler_layer_to_fx_name(self, raw_layer_name: str) -> (str, bool):\n",
        "#         \"\"\"\n",
        "#         Maps a profiler 'Layer' string (like 'resnet18.layer1.0.conv1.forward', 'cat',\n",
        "#         '[memory]', 'ProfilerStep*', etc.) to a node name in traced_graph_order.\n",
        "#         Returns (mapped_name, skip_flag).\n",
        "#           - mapped_name: The final name to store in parsed_layer_data\n",
        "#           - skip_flag: whether we skip storing this line entirely\n",
        "\n",
        "#         Adjust logic to match your naming patterns. This is an example approach.\n",
        "#         \"\"\"\n",
        "#         # 1) Skip known lines\n",
        "#         if \"[memory]\" in raw_layer_name or \"ProfilerStep*\" in raw_layer_name:\n",
        "#             return (\"[skip]\", True)\n",
        "#         if raw_layer_name in [\"forward_pass\"]:\n",
        "#             # keep if you want to store it, or skip. We'll keep:\n",
        "#             return (\"forward_pass\", False)\n",
        "#         if raw_layer_name.startswith(\"placeholder\"):\n",
        "#             return (\"placeholder\", False)\n",
        "#         if raw_layer_name.startswith(\"output\"):\n",
        "#             return (\"output\", False)\n",
        "\n",
        "#         # 2) Remove .forward if present\n",
        "#         name = raw_layer_name\n",
        "#         if name.endswith(\".forward\"):\n",
        "#             name = name[:-8]  # remove \".forward\"\n",
        "\n",
        "#         # 3) If there's a known prefix, remove it. Adjust as needed.\n",
        "#         # You might have a single known prefix. Here's an example:\n",
        "#         known_prefixes = [\"resnet18.\", \"SimpleCNN.\", \"simple_cnn_task\", \"resnet_task\"]\n",
        "#         for prefix in known_prefixes:\n",
        "#             if name.startswith(prefix):\n",
        "#                 name = name[len(prefix):]\n",
        "\n",
        "#         # 4) Replace '.' with '_' if it looks like a submodule path\n",
        "#         #    but skip if it's an operator like \"cat\", \"add\", etc. that has no dot.\n",
        "#         # We'll do a naive approach: only replace if there's a dot.\n",
        "#         if \".\" in name and not (name in [\"cat\", \"add\", \"flatten\", \"relu\", \"conv2d\"]):\n",
        "#             name = name.replace(\".\", \"_\")\n",
        "\n",
        "#         # cleanup double underscores\n",
        "#         while \"__\" in name:\n",
        "#             name = name.replace(\"__\", \"_\")\n",
        "\n",
        "#         # 5) Attempt partial matching in traced_graph_order\n",
        "#         possible_matches = []\n",
        "#         for fx_node in self.traced_graph_order:\n",
        "#             if name in fx_node or fx_node in name:\n",
        "#                 possible_matches.append(fx_node)\n",
        "\n",
        "#         if len(possible_matches) == 1:\n",
        "#             return (possible_matches[0], False)\n",
        "#         elif len(possible_matches) > 1:\n",
        "#             # pick the first or do a more advanced approach\n",
        "#             return (possible_matches[0], False)\n",
        "\n",
        "#         # If no matches, fallback to the transformed name\n",
        "#         return (name, False)\n",
        "\n",
        "#     def __repr__(self) -> str:\n",
        "#         \"\"\"\n",
        "#         Returns a string representation for debugging, showing Task ID\n",
        "#         and a summary of profiling data if available.\n",
        "#         \"\"\"\n",
        "#         lines = [f\"Task(task_id={self.task_id}, model={self.model_name})\"]\n",
        "#         if self.parsed_layer_data:\n",
        "#             lines.append(f\"  #parsed_layers={len(self.parsed_layer_data)}\")\n",
        "#         if self.forward_pass_summary:\n",
        "#             lines.append(f\"  forward_pass_summary={self.forward_pass_summary}\")\n",
        "#         if self.stages:\n",
        "#             lines.append(f\"  #stages={len(self.stages)}\")\n",
        "#         return \"\\n\".join(lines)\n"
      ],
      "metadata": {
        "id": "dYWStNXMLqeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load_metric.py\n",
        "from typing import Protocol, runtime_checkable\n",
        "from abc import abstractmethod\n",
        "\n",
        "# We'll assume you have references to Task and Taskset so you can import them or forward-declare:\n",
        "# from task import Task\n",
        "# from taskset import Taskset\n",
        "\n",
        "@runtime_checkable\n",
        "class LoadMetric(Protocol):\n",
        "    \"\"\"\n",
        "    A protocol (interface) for computing a 'load' or 'utilization' metric\n",
        "    for a Task in the context of a Taskset.\n",
        "    \"\"\"\n",
        "    @abstractmethod\n",
        "    def compute(self, task: \"Task\", taskset: \"Taskset\") -> float:\n",
        "        \"\"\"\n",
        "        Computes a load metric for `task`, possibly referencing data\n",
        "        in `taskset`. Returns a float representing the load or utilization.\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "class HPCUtilizationMetric:\n",
        "    \"\"\"\n",
        "    Default HPC-style utilization metric:\n",
        "      utilization = task.busy_time / observation_window\n",
        "\n",
        "    where observation_window is computed from the Taskset\n",
        "    (e.g., sum of forward pass times + a slack factor).\n",
        "    \"\"\"\n",
        "    def __init__(self, slack_fraction: float = 0.2):\n",
        "        self.slack_fraction = slack_fraction\n",
        "\n",
        "    def compute(self, task: \"Task\", taskset: \"Taskset\") -> float:\n",
        "        # We ask Taskset for an observation window\n",
        "        obs_window = taskset.compute_observation_window(self.slack_fraction)\n",
        "        if obs_window <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        # HPC approach: utilization = busy_time / observation_window\n",
        "        return task.busy_time / obs_window"
      ],
      "metadata": {
        "id": "yBh-EIiQkpoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taskset.py\n",
        "\n",
        "import threading\n",
        "import time\n",
        "from typing import List, Dict\n",
        "# from task import Task\n",
        "# from node import Node\n",
        "# from utils import resolve_arg\n",
        "\n",
        "class Taskset:\n",
        "    \"\"\"\n",
        "    Manages a collection of Tasks and orchestrates their execution using DAG-based stage allocation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tasks: List[Task], available_nodes: List['Node'] ,metric: LoadMetric = None):\n",
        "        \"\"\"\n",
        "        Initializes the Taskset.\n",
        "\n",
        "        Args:\n",
        "            tasks (List[Task]): The list of tasks to manage.\n",
        "            available_nodes (List[Node]): The list of available compute nodes.\n",
        "        \"\"\"\n",
        "        self.tasks = tasks\n",
        "        self.available_nodes = available_nodes\n",
        "\n",
        "        # Performance Metrics\n",
        "        self.total_utilization: float = 0.0\n",
        "        self.average_turnaround_time: float = 0.0\n",
        "        self.throughput: float = 0.0\n",
        "        self.makespan: float = 0.0\n",
        "        self.task_completion_rate: float = 0.0\n",
        "\n",
        "        # from load_metric import HPCUtilizationMetric  # or define up top\n",
        "        self.metric = metric if metric is not None else HPCUtilizationMetric()\n",
        "\n",
        "        # Initialize a lock for thread-safe updates if needed\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "        self.loads = {}\n",
        "\n",
        "    def compute_observation_window(self, slack_fraction: float = 0.2) -> float:\n",
        "        \"\"\"\n",
        "        Example: sum up the forward_pass times from each Task's profiler data\n",
        "        and multiply by (1 + slack_fraction).\n",
        "        Return the total in microseconds or seconds (up to you).\n",
        "        \"\"\"\n",
        "        total_forward_time = 0.0\n",
        "        for task in self.tasks:\n",
        "            # We can define a method on Task for \"get_forward_pass_time()\", or\n",
        "            # do it inline by scanning task.prof_records.\n",
        "            total_forward_time += task.get_forward_pass_time()  # see below\n",
        "\n",
        "        obs_window = total_forward_time * (1.0 + slack_fraction)\n",
        "        # print(obs_window)\n",
        "        return obs_window\n",
        "\n",
        "    def reset_loads(self):\n",
        "        \"\"\"\n",
        "        Clears out the load dictionary so it can be recalculated\n",
        "        or updated without stale values.\n",
        "        \"\"\"\n",
        "        self.loads = {}\n",
        "\n",
        "\n",
        "    def compute_loads(self, metric: \"LoadMetric\" = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Computes load values for each task using either:\n",
        "          - The user-provided 'metric' argument (if not None),\n",
        "          - Or else the default 'self.metric' stored in Taskset (if metric is None).\n",
        "\n",
        "        Returns:\n",
        "            A dictionary mapping task_id -> load value.\n",
        "        \"\"\"\n",
        "        # If user didn't pass a metric, fallback to the default (self.metric)\n",
        "        if metric is None:\n",
        "            # If self.metric doesn't exist or is also None, you might\n",
        "            # want to create a default HPCUtilizationMetric here:\n",
        "            if not hasattr(self, \"metric\") or self.metric is None:\n",
        "                # from load_metric import HPCUtilizationMetric\n",
        "                self.metric = HPCUtilizationMetric()  # or with a chosen slack\n",
        "            metric = self.metric\n",
        "\n",
        "        self.loads = {}\n",
        "        for t in self.tasks:\n",
        "            load_val = metric.compute(t, self)\n",
        "            print(load_val)\n",
        "            self.loads[t.task_id] = load_val\n",
        "\n",
        "        return self.loads\n",
        "\n",
        "\n",
        "    def execute_all(self):\n",
        "        \"\"\"\n",
        "        Executes all tasks in parallel, managing stage allocations and dependencies.\n",
        "        Each task runs in its own thread, and stages are executed via Node worker threads.\n",
        "        \"\"\"\n",
        "        # Assign nodes to stages for each task using a load-balancing strategy\n",
        "        for task in self.tasks:\n",
        "            task.assign_nodes_to_stages(self.available_nodes)\n",
        "            task.print_stage_allocations()\n",
        "\n",
        "        threads = []\n",
        "        for task in self.tasks:\n",
        "            t = threading.Thread(target=self.execute_task, args=(task,))\n",
        "            t.start()\n",
        "            threads.append(t)\n",
        "\n",
        "        for t in threads:\n",
        "            t.join()\n",
        "\n",
        "        self.calculate_metrics()\n",
        "\n",
        "    def execute_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Executes a single task by running its stages in topological order.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The task to execute.\n",
        "        \"\"\"\n",
        "        print(f\"[Taskset] Starting execution of Task '{task.task_id}'.\")\n",
        "        task.start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            execution_order = task.get_execution_order()\n",
        "        except ValueError as e:\n",
        "            print(f\"[Taskset] Task '{task.task_id}' execution failed: {e}\")\n",
        "            return\n",
        "\n",
        "        # Dictionary to keep track of node outputs\n",
        "        node_outputs = {}\n",
        "\n",
        "        # Iterate through stages in topological order\n",
        "        for stage_id in execution_order:\n",
        "            stage = task.get_stage(stage_id)\n",
        "            if stage is None:\n",
        "                print(f\"[Taskset] Task '{task.task_id}': Stage '{stage_id}' not found.\")\n",
        "                continue\n",
        "\n",
        "            # Define the function to execute the stage with proper binding\n",
        "            def execute(current_stage=stage):\n",
        "                current_stage.run_stage(node_outputs)\n",
        "\n",
        "            # Enqueue the stage_execution function to the Node's task queue\n",
        "            try:\n",
        "                result_queue = stage.assigned_node.assign_task(execute)\n",
        "            except AttributeError as e:\n",
        "                print(f\"[Taskset] Task '{task.task_id}': Stage '{stage_id}' failed to assign to Node: {e}\")\n",
        "                # Assign infinite execution and transfer time to indicate failure\n",
        "                with self.lock:\n",
        "                    stage.execution_time = float('inf')\n",
        "                    stage.transfer_time = float('inf')\n",
        "                continue\n",
        "\n",
        "            # Wait for the stage to complete\n",
        "            try:\n",
        "                # We don't expect any return value from run_stage, so we just wait for completion\n",
        "                result = result_queue.get()\n",
        "                # Optionally, you can check if result is None or some status flag\n",
        "            except Exception as e:\n",
        "                print(f\"[Taskset] Task '{task.task_id}': Stage '{stage_id}' encountered an error during execution: {e}\")\n",
        "                with self.lock:\n",
        "                    stage.execution_time = float('inf')\n",
        "                    stage.transfer_time = float('inf')\n",
        "                continue\n",
        "\n",
        "            # Handle potential errors by checking execution_time\n",
        "            if stage.execution_time == float('inf'):\n",
        "                print(f\"[Taskset] Task '{task.task_id}': Stage '{stage_id}' failed during execution.\")\n",
        "\n",
        "        task.finish_time = time.time()\n",
        "        print(f\"[Taskset] Completed execution of Task '{task.task_id}'.\")\n",
        "\n",
        "    def calculate_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculates and updates performance metrics for the taskset.\n",
        "        \"\"\"\n",
        "        # 1) total_busy_time = sum of (execution_time) across all tasks\n",
        "        total_busy_time = sum(stage.execution_time for task in self.tasks for stage in task.stages.values())\n",
        "\n",
        "        # 2) total_available_time = observation_window * #nodes\n",
        "        if not any(task.finish_time for task in self.tasks):\n",
        "            self.total_utilization = 0.0\n",
        "            self.average_turnaround_time = 0.0\n",
        "            self.throughput = 0.0\n",
        "            self.makespan = 0.0\n",
        "            self.task_completion_rate = 0.0\n",
        "            return\n",
        "\n",
        "        earliest_start = min(task.start_time for task in self.tasks if task.start_time)\n",
        "        latest_finish = max(task.finish_time for task in self.tasks if task.finish_time)\n",
        "        observation_window = latest_finish - earliest_start\n",
        "        total_available_time = observation_window * len(set(\n",
        "            stage.assigned_node.node_id for task in self.tasks for stage in task.stages.values()\n",
        "        ))\n",
        "        self.total_utilization = (total_busy_time / total_available_time) if total_available_time > 0 else 0.0\n",
        "\n",
        "        # 3) average turnaround\n",
        "        turnaround_times = [task.get_total_execution_time() for task in self.tasks]\n",
        "        if turnaround_times:\n",
        "            self.average_turnaround_time = sum(turnaround_times) / len(turnaround_times)\n",
        "        else:\n",
        "            self.average_turnaround_time = 0.0\n",
        "\n",
        "        # 4) makespan = difference between earliest start and latest finish\n",
        "        if earliest_start and latest_finish:\n",
        "            self.makespan = latest_finish - earliest_start\n",
        "        else:\n",
        "            self.makespan = 0.0\n",
        "\n",
        "        # 5) throughput = number_of_tasks / makespan\n",
        "        if self.makespan > 0:\n",
        "            self.throughput = len(self.tasks) / self.makespan\n",
        "        else:\n",
        "            self.throughput = 0.0\n",
        "\n",
        "        # 6) task completion rate\n",
        "        completed_tasks = [t for t in self.tasks if t.output_data is not None]\n",
        "        self.task_completion_rate = len(completed_tasks) / len(self.tasks) if self.tasks else 0.0\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"Taskset(total_tasks={len(self.tasks)}, \"\n",
        "            f\"total_utilization={self.total_utilization:.2%}, \"\n",
        "            f\"average_turnaround_time={self.average_turnaround_time:.6f} sec, \"\n",
        "            f\"throughput={self.throughput:.2f} tasks/sec, \"\n",
        "            f\"makespan={self.makespan:.6f} sec, \"\n",
        "            f\"task_completion_rate={self.task_completion_rate:.2%})\"\n",
        "        )\n"
      ],
      "metadata": {
        "id": "fpNKCjQZ8tUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluator.py\n",
        "\n",
        "import torch\n",
        "from typing import Dict\n",
        "import time\n",
        "\n",
        "class Evaluator:\n",
        "    \"\"\"\n",
        "    Evaluator runs tasks in naive mode vs. parallel mode and compares outputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, taskset: 'Taskset', profiler: 'Profiler'):\n",
        "        self.taskset = taskset\n",
        "        self.profiler = profiler\n",
        "\n",
        "        # These track each task's final output (naive vs. parallel).\n",
        "        self.naive_outputs: Dict[str, torch.Tensor] = {}\n",
        "        self.parallel_outputs: Dict[str, torch.Tensor] = {}\n",
        "\n",
        "        # These track each task's individual total time\n",
        "        # (sum-of-times approach from your original code).\n",
        "        self.naive_execution_times: Dict[str, float] = {}\n",
        "        self.parallel_execution_times: Dict[str, float] = {}\n",
        "\n",
        "        # We also track each taskâ€™s â€œcompletion timeâ€ (relative to the start\n",
        "        # of naive or parallel execution). That lets us see\n",
        "        # when each task actually finished.\n",
        "        self.naive_completion_times: Dict[str, float] = {}\n",
        "        self.parallel_completion_times: Dict[str, float] = {}\n",
        "\n",
        "        # Finally, we store the overall naive and parallel â€œmakespanâ€.\n",
        "        self.naive_makespan: float = 0.0\n",
        "        self.parallel_makespan: float = 0.0\n",
        "\n",
        "    def run_naive_execution(self):\n",
        "        \"\"\"\n",
        "        Runs each task **sequentially** and measures:\n",
        "          - Per-task execution time (the original approach),\n",
        "          - The time each task finishes (relative to the naive start),\n",
        "          - The overall naive makespan.\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Starting Naive Execution.\")\n",
        "\n",
        "        # Overall start time for the naive run:\n",
        "        naive_start = time.time()\n",
        "\n",
        "        for task in self.taskset.tasks:\n",
        "            model = task.model\n",
        "            input_tensor = task.input_data\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "            print(f\"[Evaluator] Task '{task.task_id}': Running on {device}\")\n",
        "            model.to(device)\n",
        "            input_tensor = input_tensor.to(device)\n",
        "\n",
        "            t0 = time.time()\n",
        "            with torch.no_grad():\n",
        "                output = model(input_tensor)\n",
        "            t1 = time.time()\n",
        "\n",
        "            exec_time = t1 - t0\n",
        "            print(f\"[Evaluator] Task '{task.task_id}' (Naive) executed in {exec_time:.6f} seconds.\")\n",
        "\n",
        "            # Store the sum-of-times approach for later reference\n",
        "            self.naive_execution_times[task.task_id] = exec_time\n",
        "            # The â€œfinish timeâ€ for this task is how long since naive_start\n",
        "            self.naive_completion_times[task.task_id] = time.time() - naive_start\n",
        "\n",
        "            # Record the final output on CPU\n",
        "            self.naive_outputs[task.task_id] = output.cpu()\n",
        "\n",
        "        # After all tasks are done (sequentially), measure the total naive makespan\n",
        "        naive_end = time.time()\n",
        "        self.naive_makespan = naive_end - naive_start\n",
        "        print(f\"[Evaluator] Naive Execution Completed. Naive makespan = {self.naive_makespan:.6f} s\\n\")\n",
        "\n",
        "    def run_parallel_execution(self):\n",
        "        \"\"\"\n",
        "        Executes the entire taskset in parallel and measures:\n",
        "          - The overall parallel makespan,\n",
        "          - Each taskâ€™s sum-of-times approach,\n",
        "          - Each taskâ€™s finish time (relative to the parallel start).\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Starting Parallel Execution.\")\n",
        "\n",
        "        # Clear old parallel data\n",
        "        self.parallel_outputs.clear()\n",
        "        self.parallel_execution_times.clear()\n",
        "        self.parallel_completion_times.clear()\n",
        "\n",
        "        # Start measuring overall parallel makespan\n",
        "        parallel_start = time.time()\n",
        "\n",
        "        self.taskset.execute_all()\n",
        "\n",
        "        parallel_end = time.time()\n",
        "        self.parallel_makespan = parallel_end - parallel_start\n",
        "\n",
        "        # For each task, gather final outputs + per-task times\n",
        "        for task in self.taskset.tasks:\n",
        "            if task.output_data is not None:\n",
        "                self.parallel_outputs[task.task_id] = task.output_data.cpu()\n",
        "            else:\n",
        "                self.parallel_outputs[task.task_id] = None\n",
        "\n",
        "            # The sum-of-times approach is the existing code's â€œget_total_execution_timeâ€\n",
        "            exec_time = task.get_total_execution_time()\n",
        "            self.parallel_execution_times[task.task_id] = exec_time\n",
        "\n",
        "            # The finish_time is absolute. We want relative to parallel_start:\n",
        "            # (task.finish_time is set by the time the Task completed)\n",
        "            if task.finish_time is not None:\n",
        "                self.parallel_completion_times[task.task_id] = task.finish_time - parallel_start\n",
        "            else:\n",
        "                self.parallel_completion_times[task.task_id] = float('nan')\n",
        "\n",
        "        print(f\"[Evaluator] Parallel Execution Completed. Parallel makespan = {self.parallel_makespan:.6f} s\\n\")\n",
        "\n",
        "    def compare_outputs(self):\n",
        "        \"\"\"\n",
        "        Compares naive vs. parallel outputs for correctness.\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Comparing Outputs.\")\n",
        "        all_match = True\n",
        "\n",
        "        for task_id in self.naive_outputs:\n",
        "            naive_out = self.naive_outputs[task_id]\n",
        "            parallel_out = self.parallel_outputs.get(task_id, None)\n",
        "\n",
        "            if naive_out is None or parallel_out is None:\n",
        "                print(f\"[Evaluator] Task '{task_id}' missing output in one execution.\")\n",
        "                all_match = False\n",
        "                continue\n",
        "\n",
        "            # Ensure both are on CPU for a fair comparison\n",
        "            naive_out = naive_out.cpu()\n",
        "            parallel_out = parallel_out.cpu()\n",
        "\n",
        "            if torch.equal(naive_out, parallel_out):\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs match exactly.\")\n",
        "            elif torch.allclose(naive_out, parallel_out, atol=1e-5):\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs are close within tolerance.\")\n",
        "            else:\n",
        "                print(f\"[Evaluator] Task '{task_id}' outputs do NOT match.\")\n",
        "                all_match = False\n",
        "\n",
        "        if all_match:\n",
        "            print(\"[Evaluator] All outputs match.\\n\")\n",
        "        else:\n",
        "            print(\"[Evaluator] Some outputs differ.\\n\")\n",
        "\n",
        "    def analyze_speedup_throughput(self):\n",
        "        \"\"\"\n",
        "        Prints out:\n",
        "          1) The sum-of-times approach (the old logic),\n",
        "          2) The new makespan-based approach,\n",
        "          3) Each taskâ€™s naive vs. parallel completion time,\n",
        "          4) Speedup & throughput based on both approaches.\n",
        "        \"\"\"\n",
        "        print(\"[Evaluator] Analyzing Speedup and Throughput.\\n\")\n",
        "\n",
        "        #\n",
        "        # 1) Print sum-of-times approach (the original code).\n",
        "        #\n",
        "        total_naive_time = sum(self.naive_execution_times.values())\n",
        "        total_parallel_time = sum(self.parallel_execution_times.values())\n",
        "\n",
        "        print(f\"--- Sum-of-times approach ---\")\n",
        "        print(f\"[Evaluator] Naive total time (sum of per-task):    {total_naive_time:.6f} s\")\n",
        "        print(f\"[Evaluator] Parallel total time (sum of per-task): {total_parallel_time:.6f} s\")\n",
        "\n",
        "        sum_speedup = (\n",
        "            total_naive_time / total_parallel_time\n",
        "            if total_parallel_time > 0\n",
        "            else float('inf')\n",
        "        )\n",
        "        num_tasks = len(self.taskset.tasks)\n",
        "\n",
        "        # sum-of-times throughput\n",
        "        naive_thr_sum = num_tasks / total_naive_time if total_naive_time > 0 else 0\n",
        "        parallel_thr_sum = num_tasks / total_parallel_time if total_parallel_time > 0 else 0\n",
        "\n",
        "        print(f\"[Evaluator] Speedup (sum-of-times) = {sum_speedup:.2f}x\")\n",
        "        print(f\"[Evaluator] Naive Throughput (sum-of-times)   = {naive_thr_sum:.2f} tasks/s\")\n",
        "        print(f\"[Evaluator] Parallel Throughput (sum-of-times) = {parallel_thr_sum:.2f} tasks/s\\n\")\n",
        "\n",
        "        #\n",
        "        # 2) Print makespan-based approach.\n",
        "        #\n",
        "        print(f\"--- Makespan-based approach ---\")\n",
        "        print(f\"[Evaluator] Naive makespan:   {self.naive_makespan:.6f} s\")\n",
        "        print(f\"[Evaluator] Parallel makespan: {self.parallel_makespan:.6f} s\")\n",
        "\n",
        "        makespan_speedup = (\n",
        "            self.naive_makespan / self.parallel_makespan\n",
        "            if self.parallel_makespan > 0\n",
        "            else float('inf')\n",
        "        )\n",
        "\n",
        "        # makespan-based throughput\n",
        "        naive_thr_makespan = num_tasks / self.naive_makespan if self.naive_makespan > 0 else 0\n",
        "        parallel_thr_makespan = num_tasks / self.parallel_makespan if self.parallel_makespan > 0 else 0\n",
        "\n",
        "        print(f\"[Evaluator] Speedup (makespan-based) = {makespan_speedup:.2f}x\")\n",
        "        print(f\"[Evaluator] Naive Throughput (makespan)   = {naive_thr_makespan:.2f} tasks/s\")\n",
        "        print(f\"[Evaluator] Parallel Throughput (makespan) = {parallel_thr_makespan:.2f} tasks/s\\n\")\n",
        "\n",
        "        #\n",
        "        # 3) Print each taskâ€™s naive vs. parallel completion time\n",
        "        #\n",
        "        print(f\"--- Task Completion Times (relative to start) ---\")\n",
        "        for task_id in self.naive_completion_times:\n",
        "            naive_finish = self.naive_completion_times[task_id]\n",
        "            parallel_finish = self.parallel_completion_times.get(task_id, float('nan'))\n",
        "            print(f\" Task {task_id}: naive finish={naive_finish:.6f}s, parallel finish={parallel_finish:.6f}s\")\n",
        "\n",
        "        print()  # extra newline at end\n"
      ],
      "metadata": {
        "id": "fHc7mwv50DWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_script.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models\n",
        "import copy\n",
        "import time\n",
        "# from node import Node\n",
        "# from task import Task\n",
        "# from taskset import Taskset\n",
        "# from utils import group_topological_order, resolve_arg\n",
        "# from profiler import Profiler  # Assuming profiler.py contains the Profiler class\n",
        "# from evaluator import Evaluator  # Assuming evaluator.py contains the Evaluator class\n",
        "\n",
        "\n",
        "# Define a SimpleCNN with torch.cat in its forward pass\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(32 * 28 * 28, 10)  # Assuming input images are 28x28\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First path\n",
        "        x1 = self.conv1(x)\n",
        "        x1 = self.relu(x1)\n",
        "\n",
        "        # Second path\n",
        "        x2 = self.conv2(x)\n",
        "        x2 = self.relu(x2)\n",
        "\n",
        "        # Concatenate along the channel dimension\n",
        "        x = torch.cat((x1, x2), dim=1)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define a PretrainedResNet18 with modified final layer\n",
        "class PretrainedResNet18(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10):\n",
        "        \"\"\"\n",
        "        Initializes the ResNet18 model with a modified final layer.\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): Number of output classes.\n",
        "        \"\"\"\n",
        "        super(PretrainedResNet18, self).__init__()\n",
        "        self.resnet18 = models.resnet18(pretrained=True)\n",
        "        num_ftrs = self.resnet18.fc.in_features\n",
        "        self.resnet18.fc = nn.Linear(num_ftrs, num_classes)  # Modify for desired number of classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)\n",
        "\n",
        "\n",
        "def create_synthetic_dataloader(batch_size: int = 1, num_samples: int = 1, input_size=(3, 28, 28)):\n",
        "    \"\"\"\n",
        "    Creates a synthetic DataLoader for SimpleCNN with input size (3, 28, 28).\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): Number of samples per batch.\n",
        "        num_samples (int): Total number of samples.\n",
        "\n",
        "    Returns:\n",
        "        DataLoader: PyTorch DataLoader with synthetic data.\n",
        "    \"\"\"\n",
        "    inputs = torch.randn(num_samples, *input_size)\n",
        "    targets = torch.randint(0, 10, (num_samples,))\n",
        "    dataset = TensorDataset(inputs, targets)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def create_resnet_dataloader(batch_size: int = 1, num_samples: int = 1, input_size=(3, 224, 224)):\n",
        "    \"\"\"\n",
        "    Creates a synthetic DataLoader for ResNet18 with input size (3, 224, 224).\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): Number of samples per batch.\n",
        "        num_samples (int): Total number of samples.\n",
        "\n",
        "    Returns:\n",
        "        DataLoader: PyTorch DataLoader with synthetic data.\n",
        "    \"\"\"\n",
        "    inputs = torch.randn(num_samples, *input_size)\n",
        "    targets = torch.randint(0, 10, (num_samples,))  # ResNet18 typically has 1000 classes; adjust as needed\n",
        "    dataset = TensorDataset(inputs, targets)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def initialize_components():\n",
        "    \"\"\"\n",
        "    Initializes the compute nodes, profiler, tasks for SimpleCNN and ResNet18,\n",
        "    and assigns stages to nodes.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Taskset, Profiler, List[Node]]: Initialized Taskset, Profiler, and list of Nodes.\n",
        "    \"\"\"\n",
        "    nodes = Node.discover_nodes()\n",
        "    print(f\"[Main] Discovered Nodes: {nodes}\\n\")\n",
        "\n",
        "    profiler = Profiler(mode=\"init\")  # Initialize Profiler\n",
        "    print(\"[Main] Initialized Profiler.\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    # Create SimpleCNN Tasks\n",
        "    num_simple_cnn_tasks = 1  # Adjust the number as needed\n",
        "    simple_cnn_tasks = []\n",
        "    for i in range(num_simple_cnn_tasks):\n",
        "        model = SimpleCNN()\n",
        "        dl = create_synthetic_dataloader(batch_size=10, num_samples=100, input_size=(3, 28, 28))\n",
        "        single_input_cnn, _ = next(iter(dl))\n",
        "        task = Task(\n",
        "            task_id=f\"simple_cnn_task{i+1}\",\n",
        "            model=model,\n",
        "            input_data=single_input_cnn,\n",
        "            model_name=model.__class__.__name__,\n",
        "            profiler=profiler\n",
        "        )\n",
        "        simple_cnn_tasks.append(task)\n",
        "    print(f\"[Main] Created {num_simple_cnn_tasks} SimpleCNN Tasks.\\n\")\n",
        "\n",
        "    # Create ResNet18 Tasks\n",
        "    num_resnet_tasks = 1  # Adjust the number as needed\n",
        "    resnet_tasks = []\n",
        "    for i in range(num_resnet_tasks):\n",
        "        model = PretrainedResNet18(num_classes=10)\n",
        "        dl = create_resnet_dataloader(batch_size=10, num_samples=100, input_size=(3, 224, 224))\n",
        "        single_input_resnet, _ = next(iter(dl))\n",
        "        task = Task(\n",
        "            task_id=f\"resnet_task{i+1}\",\n",
        "            model=model,\n",
        "            input_data=single_input_resnet,\n",
        "            model_name=model.__class__.__name__,\n",
        "            profiler=profiler\n",
        "        )\n",
        "        resnet_tasks.append(task)\n",
        "    print(f\"[Main] Created {num_resnet_tasks} ResNet18 Tasks.\\n\")\n",
        "\n",
        "    # Combine all tasks into a single list\n",
        "    all_tasks = simple_cnn_tasks + resnet_tasks\n",
        "    print(\"[Main] Initialized Taskset with SimpleCNN and ResNet18 tasks.\\n\")\n",
        "\n",
        "    # Initialize profiler by profiling each stage automatically\n",
        "    # Note: Uncomment and modify as needed based on your Profiler implementation\n",
        "    # 1) Profile each task on each node\n",
        "    for task in all_tasks:\n",
        "        for node_curr in nodes:\n",
        "            input_copy = copy.deepcopy(task.input_data)\n",
        "            profiler.profile_model(\n",
        "                model=task.model,\n",
        "                input_data=input_copy,\n",
        "                node_id=node_curr.node_id,\n",
        "                task_id=task.task_id,\n",
        "            )\n",
        "\n",
        "    # 2) Now that profiling is done, retrieve the final DataFrame\n",
        "    profile_db = profiler.get_profile_db()\n",
        "\n",
        "    # for task.\n",
        "\n",
        "\n",
        "    # 3) For each task, filter out its profiler rows, build forward_pass aggregates if desired,\n",
        "    #    then call init_profiling_data\n",
        "    # for task in all_tasks:\n",
        "    #     # Gather all rows in 'profile_db' that match this Task's ID\n",
        "    #     task_rows = profile_db[profile_db['Task_ID'] == task.task_id]\n",
        "\n",
        "    #     if task_rows.empty:\n",
        "    #         # No rows found for this task (unusual), skip or log warning\n",
        "    #         print(f\"No profiler rows found for Task '{task.task_id}'\")\n",
        "    #         continue\n",
        "\n",
        "    #     # Convert these rows into a list-of-dicts for easy consumption\n",
        "    #     records_for_task = task_rows.to_dict(orient='records')\n",
        "\n",
        "    #     # (Optional) Build a forward_pass dictionary if you want aggregated metrics:\n",
        "    #     # e.g. get row(s) where Layer == 'forward_pass'\n",
        "    #     forward_pass_data = task_rows[task_rows['Layer'] == 'forward_pass']\n",
        "    #     if not forward_pass_data.empty:\n",
        "    #         # Example: take max of 'CPU Total (us)' for forward_pass across all devices\n",
        "    #         total_cpu_time = forward_pass_data['CPU Total (us)'].max()\n",
        "    #         forward_pass_agg = {\n",
        "    #             \"max_forward_cpu_time_us\": total_cpu_time,\n",
        "    #             # Add other aggregates as you see fit\n",
        "    #         }\n",
        "    #     else:\n",
        "    #         forward_pass_agg = {}\n",
        "\n",
        "    #     # 4) Call init_profiling_data on the Task\n",
        "    #     task.init_profiling_data(\n",
        "    #         profiling_records=records_for_task,\n",
        "    #         forward_pass_agg=forward_pass_agg\n",
        "    #     )\n",
        "\n",
        "    # # 5) Finally, you can print the profile database if you wish\n",
        "    profiler.print_profile_db()\n",
        "\n",
        "    for task in all_tasks:\n",
        "        # task.print_stage_allocations()\n",
        "        # print(\"Is the model in training mode?\", task.model.training)\n",
        "        # print(task.parsed_layer_data)\n",
        "        print(\"\\n\")\n",
        "        print(task.prof_records)\n",
        "        # print()\n",
        "\n",
        "    # taskset = Taskset(tasks=all_tasks, available_nodes=nodes)\n",
        "    # load_metric = HPCUtilizationMetric(slack_fraction=0.2)\n",
        "    taskset = Taskset(tasks=all_tasks, available_nodes=nodes)\n",
        "    print(\"[Main] Initialized Taskset.\\n\")\n",
        "\n",
        "    return taskset, profiler, nodes\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    \"\"\"\n",
        "    Sets the seed for Python, NumPy, and PyTorch to ensure reproducibility.\n",
        "\n",
        "    Args:\n",
        "        seed (int): The seed value to use. Default is 42.\n",
        "    \"\"\"\n",
        "    import random\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # For CUDA\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU.\n",
        "\n",
        "    # Ensure deterministic behavior in CuDNN\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"[Utils] Seed set to {seed} for Python, NumPy, and PyTorch.\")\n",
        "\n",
        "\n",
        "def run_evaluation():\n",
        "    taskset, profiler, nodes = initialize_components()\n",
        "\n",
        "    # compute_loads\n",
        "    taskset.compute_loads()\n",
        "\n",
        "    set_seed(42)\n",
        "    print(\"[Main] Seed set to 42 for reproducibility.\\n\")\n",
        "\n",
        "    # Execute tasks in parallel\n",
        "    # print(\"[Main] Starting Parallel Execution of Taskset.\\n\")\n",
        "    # taskset.execute_all()\n",
        "\n",
        "    # for task in taskset.tasks:\n",
        "    #     task.print_stage_allocations()\n",
        "    #     # print(task.prof_records.keys())\n",
        "    #     print(\"Is the model in training mode?\", task.model.training)\n",
        "    # # Initialize evaluator\n",
        "    # evaluator = Evaluator(taskset=taskset, profiler=profiler)\n",
        "\n",
        "    # # Run Naive Execution\n",
        "    # evaluator.run_naive_execution()\n",
        "\n",
        "    # print(\"=== Performance Metrics ===\")\n",
        "    # print(taskset)\n",
        "    # print(\"===========================\")\n",
        "\n",
        "    # # Run Parallel Execution\n",
        "    # evaluator.run_parallel_execution()\n",
        "\n",
        "    # # Compare Outputs\n",
        "    # evaluator.compare_outputs()\n",
        "\n",
        "    # # Analyze Speedup and Throughput\n",
        "    # evaluator.analyze_speedup_throughput()\n",
        "\n",
        "    # # Print final metrics\n",
        "    # print(\"=== Final Performance Metrics ===\")\n",
        "    # print(taskset)\n",
        "    # print(\"==================================\")\n",
        "\n",
        "    # # Shutdown nodes\n",
        "    # print(\"[Main] Shutting down all Nodes.\")\n",
        "    # for node in nodes:\n",
        "    #     node.stop()\n",
        "    # print(\"[Main] All Nodes have been shut down.\")\n",
        "\n",
        "    # for task in taskset.tasks:\n",
        "    #   # task.print_stage_allocations()\n",
        "    #   print(task.task_id)\n",
        "    #   print()\n",
        "    #   print(task.prof_records)\n",
        "    #   # print(task.loads)\n",
        "    #   print()\n",
        "    #   print(\"Is the model in training mode?\", task.model.training)\n",
        "\n",
        "    # print(taskset.loads)\n",
        "    # print(taskset.tasks[1].loads\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_evaluation()\n"
      ],
      "metadata": {
        "id": "L5k7DDyI-2F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687b8e77-88db-448b-f146-8402360178e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[discover_nodes] Generated DISJOINT nodes: leftover CPU-only plus GPU+CPU with unique cores.\n",
            "[Main] Discovered Nodes: [Node(CPU-0, cpus=(0,), gpu=None), Node(CPU-1, cpus=(1,), gpu=None)]\n",
            "\n",
            "[Main] Initialized Profiler.\n",
            "\n",
            "[Main] Created 1 SimpleCNN Tasks.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Main] Created 1 ResNet18 Tasks.\n",
            "\n",
            "[Main] Initialized Taskset with SimpleCNN and ResNet18 tasks.\n",
            "\n",
            "Starting profiling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py:263: UserWarning: CUDA is not available, disabling CUDA profiling\n",
            "  warn(\"CUDA is not available, disabling CUDA profiling\")\n",
            "<ipython-input-5-2e0f5d2bab44>:318: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py:263: UserWarning: CUDA is not available, disabling CUDA profiling\n",
            "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling complete. Data saved to profiling_results.csv\n",
            "Starting profiling...\n",
            "Profiling complete. Data saved to profiling_results.csv\n",
            "Starting profiling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py:263: UserWarning: CUDA is not available, disabling CUDA profiling\n",
            "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling complete. Data saved to profiling_results.csv\n",
            "Starting profiling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py:263: UserWarning: CUDA is not available, disabling CUDA profiling\n",
            "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling complete. Data saved to profiling_results.csv\n",
            "ProfileDB:\n",
            "         Task_ID              Model                          Layer Compute  Self CPU (us)  CPU Total (us)  CUDA Total (us) Self CPU Mem (bytes) Self CUDA Mem (bytes)  Total Execution Time (us) Total Memory Used (bytes)\n",
            "simple_cnn_task1          SimpleCNN                   forward_pass   CPU-0       5187.730       23445.961              0.0             -9032480                     0                  23445.961                  -9032480\n",
            "simple_cnn_task1          SimpleCNN                          conv1   CPU-0       3079.728        8682.799              0.0                    0                     0                   8682.799                         0\n",
            "simple_cnn_task1          SimpleCNN                         relu_1   CPU-0        375.149        3411.435              0.0                    0                     0                   3411.435                         0\n",
            "simple_cnn_task1          SimpleCNN                           relu   CPU-0        517.010        3036.286              0.0                    0                     0                   3036.286                         0\n",
            "simple_cnn_task1          SimpleCNN                       [memory]   CPU-0          0.000           0.000              0.0             -9032480                     0                      0.000                  -9032480\n",
            "simple_cnn_task1          SimpleCNN                          conv2   CPU-0        346.753        2607.586              0.0                    0                     0                   2607.586                         0\n",
            "simple_cnn_task1          SimpleCNN                            cat   CPU-0        270.550         850.961              0.0                    0                     0                    850.961                         0\n",
            "simple_cnn_task1          SimpleCNN                        flatten   CPU-0        202.472         951.949              0.0                    0                     0                    951.949                         0\n",
            "simple_cnn_task1          SimpleCNN                             fc   CPU-0        268.048        3776.925              0.0                    0                     0                   3776.925                         0\n",
            "simple_cnn_task1          SimpleCNN                  ProfilerStep*   CPU-0        128.020         128.020              0.0                    0                     0                    128.020                         0\n",
            "simple_cnn_task1          SimpleCNN                   forward_pass   CPU-1       6980.482       20559.000              0.0             -8028560                     0                  20559.000                  -8028560\n",
            "simple_cnn_task1          SimpleCNN                          conv1   CPU-1        799.926        2636.714              0.0                    0                     0                   2636.714                         0\n",
            "simple_cnn_task1          SimpleCNN                         relu_1   CPU-1        576.740        2663.254              0.0                    0                     0                   2663.254                         0\n",
            "simple_cnn_task1          SimpleCNN                           relu   CPU-1       1304.919        2086.514              0.0                    0                     0                   2086.514                         0\n",
            "simple_cnn_task1          SimpleCNN                       [memory]   CPU-1          0.000           0.000              0.0             -5519760                     0                      0.000                  -5519760\n",
            "simple_cnn_task1          SimpleCNN                          conv2   CPU-1       1152.211        3793.345              0.0                    0                     0                   3793.345                         0\n",
            "simple_cnn_task1          SimpleCNN                            cat   CPU-1        298.114        1858.395              0.0                    0                     0                   1858.395                         0\n",
            "simple_cnn_task1          SimpleCNN                        flatten   CPU-1        215.649         268.596              0.0                    0                     0                    268.596                         0\n",
            "simple_cnn_task1          SimpleCNN                             fc   CPU-1       1089.594        3860.738              0.0                    0                     0                   3860.738                         0\n",
            "simple_cnn_task1          SimpleCNN                  ProfilerStep*   CPU-1       1543.329        3391.444              0.0             -2508800                     0                   3391.444                  -2508800\n",
            "    resnet_task1 PretrainedResNet18                   forward_pass   CPU-0     152660.151     5791044.137              0.0           -738501408                     0                5791044.137                -738501408\n",
            "    resnet_task1 PretrainedResNet18                 resnet18_conv1   CPU-0        756.716      218000.829              0.0                    0                     0                 218000.829                         0\n",
            "    resnet_task1 PretrainedResNet18                   resnet18_bn1   CPU-0        958.820       36890.021              0.0                    0                     0                  36890.021                         0\n",
            "    resnet_task1 PretrainedResNet18                       [memory]   CPU-0          0.000           0.000              0.0           -475669280                     0                      0.000                -475669280\n",
            "    resnet_task1 PretrainedResNet18                  resnet18_relu   CPU-0        684.964       10939.355              0.0                    0                     0                  10939.355                         0\n",
            "    resnet_task1 PretrainedResNet18               resnet18_maxpool   CPU-0        875.502      384162.839              0.0                    0                     0                 384162.839                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_0_conv1   CPU-0        869.519      168141.958              0.0                    0                     0                 168141.958                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_0_bn1   CPU-0        733.976        5816.352              0.0                    0                     0                   5816.352                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer1_0_relu_1   CPU-0        701.222        6876.792              0.0                    0                     0                   6876.792                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer1_0_relu   CPU-0       1030.981        6175.570              0.0                    0                     0                   6175.570                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_0_conv2   CPU-0        791.380      176939.316              0.0                    0                     0                 176939.316                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_0_bn2   CPU-0        747.417        5763.218              0.0                    0                     0                   5763.218                         0\n",
            "    resnet_task1 PretrainedResNet18                            add   CPU-0        621.570        8621.346              0.0                    0                     0                   8621.346                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_1_conv1   CPU-0        841.853      215144.706              0.0                    0                     0                 215144.706                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_1_bn1   CPU-0        812.030        6196.474              0.0                    0                     0                   6196.474                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer1_1_relu_1   CPU-0        964.726        7009.187              0.0                    0                     0                   7009.187                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer1_1_relu   CPU-0       1020.345        6044.461              0.0                    0                     0                   6044.461                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_1_conv2   CPU-0        805.067      189687.200              0.0                    0                     0                 189687.200                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_1_bn2   CPU-0        784.597        6267.356              0.0                    0                     0                   6267.356                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_1   CPU-0        611.606        7181.279              0.0                    0                     0                   7181.279                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_0_conv1   CPU-0        872.438      118073.734              0.0                    0                     0                 118073.734                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_0_bn1   CPU-0        726.881        3393.411              0.0                    0                     0                   3393.411                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer2_0_relu_1   CPU-0        645.574        3655.198              0.0                    0                     0                   3655.198                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer2_0_relu   CPU-0        849.373        3009.624              0.0                    0                     0                   3009.624                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_0_conv2   CPU-0        781.065      201619.205              0.0                    0                     0                 201619.205                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_0_bn2   CPU-0        763.938        3760.122              0.0                    0                     0                   3760.122                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer2_0_downsample_0   CPU-0        766.978       21214.187              0.0                    0                     0                  21214.187                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer2_0_downsample_1   CPU-0        666.084        3023.686              0.0                    0                     0                   3023.686                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_2   CPU-0        462.946        3166.910              0.0                    0                     0                   3166.910                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_1_conv1   CPU-0       1017.393      206990.511              0.0                    0                     0                 206990.511                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_1_bn1   CPU-0       4965.751        7651.170              0.0                    0                     0                   7651.170                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer2_1_relu_1   CPU-0        618.758        4978.294              0.0                    0                     0                   4978.294                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer2_1_relu   CPU-0       2328.917        4359.536              0.0                    0                     0                   4359.536                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_1_conv2   CPU-0        782.737      193934.807              0.0                    0                     0                 193934.807                         0\n",
            "    resnet_task1 PretrainedResNet18                  ProfilerStep*   CPU-0      95137.746     1873058.189              0.0           -262832128                     0                1873058.189                -262832128\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_1_bn2   CPU-0        722.880        3556.863              0.0                    0                     0                   3556.863                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_3   CPU-0        512.905        3362.272              0.0                    0                     0                   3362.272                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_0_conv1   CPU-0        834.836      108557.552              0.0                    0                     0                 108557.552                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_0_bn1   CPU-0        735.692        2363.345              0.0                    0                     0                   2363.345                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer3_0_relu_1   CPU-0        632.526        2672.595              0.0                    0                     0                   2672.595                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer3_0_relu   CPU-0        769.608        2040.069              0.0                    0                     0                   2040.069                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_0_conv2   CPU-0        821.618      213859.714              0.0                    0                     0                 213859.714                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_0_bn2   CPU-0       1016.249        2801.104              0.0                    0                     0                   2801.104                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer3_0_downsample_0   CPU-0       2032.441       24313.517              0.0                    0                     0                  24313.517                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer3_0_downsample_1   CPU-0        785.856        2453.869              0.0                    0                     0                   2453.869                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_4   CPU-0        473.575        1925.368              0.0                    0                     0                   1925.368                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_1_conv1   CPU-0        810.977      232813.549              0.0                    0                     0                 232813.549                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_1_bn1   CPU-0        738.825        2727.328              0.0                    0                     0                   2727.328                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer3_1_relu_1   CPU-0        617.827        2463.545              0.0                    0                     0                   2463.545                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer3_1_relu   CPU-0        834.179        1845.718              0.0                    0                     0                   1845.718                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_1_conv2   CPU-0        786.066      206831.328              0.0                    0                     0                 206831.328                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_1_bn2   CPU-0        687.797        2433.001              0.0                    0                     0                   2433.001                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_5   CPU-0        462.094        1999.910              0.0                    0                     0                   1999.910                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_0_conv1   CPU-0        865.336      135425.396              0.0                    0                     0                 135425.396                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_0_bn1   CPU-0        693.122        1887.393              0.0                    0                     0                   1887.393                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer4_0_relu_1   CPU-0        601.799        2069.221              0.0                    0                     0                   2069.221                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer4_0_relu   CPU-0        776.947        1467.422              0.0                    0                     0                   1467.422                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_0_conv2   CPU-0        911.345      218617.131              0.0                    0                     0                 218617.131                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_0_bn2   CPU-0        716.956        1977.239              0.0                    0                     0                   1977.239                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer4_0_downsample_0   CPU-0        651.981       15357.634              0.0                    0                     0                  15357.634                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer4_0_downsample_1   CPU-0        692.177        1860.768              0.0                    0                     0                   1860.768                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_6   CPU-0        411.869        1062.308              0.0                    0                     0                   1062.308                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_1_conv1   CPU-0        847.142      219568.525              0.0                    0                     0                 219568.525                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_1_bn1   CPU-0        687.715        1845.817              0.0                    0                     0                   1845.817                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer4_1_relu_1   CPU-0        570.668        1887.671              0.0                    0                     0                   1887.671                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer4_1_relu   CPU-0        721.516        1317.003              0.0                    0                     0                   1317.003                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_1_conv2   CPU-0        874.673      241235.187              0.0                    0                     0                 241235.187                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_1_bn2   CPU-0        717.655        1904.709              0.0                    0                     0                   1904.709                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_7   CPU-0        393.990        1120.111              0.0                    0                     0                   1120.111                         0\n",
            "    resnet_task1 PretrainedResNet18               resnet18_avgpool   CPU-0        524.963        4324.639              0.0                    0                     0                   4324.639                         0\n",
            "    resnet_task1 PretrainedResNet18                        flatten   CPU-0        332.421         441.468              0.0                    0                     0                    441.468                         0\n",
            "    resnet_task1 PretrainedResNet18                    resnet18_fc   CPU-0        393.055         907.005              0.0                    0                     0                    907.005                         0\n",
            "    resnet_task1 PretrainedResNet18                   forward_pass   CPU-1     159511.478     5947462.995              0.0           -743105312                     0                5947462.995                -743105312\n",
            "    resnet_task1 PretrainedResNet18                 resnet18_conv1   CPU-1        845.743      270220.612              0.0                    0                     0                 270220.612                         0\n",
            "    resnet_task1 PretrainedResNet18                   resnet18_bn1   CPU-1       1012.124       47459.153              0.0                    0                     0                  47459.153                         0\n",
            "    resnet_task1 PretrainedResNet18                       [memory]   CPU-1          0.000           0.000              0.0           -467641120                     0                      0.000                -467641120\n",
            "    resnet_task1 PretrainedResNet18                  resnet18_relu   CPU-1        900.846       12351.755              0.0                    0                     0                  12351.755                         0\n",
            "    resnet_task1 PretrainedResNet18               resnet18_maxpool   CPU-1        930.423      407898.603              0.0                    0                     0                 407898.603                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_0_conv1   CPU-1        958.601      200266.753              0.0                    0                     0                 200266.753                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_0_bn1   CPU-1        776.581        6121.575              0.0                    0                     0                   6121.575                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer1_0_relu_1   CPU-1        651.304        6258.354              0.0                    0                     0                   6258.354                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer1_0_relu   CPU-1        955.863        5607.050              0.0                    0                     0                   5607.050                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_0_conv2   CPU-1        864.998      211783.119              0.0                    0                     0                 211783.119                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_0_bn2   CPU-1        809.714        6216.418              0.0                    0                     0                   6216.418                         0\n",
            "    resnet_task1 PretrainedResNet18                            add   CPU-1        621.892        7101.559              0.0                    0                     0                   7101.559                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_1_conv1   CPU-1        827.393      183939.951              0.0                    0                     0                 183939.951                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_1_bn1   CPU-1        732.646        5782.064              0.0                    0                     0                   5782.064                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer1_1_relu_1   CPU-1        561.796        5658.092              0.0                    0                     0                   5658.092                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer1_1_relu   CPU-1        910.569        5096.296              0.0                    0                     0                   5096.296                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer1_1_conv2   CPU-1        757.813      163030.650              0.0                    0                     0                 163030.650                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer1_1_bn2   CPU-1        707.179        5612.109              0.0                    0                     0                   5612.109                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_1   CPU-1        588.885        6458.273              0.0                    0                     0                   6458.273                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_0_conv1   CPU-1        771.630       98863.691              0.0                    0                     0                  98863.691                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_0_bn1   CPU-1        710.405        3200.411              0.0                    0                     0                   3200.411                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer2_0_relu_1   CPU-1        536.600        2995.859              0.0                    0                     0                   2995.859                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer2_0_relu   CPU-1        735.397        2459.259              0.0                    0                     0                   2459.259                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_0_conv2   CPU-1        816.233      168360.870              0.0                    0                     0                 168360.870                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_0_bn2   CPU-1        722.927        3266.532              0.0                    0                     0                   3266.532                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer2_0_downsample_0   CPU-1        686.436       20721.062              0.0                    0                     0                  20721.062                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer2_0_downsample_1   CPU-1        627.078        3098.900              0.0                    0                     0                   3098.900                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_2   CPU-1        441.814        2901.966              0.0                    0                     0                   2901.966                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_1_conv1   CPU-1        837.534      199544.464              0.0                    0                     0                 199544.464                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_1_bn1   CPU-1        731.520        3429.421              0.0                    0                     0                   3429.421                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer2_1_relu_1   CPU-1        635.711        3367.249              0.0                    0                     0                   3367.249                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer2_1_relu   CPU-1        848.919        2731.538              0.0                    0                     0                   2731.538                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer2_1_conv2   CPU-1        865.520      218553.991              0.0                    0                     0                 218553.991                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer2_1_bn2   CPU-1        737.120        3968.545              0.0                    0                     0                   3968.545                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_3   CPU-1        541.458        3322.722              0.0                    0                     0                   3322.722                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_0_conv1   CPU-1        837.631      106900.700              0.0                    0                     0                 106900.700                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_0_bn1   CPU-1        691.650        2169.675              0.0                    0                     0                   2169.675                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer3_0_relu_1   CPU-1        636.424        2473.849              0.0                    0                     0                   2473.849                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer3_0_relu   CPU-1        756.249        1837.425              0.0                    0                     0                   1837.425                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_0_conv2   CPU-1        806.992      196026.805              0.0                    0                     0                 196026.805                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_0_bn2   CPU-1        719.239        2337.222              0.0                    0                     0                   2337.222                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer3_0_downsample_0   CPU-1        581.890       14591.633              0.0                    0                     0                  14591.633                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer3_0_downsample_1   CPU-1        560.850        1871.228              0.0                    0                     0                   1871.228                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_4   CPU-1        404.129        1966.520              0.0                    0                     0                   1966.520                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_1_conv1   CPU-1        798.776      203682.001              0.0                    0                     0                 203682.001                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_1_bn1   CPU-1        713.470        2314.290              0.0                    0                     0                   2314.290                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer3_1_relu_1   CPU-1        559.818        2316.348              0.0                    0                     0                   2316.348                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer3_1_relu   CPU-1        772.491        1756.530              0.0                    0                     0                   1756.530                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer3_1_conv2   CPU-1        934.727      254019.063              0.0                    0                     0                 254019.063                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer3_1_bn2   CPU-1        719.713        2451.793              0.0                    0                     0                   2451.793                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_5   CPU-1        406.537        1711.610              0.0                    0                     0                   1711.610                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_0_conv1   CPU-1       3003.752      172352.578              0.0                    0                     0                 172352.578                         0\n",
            "    resnet_task1 PretrainedResNet18                  ProfilerStep*   CPU-1     107737.090     1943541.525              0.0           -275464192                     0                1943541.525                -275464192\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_0_bn1   CPU-1       1392.530        2885.266              0.0                    0                     0                   2885.266                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer4_0_relu_1   CPU-1        632.751        2114.196              0.0                    0                     0                   2114.196                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer4_0_relu   CPU-1        780.779        1481.445              0.0                    0                     0                   1481.445                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_0_conv2   CPU-1        866.943      250505.408              0.0                    0                     0                 250505.408                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_0_bn2   CPU-1        678.070        1732.962              0.0                    0                     0                   1732.962                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer4_0_downsample_0   CPU-1        584.853       14508.949              0.0                    0                     0                  14508.949                         0\n",
            "    resnet_task1 PretrainedResNet18 resnet18_layer4_0_downsample_1   CPU-1        587.262        1691.279              0.0                    0                     0                   1691.279                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_6   CPU-1        396.635        1073.056              0.0                    0                     0                   1073.056                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_1_conv1   CPU-1        911.493      219984.214              0.0                    0                     0                 219984.214                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_1_bn1   CPU-1        732.354        1959.996              0.0                    0                     0                   1959.996                         0\n",
            "    resnet_task1 PretrainedResNet18       resnet18_layer4_1_relu_1   CPU-1        605.938        1928.215              0.0                    0                     0                   1928.215                         0\n",
            "    resnet_task1 PretrainedResNet18         resnet18_layer4_1_relu   CPU-1        778.235        1322.277              0.0                    0                     0                   1322.277                         0\n",
            "    resnet_task1 PretrainedResNet18        resnet18_layer4_1_conv2   CPU-1        860.775      228490.160              0.0                    0                     0                 228490.160                         0\n",
            "    resnet_task1 PretrainedResNet18          resnet18_layer4_1_bn2   CPU-1        706.293        1893.057              0.0                    0                     0                   1893.057                         0\n",
            "    resnet_task1 PretrainedResNet18                          add_7   CPU-1        425.000        1153.033              0.0                    0                     0                   1153.033                         0\n",
            "    resnet_task1 PretrainedResNet18               resnet18_avgpool   CPU-1        562.650        1483.714              0.0                    0                     0                   1483.714                         0\n",
            "    resnet_task1 PretrainedResNet18                        flatten   CPU-1        306.376         374.258              0.0                    0                     0                    374.258                         0\n",
            "    resnet_task1 PretrainedResNet18                    resnet18_fc   CPU-1        400.441         911.849              0.0                    0                     0                    911.849                         0\n",
            "\n",
            "\n",
            "{}\n",
            "\n",
            "\n",
            "{}\n",
            "[Main] Initialized Taskset.\n",
            "\n",
            "0.0\n",
            "0.0\n",
            "[Utils] Seed set to 42 for Python, NumPy, and PyTorch.\n",
            "[Main] Seed set to 42 for reproducibility.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "chHMAKh5XB57"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}