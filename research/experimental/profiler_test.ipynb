{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.profiler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define an extended Feedforward Neural Network (FFN) with more layers\n",
    "class ExtendedFFN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_hidden_layers=4):\n",
    "        super(ExtendedFFN, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_hidden_layers)])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Apply hidden layers with ReLU activations\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = hidden_layer(x)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Define a Convolutional Neural Network (CNN)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)           # Convolution Layer 1\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)           # Pooling Layer 1\n",
    "        x = self.conv2(x)           # Convolution Layer 2\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)           # Pooling Layer 2\n",
    "        x = self.flatten(x)         # Flatten\n",
    "        x = self.fc1(x)             # Fully Connected Layer 1\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)         # Dropout for regularization\n",
    "        x = self.fc2(x)             # Fully Connected Layer 2\n",
    "        return x\n",
    "\n",
    "# Function to select the correct data based on the model type (FFN or CNN)\n",
    "def get_data_for_model(model_type):\n",
    "    if model_type == 'FFN':\n",
    "        # Data for FFN\n",
    "        input_size = 100\n",
    "        batch_size = 64\n",
    "        inputs = torch.randn(batch_size, input_size)\n",
    "        targets = torch.randint(0, 10, (batch_size,))\n",
    "        return inputs, targets, batch_size\n",
    "    elif model_type == 'CNN':\n",
    "        # Data for CNN\n",
    "        input_shape = (64, 1, 28, 28)  # Example input size (like MNIST)\n",
    "        inputs = torch.randn(input_shape)\n",
    "        targets = torch.randint(0, 10, (64,))\n",
    "        return inputs, targets, 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to wrap forward methods of each layer\n",
    "def wrap_forward_methods(model):\n",
    "    for idx, (name, module) in enumerate(model.named_modules()):\n",
    "        # Avoid wrapping the model itself\n",
    "        if module != model:\n",
    "            original_forward = module.forward\n",
    "            layer_name = f\"{name}_{idx}\"  # Include numbering for uniqueness\n",
    "\n",
    "            def wrapped_forward(*inputs, original_forward=original_forward, layer_name=layer_name, **kwargs):\n",
    "                with torch.profiler.record_function(layer_name):\n",
    "                    return original_forward(*inputs, **kwargs)\n",
    "\n",
    "            module.forward = wrapped_forward\n",
    "\n",
    "# Function to profile the model layer by layer\n",
    "def profile_model_layer_by_layer(model, device, dataloader):\n",
    "    model.to(device)\n",
    "    wrap_forward_methods(model)\n",
    "\n",
    "    # Warm-up\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            model(inputs)\n",
    "            break  # Only need one batch for warm-up\n",
    "\n",
    "    # Set up the profiler\n",
    "    with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        record_shapes=False,\n",
    "        profile_memory=True\n",
    "    ) as profiler:\n",
    "        # Run one forward pass\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in dataloader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                model(inputs)\n",
    "                break  # Only need one batch\n",
    "\n",
    "    # Process the profiler events\n",
    "    process_profiler_events(profiler)\n",
    "\n",
    "# Function to process profiler events and print per-layer metrics\n",
    "def process_profiler_events(profiler):\n",
    "    # Prepare header\n",
    "    print(f\"{'Layer Name':<40} {'CPU Total (us)':<15} {'CUDA Total (us)':<15} {'CPU Mem (bytes)':<15} {'CUDA Mem (bytes)':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    # Aggregate stats per layer\n",
    "    aggregated_stats = {}\n",
    "\n",
    "    for event in profiler.events():\n",
    "        # Only consider events that we recorded with record_function (i.e., our layers)\n",
    "        if event.name.startswith(\"enumerate(DataLoader\"):\n",
    "            continue  # Skip DataLoader events\n",
    "        if event.name in aggregated_stats:\n",
    "            # Aggregate stats\n",
    "            aggregated_stats[event.name]['cpu_time_total'] += event.cpu_time_total\n",
    "            aggregated_stats[event.name]['cuda_time_total'] += event.cuda_time_total\n",
    "            aggregated_stats[event.name]['cpu_memory_usage'] += event.cpu_memory_usage\n",
    "            aggregated_stats[event.name]['cuda_memory_usage'] += event.cuda_memory_usage\n",
    "        else:\n",
    "            aggregated_stats[event.name] = {\n",
    "                'cpu_time_total': event.cpu_time_total,\n",
    "                'cuda_time_total': event.cuda_time_total,\n",
    "                'cpu_memory_usage': event.cpu_memory_usage,\n",
    "                'cuda_memory_usage': event.cuda_memory_usage\n",
    "            }\n",
    "\n",
    "    # Print the aggregated stats\n",
    "    total_cpu_time = 0\n",
    "    total_cuda_time = 0\n",
    "    total_cpu_mem = 0\n",
    "    total_cuda_mem = 0\n",
    "\n",
    "    for layer_name, stats in aggregated_stats.items():\n",
    "        total_cpu_time += stats['cpu_time_total']\n",
    "        total_cuda_time += stats['cuda_time_total']\n",
    "        total_cpu_mem += stats['cpu_memory_usage']\n",
    "        total_cuda_mem += stats['cuda_memory_usage']\n",
    "        print(f\"{layer_name:<40} {stats['cpu_time_total']:<15.2f} {stats['cuda_time_total']:<15.2f} {stats['cpu_memory_usage']:<15} {stats['cuda_memory_usage']:<15}\")\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Total':<40} {total_cpu_time:<15.2f} {total_cuda_time:<15.2f} {total_cpu_mem:<15} {total_cuda_mem:<15}\")\n",
    "    print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     for model_type in ['FFN', 'CNN']:\n",
    "#         print(f\"Profiling {model_type} layer by layer...\")\n",
    "#         # Get the model and data\n",
    "#         if model_type == 'FFN':\n",
    "#             model = ExtendedFFN(input_size=100, hidden_size=50, output_size=10, num_hidden_layers=4)\n",
    "#         else:\n",
    "#             model = CNN()\n",
    "\n",
    "#         inputs, targets, batch_size = get_data_for_model(model_type)\n",
    "#         dataset = TensorDataset(inputs, targets)\n",
    "#         dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "#         # Profile on CPU\n",
    "#         profile_model_layer_by_layer(model, device='cpu', dataloader=dataloader)\n",
    "\n",
    "#         # Profile on GPU if available\n",
    "#         if torch.cuda.is_available():\n",
    "#             print(f\"Profiling {model_type} layer by layer on GPU...\")\n",
    "#             profile_model_layer_by_layer(model, device='cuda', dataloader=dataloader)\n",
    "#         else:\n",
    "#             print(f\"CUDA is not available for {model_type}.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Function to profile the whole model\n",
    "def profile_whole_model(model, device, dataloader):\n",
    "    model.to(device)\n",
    "\n",
    "    # Warm-up\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            model(inputs)\n",
    "            break  # Only need one batch for warm-up\n",
    "\n",
    "    # Time the forward pass using time module\n",
    "    with torch.no_grad():\n",
    "        start_time = time.perf_counter()\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            break  # Only need one batch\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        end_time = time.perf_counter()\n",
    "        total_wall_time = (end_time - start_time) * 1e6  # Convert to microseconds\n",
    "\n",
    "    print(f\"Wall-clock time for the forward pass: {total_wall_time:.2f} us\")\n",
    "\n",
    "    # Set up the profiler\n",
    "    with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        record_shapes=False,\n",
    "        profile_memory=True\n",
    "    ) as profiler:\n",
    "        # Run one forward pass\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in dataloader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                model(inputs)\n",
    "                break  # Only need one batch\n",
    "\n",
    "    # Process the profiler events\n",
    "    process_whole_model_profiler_events(profiler, total_wall_time)\n",
    "\n",
    "# Function to process profiler events for the whole model\n",
    "def process_whole_model_profiler_events(profiler, wall_time):\n",
    "    # Sum up the total CPU and CUDA time and memory usage\n",
    "    total_cpu_time = 0\n",
    "    total_cuda_time = 0\n",
    "    total_cpu_mem = 0\n",
    "    total_cuda_mem = 0\n",
    "\n",
    "    for event in profiler.events():\n",
    "        total_cpu_time += event.cpu_time_total\n",
    "        total_cuda_time += event.cuda_time_total\n",
    "        total_cpu_mem += event.cpu_memory_usage\n",
    "        total_cuda_mem += event.cuda_memory_usage\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Metric':<20} {'CPU':<15} {'CUDA':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Total Time (us)':<20} {total_cpu_time:<15.2f} {total_cuda_time:<15.2f}\")\n",
    "    print(f\"{'Total Memory (bytes)':<20} {total_cpu_mem:<15} {total_cuda_mem:<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    total_profiler_time = total_cpu_time + total_cuda_time\n",
    "    total_profiler_mem = total_cpu_mem + total_cuda_mem\n",
    "    print(f\"Total Profiler Time: {total_profiler_time:.2f} us\")\n",
    "    print(f\"Total Profiler Memory Usage: {total_profiler_mem} bytes\")\n",
    "    print(f\"Wall-clock Time: {wall_time:.2f} us\")\n",
    "    print(f\"Difference between Profiler Time and Wall-clock Time: {abs(total_profiler_time - wall_time):.2f} us\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling FFN layer by layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EndUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\profiler.py:228: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name                               CPU Total (us)  CUDA Total (us) CPU Mem (bytes) CUDA Mem (bytes)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "aten::empty                              266.00          0.00            8               0              \n",
      "aten::random_                            24.00           0.00            0               0              \n",
      "aten::item                               13.00           0.00            0               0              \n",
      "aten::_local_scalar_dense                5.00            0.00            0               0              \n",
      "[memory]                                 0.00            0.00            -130568         0              \n",
      "aten::select                             974.00          0.00            0               0              \n",
      "aten::as_strided                         227.00          0.00            0               0              \n",
      "aten::stack                              1514.00         0.00            26112           0              \n",
      "aten::cat                                120.00          0.00            26112           0              \n",
      "aten::view                               7.00            0.00            0               0              \n",
      "aten::unsqueeze                          643.00          0.00            0               0              \n",
      "aten::to                                 3.00            0.00            0               0              \n",
      "input_layer_1                            926.00          0.00            12800           0              \n",
      "aten::linear                             1052.00         0.00            66560           0              \n",
      "aten::t                                  111.00          0.00            0               0              \n",
      "aten::transpose                          48.00           0.00            0               0              \n",
      "aten::addmm                              713.00          0.00            66560           0              \n",
      "aten::expand                             26.00           0.00            0               0              \n",
      "aten::copy_                              71.00           0.00            0               0              \n",
      "aten::resolve_conj                       0.00            0.00            0               0              \n",
      "relu_8                                   368.00          0.00            64000           0              \n",
      "aten::relu                               126.00          0.00            64000           0              \n",
      "aten::clamp_min                          97.00           0.00            64000           0              \n",
      "hidden_layers.0_3                        170.00          0.00            12800           0              \n",
      "hidden_layers.1_4                        183.00          0.00            12800           0              \n",
      "hidden_layers.2_5                        139.00          0.00            12800           0              \n",
      "hidden_layers.3_6                        118.00          0.00            12800           0              \n",
      "output_layer_7                           71.00           0.00            2560            0              \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total                                    8015.00         0.00            313344          0              \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Profiling FFN as a whole...\n",
      "Wall-clock time for the forward pass: 2496.60 us\n",
      "------------------------------------------------------------\n",
      "Metric               CPU             CUDA           \n",
      "------------------------------------------------------------\n",
      "Total Time (us)      6180.00         0.00           \n",
      "Total Memory (bytes) 339456          0              \n",
      "------------------------------------------------------------\n",
      "Total Profiler Time: 6180.00 us\n",
      "Total Profiler Memory Usage: 339456 bytes\n",
      "Wall-clock Time: 2496.60 us\n",
      "Difference between Profiler Time and Wall-clock Time: 3683.40 us\n",
      "------------------------------------------------------------\n",
      "CUDA is not available for FFN.\n",
      "Profiling CNN layer by layer...\n",
      "Layer Name                               CPU Total (us)  CUDA Total (us) CPU Mem (bytes) CUDA Mem (bytes)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "aten::empty                              134.00          0.00            9699336         0              \n",
      "aten::random_                            23.00           0.00            0               0              \n",
      "aten::item                               8.00            0.00            0               0              \n",
      "aten::_local_scalar_dense                3.00            0.00            0               0              \n",
      "[memory]                                 0.00            0.00            -21776904       0              \n",
      "aten::select                             616.00          0.00            0               0              \n",
      "aten::as_strided                         130.00          0.00            0               0              \n",
      "aten::stack                              669.00          0.00            201216          0              \n",
      "aten::cat                                453.00          0.00            201216          0              \n",
      "aten::narrow                             237.00          0.00            0               0              \n",
      "aten::slice                              8.00            0.00            0               0              \n",
      "aten::view                               23.00           0.00            0               0              \n",
      "aten::unsqueeze                          85.00           0.00            0               0              \n",
      "aten::to                                 27.00           0.00            4               0              \n",
      "conv1_1                                  4615.00         0.00            6422528         0              \n",
      "aten::conv2d                             11106.00        0.00            9633792         0              \n",
      "aten::convolution                        11088.00        0.00            9633792         0              \n",
      "aten::_convolution                       11059.00        0.00            9633792         0              \n",
      "aten::mkldnn_convolution                 11016.00        0.00            9633792         0              \n",
      "aten::as_strided_                        22.00           0.00            0               0              \n",
      "aten::resize_                            11.00           0.00            0               0              \n",
      "relu1_2                                  3572.00         0.00            6422528         0              \n",
      "aten::relu                               4180.00         0.00            9666560         0              \n",
      "aten::clamp_min                          4143.00         0.00            9666560         0              \n",
      "pool1_3                                  11946.00        0.00            1605632         0              \n",
      "aten::max_pool2d                         16400.00        0.00            2408448         0              \n",
      "aten::max_pool2d_with_indices            15247.00        0.00            7225344         0              \n",
      "conv2_4                                  6800.00         0.00            3211264         0              \n",
      "relu2_5                                  987.00          0.00            3211264         0              \n",
      "pool2_6                                  5037.00         0.00            802816          0              \n",
      "flatten_7                                96.00           0.00            0               0              \n",
      "aten::flatten                            28.00           0.00            0               0              \n",
      "fc1_8                                    1034.00         0.00            32768           0              \n",
      "aten::linear                             1032.00         0.00            35328           0              \n",
      "aten::t                                  62.00           0.00            0               0              \n",
      "aten::transpose                          33.00           0.00            0               0              \n",
      "aten::addmm                              951.00          0.00            35328           0              \n",
      "aten::expand                             9.00            0.00            0               0              \n",
      "aten::copy_                              42.00           0.00            0               0              \n",
      "aten::resolve_conj                       0.00            0.00            0               0              \n",
      "relu3_9                                  98.00           0.00            32768           0              \n",
      "dropout_10                               243.00          0.00            32768           0              \n",
      "aten::dropout                            165.00          0.00            32768           0              \n",
      "aten::empty_like                         14.00           0.00            32768           0              \n",
      "aten::bernoulli_                         34.00           0.00            0               0              \n",
      "aten::div_                               79.00           0.00            0               0              \n",
      "aten::_to_copy                           20.00           0.00            4               0              \n",
      "aten::empty_strided                      4.00            0.00            4               0              \n",
      "aten::mul                                13.00           0.00            32768           0              \n",
      "fc2_11                                   132.00          0.00            2560            0              \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total                                    123734.00       0.00            77772812        0              \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Profiling CNN as a whole...\n",
      "Wall-clock time for the forward pass: 32302.50 us\n",
      "------------------------------------------------------------\n",
      "Metric               CPU             CUDA           \n",
      "------------------------------------------------------------\n",
      "Total Time (us)      118939.00       0.00           \n",
      "Total Memory (bytes) 77974028        0              \n",
      "------------------------------------------------------------\n",
      "Total Profiler Time: 118939.00 us\n",
      "Total Profiler Memory Usage: 77974028 bytes\n",
      "Wall-clock Time: 32302.50 us\n",
      "Difference between Profiler Time and Wall-clock Time: 86636.50 us\n",
      "------------------------------------------------------------\n",
      "CUDA is not available for CNN.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    for model_type in ['FFN', 'CNN']:\n",
    "        print(f\"Profiling {model_type} layer by layer...\")\n",
    "        # Get the model and data\n",
    "        if model_type == 'FFN':\n",
    "            model = ExtendedFFN(input_size=100, hidden_size=50, output_size=10, num_hidden_layers=4)\n",
    "        else:\n",
    "            model = CNN()\n",
    "\n",
    "        inputs, targets, batch_size = get_data_for_model(model_type)\n",
    "        dataset = TensorDataset(inputs, targets)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "        # Profile layer by layer\n",
    "        profile_model_layer_by_layer(model, device='cpu', dataloader=dataloader)\n",
    "\n",
    "        # Profile whole model\n",
    "        print(f\"Profiling {model_type} as a whole...\")\n",
    "        profile_whole_model(model, device='cpu', dataloader=dataloader)\n",
    "\n",
    "        # Profile on GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Profiling {model_type} layer by layer on GPU...\")\n",
    "            profile_model_layer_by_layer(model, device='cuda', dataloader=dataloader)\n",
    "\n",
    "            print(f\"Profiling {model_type} as a whole on GPU...\")\n",
    "            profile_whole_model(model, device='cuda', dataloader=dataloader)\n",
    "        else:\n",
    "            print(f\"CUDA is not available for {model_type}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
